{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3fa5de",
   "metadata": {},
   "source": [
    "# Business Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5e91055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150346, 14)\n",
      "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
      "       'attributes', 'categories', 'hours'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150346 entries, 0 to 150345\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   business_id   150346 non-null  object \n",
      " 1   name          150346 non-null  object \n",
      " 2   address       150346 non-null  object \n",
      " 3   city          150346 non-null  object \n",
      " 4   state         150346 non-null  object \n",
      " 5   postal_code   150346 non-null  object \n",
      " 6   latitude      150346 non-null  float64\n",
      " 7   longitude     150346 non-null  float64\n",
      " 8   stars         150346 non-null  float64\n",
      " 9   review_count  150346 non-null  int64  \n",
      " 10  is_open       150346 non-null  int64  \n",
      " 11  attributes    136602 non-null  object \n",
      " 12  categories    150243 non-null  object \n",
      " 13  hours         127123 non-null  object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "RAW = Path(\"../data/raw\")\n",
    "\n",
    "# 1) Read JSON Lines\n",
    "biz = pd.read_json(RAW / \"yelp_academic_dataset_business.json\", lines=True)\n",
    "\n",
    "print(biz.shape)       # rows, columns\n",
    "print(biz.columns)  # column names\n",
    "biz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6a849eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/raw/1_yelp_business_flat.csv\n",
      "Shape: (150346, 15)\n"
     ]
    }
   ],
   "source": [
    "# Ensure review_count is numeric\n",
    "biz[\"review_count\"] = pd.to_numeric(biz[\"review_count\"], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "# Log transform review_count to reduce skewness\n",
    "biz[\"review_count_log1p\"] = np.log1p(biz[\"review_count\"]).astype(\"float32\")\n",
    "\n",
    "# --- Helpers --------------------------------------------------------------- \n",
    "\n",
    "\n",
    "def dict_or_empty(x):\n",
    "    return x if isinstance(x, dict) else {}\n",
    "\n",
    "def flatten_dict_column(df, col, prefix):\n",
    "    \"\"\"\n",
    "    Flattens a column of dicts (possibly containing nested dicts) into top-level columns.\n",
    "    - df[col] remains untouched; you can drop it afterwards if you like.\n",
    "    - Returns a new DataFrame with flattened columns prefixed.\n",
    "    \"\"\"\n",
    "    # Ensure every row is a dict (avoid NaN/None)\n",
    "    series = df[col].apply(dict_or_empty)\n",
    "\n",
    "    # Use json_normalize with a separator to flatten nested dicts (e.g., Ambience.romantic)\n",
    "    flat = pd.json_normalize(series, sep=\"__\")\n",
    "    if not flat.empty:\n",
    "        flat.columns = [f\"{prefix}{c}\" for c in flat.columns]\n",
    "    else:\n",
    "        # No data -> empty DF with no columns\n",
    "        flat = pd.DataFrame(index=df.index)\n",
    "    return flat\n",
    "\n",
    "# --- Flatten nested dict columns ------------------------------------------\n",
    "\n",
    "attr_flat  = flatten_dict_column(biz, \"attributes\", \"attr_\")\n",
    "hours_flat = flatten_dict_column(biz, \"hours\",      \"hours_\")\n",
    "\n",
    "# If some attributes values are JSON-encoded strings (rare), try to parse them:\n",
    "for c in attr_flat.columns:\n",
    "    # Parse strings that look like mini-JSON dicts (e.g., \"{'romantic': False, ...}\")\n",
    "    # Yelp sometimes uses single quotes; replace with double quotes safely when it seems dict-like.\n",
    "    mask = attr_flat[c].apply(lambda v: isinstance(v, str) and v.strip().startswith(\"{\") and v.strip().endswith(\"}\"))\n",
    "    if mask.any():\n",
    "        def try_parse(v):\n",
    "            if not isinstance(v, str): return v\n",
    "            s = v.strip()\n",
    "            # best-effort: convert single quotes to double quotes for JSON parsing\n",
    "            s_json = s.replace(\"'\", '\"')\n",
    "            try:\n",
    "                parsed = json.loads(s_json)\n",
    "                if isinstance(parsed, dict):\n",
    "                    return parsed\n",
    "            except Exception:\n",
    "                pass\n",
    "            return v\n",
    "        parsed_series = attr_flat.loc[mask, c].apply(try_parse)\n",
    "        # If we actually parsed dicts, expand them\n",
    "        if parsed_series.apply(lambda x: isinstance(x, dict)).any():\n",
    "            sub = pd.json_normalize(parsed_series, sep=\"__\")\n",
    "            sub.columns = [f\"{c}__{k}\" for k in sub.columns]  # keep source col name\n",
    "            # align indices and join\n",
    "            attr_flat = attr_flat.drop(columns=[c]).join(sub, how=\"left\")\n",
    "\n",
    "# --- Categories handling ---------------------------------------------------\n",
    "# Yelp 'categories' is usually a comma-separated string. Normalize to a clean list or string.\n",
    "def normalize_categories(val):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, list):\n",
    "        # Occasionally already a list\n",
    "        return [x.strip() for x in val if isinstance(x, str)]\n",
    "    # Treat as comma-separated\n",
    "    return [x.strip() for x in str(val).split(\",\") if x.strip()]\n",
    "\n",
    "cats_list = biz[\"categories\"].apply(normalize_categories)\n",
    "\n",
    "# (Option A) Keep as semicolon-separated string for single-row-per-business\n",
    "cats_str = cats_list.apply(lambda lst: \"; \".join(lst) if lst else None)\n",
    "\n",
    "# --- Build flat table ------------------------------------------------------\n",
    "cols_to_drop = [\"attributes\", \"hours\", \"categories\"]\n",
    "base = biz.drop(columns=[c for c in cols_to_drop if c in biz.columns])\n",
    "\n",
    "biz_flat = pd.concat([base, attr_flat, hours_flat], axis=1)\n",
    "biz_flat[\"categories_norm\"] = cats_str\n",
    "\n",
    "# Optional: sort columns (ID first, readable order)\n",
    "id_cols = [c for c in [\"business_id\", \"name\", \"city\", \"state\", \"postal_code\"] if c in biz_flat.columns]\n",
    "other_cols = [c for c in biz_flat.columns if c not in id_cols]\n",
    "biz_flat = biz_flat[id_cols + other_cols]\n",
    "\n",
    "# 2) Save one-row-per-business CSV\n",
    "out_csv = RAW / \"1_yelp_business_flat.csv\"\n",
    "biz_flat.to_csv(out_csv, index=False)\n",
    "print(f\"Saved: {out_csv}\")\n",
    "\n",
    "print(\"Shape:\", biz.shape)   # (rows, columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200cf15",
   "metadata": {},
   "source": [
    "## load & filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdec0ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/713055227.py:5: DtypeWarning: Columns (44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  biz = pd.read_csv(RAW / \"1_yelp_business_flat.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52268, 56)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RAW = Path(\"../data/raw\")\n",
    "biz = pd.read_csv(RAW / \"1_yelp_business_flat.csv\")\n",
    "\n",
    "# keep restaurants only (recommended)\n",
    "is_rest = biz[\"categories_norm\"].fillna(\"\").str.contains(\"Restaurants\", case=False)\n",
    "biz = biz.loc[is_rest].copy()\n",
    "\n",
    "print(biz.shape)\n",
    "biz.head()\n",
    "\n",
    "\n",
    "# drop leakage: DO NOT use business.stars as a feature\n",
    "biz = biz.drop(columns=[c for c in [\"stars\"] if c in biz.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "828eae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (52268, 55)\n",
      "Columns: Index(['business_id', 'name', 'city', 'state', 'postal_code', 'address',\n",
      "       'latitude', 'longitude', 'review_count', 'is_open',\n",
      "       'review_count_log1p', 'attr_ByAppointmentOnly',\n",
      "       'attr_BusinessAcceptsCreditCards', 'attr_BikeParking',\n",
      "       'attr_RestaurantsPriceRange2', 'attr_CoatCheck',\n",
      "       'attr_RestaurantsTakeOut', 'attr_RestaurantsDelivery', 'attr_Caters',\n",
      "       'attr_WiFi', 'attr_WheelchairAccessible', 'attr_HappyHour',\n",
      "       'attr_OutdoorSeating', 'attr_HasTV', 'attr_RestaurantsReservations',\n",
      "       'attr_DogsAllowed', 'attr_Alcohol', 'attr_GoodForKids',\n",
      "       'attr_RestaurantsAttire', 'attr_RestaurantsTableService',\n",
      "       'attr_RestaurantsGoodForGroups', 'attr_DriveThru', 'attr_NoiseLevel',\n",
      "       'attr_GoodForMeal', 'attr_BusinessAcceptsBitcoin', 'attr_Smoking',\n",
      "       'attr_GoodForDancing', 'attr_AcceptsInsurance', 'attr_BestNights',\n",
      "       'attr_BYOB', 'attr_Corkage', 'attr_BYOBCorkage',\n",
      "       'attr_HairSpecializesIn', 'attr_Open24Hours',\n",
      "       'attr_RestaurantsCounterService', 'attr_AgesAllowed',\n",
      "       'attr_DietaryRestrictions', 'hours_Monday', 'hours_Tuesday',\n",
      "       'hours_Wednesday', 'hours_Thursday', 'hours_Friday', 'hours_Saturday',\n",
      "       'hours_Sunday', 'categories_norm'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>...</th>\n",
       "      <th>attr_AgesAllowed</th>\n",
       "      <th>attr_DietaryRestrictions</th>\n",
       "      <th>hours_Monday</th>\n",
       "      <th>hours_Tuesday</th>\n",
       "      <th>hours_Wednesday</th>\n",
       "      <th>hours_Thursday</th>\n",
       "      <th>hours_Friday</th>\n",
       "      <th>hours_Saturday</th>\n",
       "      <th>hours_Sunday</th>\n",
       "      <th>categories_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7:0-20:0</td>\n",
       "      <td>7:0-20:0</td>\n",
       "      <td>7:0-20:0</td>\n",
       "      <td>7:0-20:0</td>\n",
       "      <td>7:0-21:0</td>\n",
       "      <td>7:0-21:0</td>\n",
       "      <td>7:0-21:0</td>\n",
       "      <td>Restaurants; Food; Bubble Tea; Coffee &amp; Tea; B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CF33F8-E6oudUQ46HnavjQ</td>\n",
       "      <td>Sonic Drive-In</td>\n",
       "      <td>Ashland City</td>\n",
       "      <td>TN</td>\n",
       "      <td>37015</td>\n",
       "      <td>615 S Main St</td>\n",
       "      <td>36.269593</td>\n",
       "      <td>-87.058943</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:0-0:0</td>\n",
       "      <td>6:0-22:0</td>\n",
       "      <td>6:0-22:0</td>\n",
       "      <td>6:0-22:0</td>\n",
       "      <td>9:0-0:0</td>\n",
       "      <td>9:0-22:0</td>\n",
       "      <td>8:0-22:0</td>\n",
       "      <td>Burgers; Fast Food; Sandwiches; Food; Ice Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>k0hlBqXX-Bt0vf1op7Jr1w</td>\n",
       "      <td>Tsevi's Pub And Grill</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123</td>\n",
       "      <td>8025 Mackenzie Rd</td>\n",
       "      <td>38.565165</td>\n",
       "      <td>-90.321087</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pubs; Restaurants; Italian; Bars; American (Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bBDDEgkFA1Otx9Lfe7BZUQ</td>\n",
       "      <td>Sonic Drive-In</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37207</td>\n",
       "      <td>2312 Dickerson Pike</td>\n",
       "      <td>36.208102</td>\n",
       "      <td>-86.768170</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:0-0:0</td>\n",
       "      <td>6:0-21:0</td>\n",
       "      <td>6:0-21:0</td>\n",
       "      <td>6:0-16:0</td>\n",
       "      <td>6:0-16:0</td>\n",
       "      <td>6:0-17:0</td>\n",
       "      <td>6:0-21:0</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt; Fast Food; Burgers;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>eEOYSgkmpB90uNA7lDOMRA</td>\n",
       "      <td>Vietnamese Food Truck</td>\n",
       "      <td>Tampa Bay</td>\n",
       "      <td>FL</td>\n",
       "      <td>33602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.955269</td>\n",
       "      <td>-82.456320</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:0-14:0</td>\n",
       "      <td>11:0-14:0</td>\n",
       "      <td>11:0-14:0</td>\n",
       "      <td>11:0-14:0</td>\n",
       "      <td>11:0-14:0</td>\n",
       "      <td>5:0-10:0</td>\n",
       "      <td>15:0-18:0</td>\n",
       "      <td>Vietnamese; Food; Restaurants; Food Trucks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                   name          city state  \\\n",
       "3   MTSW4McQd7CbVtyjqoe9mw     St Honore Pastries  Philadelphia    PA   \n",
       "5   CF33F8-E6oudUQ46HnavjQ         Sonic Drive-In  Ashland City    TN   \n",
       "8   k0hlBqXX-Bt0vf1op7Jr1w  Tsevi's Pub And Grill        Affton    MO   \n",
       "9   bBDDEgkFA1Otx9Lfe7BZUQ         Sonic Drive-In     Nashville    TN   \n",
       "11  eEOYSgkmpB90uNA7lDOMRA  Vietnamese Food Truck     Tampa Bay    FL   \n",
       "\n",
       "   postal_code              address   latitude  longitude  review_count  \\\n",
       "3        19107          935 Race St  39.955505 -75.155564          80.0   \n",
       "5        37015        615 S Main St  36.269593 -87.058943           6.0   \n",
       "8        63123    8025 Mackenzie Rd  38.565165 -90.321087          19.0   \n",
       "9        37207  2312 Dickerson Pike  36.208102 -86.768170          10.0   \n",
       "11       33602                  NaN  27.955269 -82.456320          10.0   \n",
       "\n",
       "    is_open  ...  attr_AgesAllowed attr_DietaryRestrictions hours_Monday  \\\n",
       "3         1  ...               NaN                      NaN     7:0-20:0   \n",
       "5         1  ...               NaN                      NaN      0:0-0:0   \n",
       "8         0  ...               NaN                      NaN          NaN   \n",
       "9         1  ...               NaN                      NaN      0:0-0:0   \n",
       "11        1  ...               NaN                      NaN    11:0-14:0   \n",
       "\n",
       "   hours_Tuesday  hours_Wednesday hours_Thursday hours_Friday hours_Saturday  \\\n",
       "3       7:0-20:0         7:0-20:0       7:0-20:0     7:0-21:0       7:0-21:0   \n",
       "5       6:0-22:0         6:0-22:0       6:0-22:0      9:0-0:0       9:0-22:0   \n",
       "8            NaN              NaN            NaN          NaN            NaN   \n",
       "9       6:0-21:0         6:0-21:0       6:0-16:0     6:0-16:0       6:0-17:0   \n",
       "11     11:0-14:0        11:0-14:0      11:0-14:0    11:0-14:0       5:0-10:0   \n",
       "\n",
       "   hours_Sunday                                    categories_norm  \n",
       "3      7:0-21:0  Restaurants; Food; Bubble Tea; Coffee & Tea; B...  \n",
       "5      8:0-22:0  Burgers; Fast Food; Sandwiches; Food; Ice Crea...  \n",
       "8           NaN  Pubs; Restaurants; Italian; Bars; American (Tr...  \n",
       "9      6:0-21:0  Ice Cream & Frozen Yogurt; Fast Food; Burgers;...  \n",
       "11    15:0-18:0         Vietnamese; Food; Restaurants; Food Trucks  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52268 entries, 3 to 150340\n",
      "Data columns (total 55 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   business_id                      52268 non-null  object \n",
      " 1   name                             52268 non-null  object \n",
      " 2   city                             52268 non-null  object \n",
      " 3   state                            52268 non-null  object \n",
      " 4   postal_code                      52247 non-null  object \n",
      " 5   address                          51825 non-null  object \n",
      " 6   latitude                         52268 non-null  float64\n",
      " 7   longitude                        52268 non-null  float64\n",
      " 8   review_count                     52268 non-null  float64\n",
      " 9   is_open                          52268 non-null  int64  \n",
      " 10  review_count_log1p               52268 non-null  float64\n",
      " 11  attr_ByAppointmentOnly           3345 non-null   object \n",
      " 12  attr_BusinessAcceptsCreditCards  45531 non-null  object \n",
      " 13  attr_BikeParking                 35449 non-null  object \n",
      " 14  attr_RestaurantsPriceRange2      44484 non-null  float64\n",
      " 15  attr_CoatCheck                   4278 non-null   object \n",
      " 16  attr_RestaurantsTakeOut          47628 non-null  object \n",
      " 17  attr_RestaurantsDelivery         45058 non-null  object \n",
      " 18  attr_Caters                      34523 non-null  object \n",
      " 19  attr_WiFi                        37712 non-null  object \n",
      " 20  attr_WheelchairAccessible        13546 non-null  object \n",
      " 21  attr_HappyHour                   13007 non-null  object \n",
      " 22  attr_OutdoorSeating              41882 non-null  object \n",
      " 23  attr_HasTV                       41899 non-null  object \n",
      " 24  attr_RestaurantsReservations     42857 non-null  object \n",
      " 25  attr_DogsAllowed                 11463 non-null  object \n",
      " 26  attr_Alcohol                     39946 non-null  object \n",
      " 27  attr_GoodForKids                 40955 non-null  object \n",
      " 28  attr_RestaurantsAttire           38955 non-null  object \n",
      " 29  attr_RestaurantsTableService     19722 non-null  object \n",
      " 30  attr_RestaurantsGoodForGroups    41419 non-null  object \n",
      " 31  attr_DriveThru                   5868 non-null   object \n",
      " 32  attr_NoiseLevel                  34808 non-null  object \n",
      " 33  attr_GoodForMeal                 28553 non-null  object \n",
      " 34  attr_BusinessAcceptsBitcoin      6729 non-null   object \n",
      " 35  attr_Smoking                     3443 non-null   object \n",
      " 36  attr_GoodForDancing              3595 non-null   object \n",
      " 37  attr_AcceptsInsurance            19 non-null     object \n",
      " 38  attr_BestNights                  4502 non-null   object \n",
      " 39  attr_BYOB                        4211 non-null   object \n",
      " 40  attr_Corkage                     3421 non-null   object \n",
      " 41  attr_BYOBCorkage                 1437 non-null   object \n",
      " 42  attr_HairSpecializesIn           2 non-null      object \n",
      " 43  attr_Open24Hours                 21 non-null     object \n",
      " 44  attr_RestaurantsCounterService   18 non-null     object \n",
      " 45  attr_AgesAllowed                 88 non-null     object \n",
      " 46  attr_DietaryRestrictions         29 non-null     object \n",
      " 47  hours_Monday                     38967 non-null  object \n",
      " 48  hours_Tuesday                    41783 non-null  object \n",
      " 49  hours_Wednesday                  43742 non-null  object \n",
      " 50  hours_Thursday                   44429 non-null  object \n",
      " 51  hours_Friday                     44644 non-null  object \n",
      " 52  hours_Saturday                   43525 non-null  object \n",
      " 53  hours_Sunday                     37703 non-null  object \n",
      " 54  categories_norm                  52268 non-null  object \n",
      "dtypes: float64(5), int64(1), object(49)\n",
      "memory usage: 22.3+ MB\n",
      "\n",
      "Missing values per column:\n",
      "business_id                            0\n",
      "name                                   0\n",
      "city                                   0\n",
      "state                                  0\n",
      "postal_code                           21\n",
      "address                              443\n",
      "latitude                               0\n",
      "longitude                              0\n",
      "review_count                           0\n",
      "is_open                                0\n",
      "review_count_log1p                     0\n",
      "attr_ByAppointmentOnly             48923\n",
      "attr_BusinessAcceptsCreditCards     6737\n",
      "attr_BikeParking                   16819\n",
      "attr_RestaurantsPriceRange2         7784\n",
      "attr_CoatCheck                     47990\n",
      "attr_RestaurantsTakeOut             4640\n",
      "attr_RestaurantsDelivery            7210\n",
      "attr_Caters                        17745\n",
      "attr_WiFi                          14556\n",
      "attr_WheelchairAccessible          38722\n",
      "attr_HappyHour                     39261\n",
      "attr_OutdoorSeating                10386\n",
      "attr_HasTV                         10369\n",
      "attr_RestaurantsReservations        9411\n",
      "attr_DogsAllowed                   40805\n",
      "attr_Alcohol                       12322\n",
      "attr_GoodForKids                   11313\n",
      "attr_RestaurantsAttire             13313\n",
      "attr_RestaurantsTableService       32546\n",
      "attr_RestaurantsGoodForGroups      10849\n",
      "attr_DriveThru                     46400\n",
      "attr_NoiseLevel                    17460\n",
      "attr_GoodForMeal                   23715\n",
      "attr_BusinessAcceptsBitcoin        45539\n",
      "attr_Smoking                       48825\n",
      "attr_GoodForDancing                48673\n",
      "attr_AcceptsInsurance              52249\n",
      "attr_BestNights                    47766\n",
      "attr_BYOB                          48057\n",
      "attr_Corkage                       48847\n",
      "attr_BYOBCorkage                   50831\n",
      "attr_HairSpecializesIn             52266\n",
      "attr_Open24Hours                   52247\n",
      "attr_RestaurantsCounterService     52250\n",
      "attr_AgesAllowed                   52180\n",
      "attr_DietaryRestrictions           52239\n",
      "hours_Monday                       13301\n",
      "hours_Tuesday                      10485\n",
      "hours_Wednesday                     8526\n",
      "hours_Thursday                      7839\n",
      "hours_Friday                        7624\n",
      "hours_Saturday                      8743\n",
      "hours_Sunday                       14565\n",
      "categories_norm                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", biz.shape)       # rows, columns\n",
    "print(\"Columns:\", biz.columns)   # column names\n",
    "display(biz.head())              # first 5 rows\n",
    "\n",
    "# Basic checks\n",
    "biz.info()                       # dtypes + non-null counts\n",
    "biz.describe()                   # summary stats for numeric cols\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(biz.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4e0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ea566b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52268 entries, 3 to 150340\n",
      "Data columns (total 55 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   business_id                      52268 non-null  object \n",
      " 1   name                             52268 non-null  object \n",
      " 2   city                             52268 non-null  object \n",
      " 3   state                            52268 non-null  object \n",
      " 4   postal_code                      52247 non-null  object \n",
      " 5   address                          51825 non-null  object \n",
      " 6   latitude                         52268 non-null  float64\n",
      " 7   longitude                        52268 non-null  float64\n",
      " 8   review_count                     52268 non-null  float64\n",
      " 9   is_open                          52268 non-null  int64  \n",
      " 10  review_count_log1p               52268 non-null  float64\n",
      " 11  attr_ByAppointmentOnly           3345 non-null   object \n",
      " 12  attr_BusinessAcceptsCreditCards  45531 non-null  object \n",
      " 13  attr_BikeParking                 35449 non-null  object \n",
      " 14  attr_RestaurantsPriceRange2      44484 non-null  float64\n",
      " 15  attr_CoatCheck                   4278 non-null   object \n",
      " 16  attr_RestaurantsTakeOut          47628 non-null  object \n",
      " 17  attr_RestaurantsDelivery         45058 non-null  object \n",
      " 18  attr_Caters                      34523 non-null  object \n",
      " 19  attr_WiFi                        37712 non-null  object \n",
      " 20  attr_WheelchairAccessible        13546 non-null  object \n",
      " 21  attr_HappyHour                   13007 non-null  object \n",
      " 22  attr_OutdoorSeating              41882 non-null  object \n",
      " 23  attr_HasTV                       41899 non-null  object \n",
      " 24  attr_RestaurantsReservations     42857 non-null  object \n",
      " 25  attr_DogsAllowed                 11463 non-null  object \n",
      " 26  attr_Alcohol                     39946 non-null  object \n",
      " 27  attr_GoodForKids                 40955 non-null  object \n",
      " 28  attr_RestaurantsAttire           38955 non-null  object \n",
      " 29  attr_RestaurantsTableService     19722 non-null  object \n",
      " 30  attr_RestaurantsGoodForGroups    41419 non-null  object \n",
      " 31  attr_DriveThru                   5868 non-null   object \n",
      " 32  attr_NoiseLevel                  34808 non-null  object \n",
      " 33  attr_GoodForMeal                 28553 non-null  object \n",
      " 34  attr_BusinessAcceptsBitcoin      6729 non-null   object \n",
      " 35  attr_Smoking                     3443 non-null   object \n",
      " 36  attr_GoodForDancing              3595 non-null   object \n",
      " 37  attr_AcceptsInsurance            19 non-null     object \n",
      " 38  attr_BestNights                  4502 non-null   object \n",
      " 39  attr_BYOB                        4211 non-null   object \n",
      " 40  attr_Corkage                     3421 non-null   object \n",
      " 41  attr_BYOBCorkage                 1437 non-null   object \n",
      " 42  attr_HairSpecializesIn           2 non-null      object \n",
      " 43  attr_Open24Hours                 21 non-null     object \n",
      " 44  attr_RestaurantsCounterService   18 non-null     object \n",
      " 45  attr_AgesAllowed                 88 non-null     object \n",
      " 46  attr_DietaryRestrictions         29 non-null     object \n",
      " 47  hours_Monday                     38967 non-null  object \n",
      " 48  hours_Tuesday                    41783 non-null  object \n",
      " 49  hours_Wednesday                  43742 non-null  object \n",
      " 50  hours_Thursday                   44429 non-null  object \n",
      " 51  hours_Friday                     44644 non-null  object \n",
      " 52  hours_Saturday                   43525 non-null  object \n",
      " 53  hours_Sunday                     37703 non-null  object \n",
      " 54  categories_norm                  52268 non-null  object \n",
      "dtypes: float64(5), int64(1), object(49)\n",
      "memory usage: 22.3+ MB\n"
     ]
    }
   ],
   "source": [
    "biz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a34a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d638e8b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f13d31d4",
   "metadata": {},
   "source": [
    "## Drop Rare or sparse attributes (very low coverage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e72c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/2804800455.py:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  biz[\"avg_daily_hours\"]    = (biz[\"total_weekly_hours\"] / biz[\"days_open\"].replace(0, pd.NA)).fillna(0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/raw/2_yelp_business_flat_attr_clean.csv | Shape: (52268, 43)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# --- Build time features from hours_* strings ---\n",
    "TIME_FMT = \"%H:%M\"\n",
    "RANGE_RE = re.compile(r\"^\\s*(\\d{1,2}:\\d{2})\\s*-\\s*(\\d{1,2}:\\d{2})\\s*$\")\n",
    "\n",
    "def hours_from_range(s):\n",
    "    if not isinstance(s, str):\n",
    "        return 0.0\n",
    "    m = RANGE_RE.match(s)\n",
    "    if not m:\n",
    "        return 0.0\n",
    "    start_str, end_str = m.groups()\n",
    "    start = datetime.strptime(start_str, TIME_FMT)\n",
    "    end   = datetime.strptime(end_str, TIME_FMT)\n",
    "    if start_str == end_str:\n",
    "        return 24.0 if start_str in (\"00:00\", \"0:00\") else 0.0\n",
    "    if end <= start:  # crosses midnight\n",
    "        return (24 - (start.hour + start.minute/60)) + (end.hour + end.minute/60)\n",
    "    return (end - start).seconds / 3600.0\n",
    "\n",
    "day_names = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "for d in day_names:\n",
    "    src = f\"hours_{d}\"\n",
    "    dst = f\"openhours_{d}\"\n",
    "    if src in biz.columns:\n",
    "        biz[dst] = biz[src].apply(hours_from_range)\n",
    "    else:\n",
    "        biz[dst] = 0.0\n",
    "\n",
    "open_cols = [f\"openhours_{d}\" for d in day_names]\n",
    "\n",
    "biz[\"total_weekly_hours\"] = biz[open_cols].sum(axis=1)\n",
    "biz[\"days_open\"]          = (biz[open_cols] > 0).sum(axis=1)\n",
    "biz[\"weekend_hours\"]      = biz[\"openhours_Saturday\"] + biz[\"openhours_Sunday\"]\n",
    "biz[\"avg_daily_hours\"]    = (biz[\"total_weekly_hours\"] / biz[\"days_open\"].replace(0, pd.NA)).fillna(0.0)\n",
    "\n",
    "# (optional) keep a flag to distinguish missing hours info later, if needed\n",
    "biz[\"has_hours_info\"]     = (biz[open_cols].sum(axis=1) > 0).astype(\"int8\")\n",
    "\n",
    "# --- Cast & (optionally) fill, same style as review_count ---\n",
    "for c in [\"total_weekly_hours\",\"days_open\",\"weekend_hours\",\"avg_daily_hours\"]:\n",
    "    biz[c] = pd.to_numeric(biz[c], errors=\"coerce\").astype(\"float32\")\n",
    "    # If you want to keep NaN for “unknown”, comment the next line out:\n",
    "    # biz[c] = biz[c].fillna(0)\n",
    "\n",
    "# --- Now drop leakage + sparse columns (but DO NOT drop the new features) ---\n",
    "leak_and_sparse = [\n",
    "    \"stars\", \"name\", \"postal_code\", \"address\",\n",
    "    \"attr_CoatCheck\", \"attr_GoodForMeal\", \"attr_BusinessAcceptsBitcoin\",\n",
    "    \"attr_GoodForDancing\", \"attr_AcceptsInsurance\", \"attr_BestNights\",\n",
    "    \"attr_BYOB\", \"attr_Corkage\", \"attr_BYOBCorkage\", \"attr_HairSpecializesIn\",\n",
    "    \"attr_RestaurantsCounterService\", \"attr_AgesAllowed\", \"attr_DietaryRestrictions\", \"attr_Open24Hours\",\n",
    "    # you may drop raw hours_* strings now that features are built:\n",
    "    \"hours_Monday\",\"hours_Tuesday\",\"hours_Wednesday\",\"hours_Thursday\",\n",
    "    \"hours_Friday\",\"hours_Saturday\",\"hours_Sunday\",\n",
    "]\n",
    "biz = biz.drop(columns=[c for c in leak_and_sparse if c in biz.columns])\n",
    "\n",
    "# --- Save with time features included ---\n",
    "out_path = RAW / \"2_yelp_business_flat_attr_clean.csv\"\n",
    "biz.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path, \"| Shape:\", biz.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e618912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4121c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535b546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd4fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd682305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00d1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a959bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "\n",
    "# RAW = Path(\"../data/raw\")\n",
    "# biz = pd.read_csv(RAW / \"1_yelp_business_flat.csv\")\n",
    "\n",
    "# # keep restaurants only (recommended)\n",
    "# is_rest = biz[\"categories_norm\"].fillna(\"\").str.contains(\"Restaurants\", case=False)\n",
    "# biz = biz.loc[is_rest].copy()\n",
    "\n",
    "# print(\"Shape before drops:\", biz.shape)\n",
    "\n",
    "# # --- Drop leakage (target column) ---\n",
    "# biz = biz.drop(columns=[c for c in [\"stars\"] if c in biz.columns])\n",
    "\n",
    "# # --- Drop sparse / redundant attributes ---\n",
    "# cols_to_drop = [\n",
    "#     \"name\", \"postal_code\", \"address\",\n",
    "#     \"attr_CoatCheck\", \"attr_GoodForMeal\", \"attr_BusinessAcceptsBitcoin\", \n",
    "#     \"attr_GoodForDancing\", \"attr_AcceptsInsurance\", \"attr_BestNights\",\n",
    "#     \"attr_BYOB\", \"attr_Corkage\", \"attr_BYOBCorkage\", \"attr_HairSpecializesIn\",\n",
    "#     \"attr_RestaurantsCounterService\", \"attr_AgesAllowed\", \"attr_DietaryRestrictions\", \"attr_Open24Hours\",\n",
    "#     \"hours_Monday\", \"hours_Tuesday\", \"hours_Wednesday\", \"hours_Thursday\",\n",
    "#     \"hours_Friday\", \"hours_Saturday\", \"hours_Sunday\",\n",
    "# ]\n",
    "\n",
    "# # Drop only those columns that exist\n",
    "# to_drop = [c for c in cols_to_drop if c in biz.columns]\n",
    "# biz = biz.drop(columns=to_drop)\n",
    "\n",
    "# print(\"Dropped columns:\", to_drop)\n",
    "# print(\"Shape after drops:\", biz.shape)\n",
    "\n",
    "# # Quick peek\n",
    "# biz.head()\n",
    "\n",
    "# out_path = RAW / \"2_yelp_business_flat_attr_clean.csv\"\n",
    "# biz.to_csv(out_path, index=False)\n",
    "# print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076fb1b",
   "metadata": {},
   "source": [
    "## Attribute : consistent categorical\n",
    "consistent categorical values that can be used for ML\n",
    "\n",
    "Flattens dict-like attributes (e.g., attr_GoodForMeal, attr_Ambience, attr_BusinessParking) into subcolumns like attr_GoodForMeal__breakfast.\n",
    "\n",
    "Normalizes boolean-ish values to {1.0, 0.0, NaN} (Float32).\n",
    "\n",
    "Normalizes WiFi / Alcohol / NoiseLevel / RestaurantsAttire to consistent categories.\n",
    "\n",
    "Casts RestaurantsPriceRange2 to numeric 1–4 (Float32).\n",
    "\n",
    "Fixes junk like u'free', \"none'\", casual', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9905ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/raw/2_yelp_business_drop_week.csv | Shape: (52268, 36)\n"
     ]
    }
   ],
   "source": [
    "# --- Now drop leakage \n",
    "drop_week = [\n",
    "   \"openhours_Monday\", \"openhours_Tuesday\", \"openhours_Wednesday\", \"openhours_Thursday\", \"openhours_Friday\", \"openhours_Saturday\", \"openhours_Sunday\"\n",
    "]\n",
    "biz = biz.drop(columns=[c for c in drop_week if c in biz.columns])\n",
    "\n",
    "# --- Save with time features included ---\n",
    "out_path = RAW / \"2_yelp_business_drop_week.csv\"\n",
    "biz.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path, \"| Shape:\", biz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e30ea6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cleaning attributes.\n",
      "Example columns and categories:\n",
      "attr_WiFi → ['free', 'no', 'paid']\n",
      "attr_Alcohol → ['beer_and_wine', 'full_bar']\n",
      "attr_RestaurantsAttire → ['casual', 'dressy', 'formal']\n",
      "attr_NoiseLevel → ['average', 'loud', 'quiet', 'very_loud']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/62268177.py:147: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  print(c, \"→\", list(biz[c].cat.categories) if pd.api.types.is_categorical_dtype(biz[c]) else \"not categorical\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/raw/3_yelp_business_flat_attr_formatted.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52268, 36)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json, ast, re\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Helpers\n",
    "# ------------------------\n",
    "def parse_dictish(v):\n",
    "    \"\"\"Convert dict-like strings to dicts safely; otherwise {}.\"\"\"\n",
    "    if isinstance(v, dict):\n",
    "        return v\n",
    "    if pd.isna(v):\n",
    "        return {}\n",
    "    s = str(v).strip()\n",
    "    # fix odd trailing quote like \"none'\"\n",
    "    if s.endswith(\"'\") and s.count(\"'\") % 2 == 1:\n",
    "        s = s[:-1]\n",
    "    # python literal (handles single quotes / True/False/None)\n",
    "    try:\n",
    "        out = ast.literal_eval(s)\n",
    "        if isinstance(out, dict):\n",
    "            return out\n",
    "    except Exception:\n",
    "        pass\n",
    "    # JSON fallback\n",
    "    s_json = (s.replace(\"'\", '\"')\n",
    "                .replace(\"None\", \"null\")\n",
    "                .replace(\"True\", \"true\")\n",
    "                .replace(\"False\", \"false\"))\n",
    "    try:\n",
    "        out = json.loads(s_json)\n",
    "        if isinstance(out, dict):\n",
    "            return out\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {}\n",
    "\n",
    "def norm_token(v):\n",
    "    \"\"\"Lowercase, strip quotes/unicode prefixes; return None for empty/none-ish.\"\"\"\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    s = str(v).strip()\n",
    "    s = s.replace(\"u'\", \"'\")\n",
    "    s = s.strip(\"'\").strip('\"').strip()\n",
    "    s_low = s.lower()\n",
    "    if s_low in {\"\", \"none\", \"null\", \"nan\"}:\n",
    "        return None\n",
    "    return s_low\n",
    "\n",
    "def to_TFN(v):\n",
    "    \"\"\"Map many boolean spellings to 'TRUE'/'FALSE'/NaN (string categories).\"\"\"\n",
    "    t = norm_token(v)\n",
    "    if t is None:\n",
    "        return np.nan\n",
    "    if t in {\"true\",\"t\",\"yes\",\"y\",\"1\"}:\n",
    "        return \"TRUE\"\n",
    "    if t in {\"false\",\"f\",\"no\",\"n\",\"0\"}:\n",
    "        return \"FALSE\"\n",
    "    return np.nan  # unexpected values → NaN so they don't pollute categories\n",
    "\n",
    "# ------------------------\n",
    "# 1) Expand dict-like attribute columns\n",
    "# ------------------------\n",
    "attr_cols = [c for c in biz.columns if c.startswith(\"attr_\")]\n",
    "\n",
    "dict_like = []\n",
    "for c in attr_cols:\n",
    "    ser = biz[c].dropna().astype(str).str.strip()\n",
    "    if not ser.empty and ser.str.match(r\"^\\{.*\\}$\").any():\n",
    "        dict_like.append(c)\n",
    "\n",
    "for c in dict_like:\n",
    "    parsed = biz[c].apply(parse_dictish)\n",
    "    sub = pd.json_normalize(parsed, sep=\"__\")\n",
    "    # Name subkeys like attr_GoodForMeal__breakfast, attr_BusinessParking__garage, etc.\n",
    "    sub.columns = [f\"{c}__{k}\" for k in sub.columns]\n",
    "    biz = biz.drop(columns=[c]).join(sub)\n",
    "\n",
    "# Recompute attribute columns after expansion\n",
    "attr_cols = [c for c in biz.columns if c.startswith(\"attr_\")]\n",
    "\n",
    "# ------------------------\n",
    "# 2) Clean special categorical attributes\n",
    "# ------------------------\n",
    "if \"attr_WiFi\" in biz.columns:\n",
    "    wifi = biz[\"attr_WiFi\"].apply(norm_token)\n",
    "    wifi = wifi.map({\"no\":\"no\",\"free\":\"free\",\"paid\":\"paid\"}).astype(\"category\")\n",
    "    biz[\"attr_WiFi\"] = wifi\n",
    "\n",
    "if \"attr_Alcohol\" in biz.columns:\n",
    "    alc = biz[\"attr_Alcohol\"].apply(norm_token)\n",
    "    # normalize common variants\n",
    "    alc = alc.replace({\n",
    "        \"full_bar\":\"full_bar\",\n",
    "        \"full bar\":\"full_bar\",\n",
    "        \"beer_and_wine\":\"beer_and_wine\",\n",
    "        \"beer and wine\":\"beer_and_wine\",\n",
    "        \"none\":\"none\"\n",
    "    })\n",
    "    valid_alc = {\"none\",\"beer_and_wine\",\"full_bar\"}\n",
    "    alc = alc.where(alc.isin(valid_alc))\n",
    "    biz[\"attr_Alcohol\"] = alc.astype(\"category\")\n",
    "\n",
    "if \"attr_RestaurantsAttire\" in biz.columns:\n",
    "    attire = biz[\"attr_RestaurantsAttire\"].apply(norm_token)\n",
    "    attire = attire.replace({\"casual\":\"casual\",\"dressy\":\"dressy\",\"formal\":\"formal\"})\n",
    "    attire = attire.where(attire.isin({\"casual\",\"dressy\",\"formal\"}))\n",
    "    biz[\"attr_RestaurantsAttire\"] = attire.astype(\"category\")\n",
    "\n",
    "if \"attr_NoiseLevel\" in biz.columns:\n",
    "    noise = biz[\"attr_NoiseLevel\"].apply(norm_token)\n",
    "    noise = noise.where(noise.isin({\"quiet\",\"average\",\"loud\",\"very_loud\"}))\n",
    "    # keep as categorical; you can also map to ordered codes later if you prefer an ordinal\n",
    "    biz[\"attr_NoiseLevel\"] = noise.astype(\"category\")\n",
    "\n",
    "if \"attr_AgesAllowed\" in biz.columns:\n",
    "    ages = biz[\"attr_AgesAllowed\"].apply(norm_token)\n",
    "    # leave as categorical (values like '21plus','allages' appear)\n",
    "    biz[\"attr_AgesAllowed\"] = ages.astype(\"category\")\n",
    "\n",
    "# ------------------------\n",
    "# 3) Clean all remaining boolean-ish attribute columns to TRUE/FALSE/NaN\n",
    "# ------------------------\n",
    "# We exclude the special categorical ones we just handled above\n",
    "special_cats = {\"attr_WiFi\",\"attr_Alcohol\",\"attr_RestaurantsAttire\",\"attr_NoiseLevel\",\"attr_AgesAllowed\"}\n",
    "boolish_attr = [c for c in attr_cols if c not in special_cats]\n",
    "\n",
    "for c in boolish_attr:\n",
    "    # If column looks numeric-only (e.g. price range), skip boolean mapping\n",
    "    if pd.api.types.is_numeric_dtype(biz[c]):\n",
    "        continue\n",
    "    # Apply TRUE/FALSE/NaN mapping\n",
    "    biz[c] = biz[c].apply(to_TFN).astype(\"category\")\n",
    "\n",
    "# ------------------------\n",
    "# 4) (Optional) Numeric cast for a few known numeric attrs\n",
    "# ------------------------\n",
    "for c in [\"attr_RestaurantsPriceRange2\"]:\n",
    "    if c in biz.columns:\n",
    "        biz[c] = pd.to_numeric(biz[c], errors=\"coerce\").astype(\"Float32\")\n",
    "\n",
    "print(\"Done cleaning attributes.\")\n",
    "print(\"Example columns and categories:\")\n",
    "for c in [\"attr_WiFi\",\"attr_Alcohol\",\"attr_RestaurantsAttire\",\"attr_NoiseLevel\"]:\n",
    "    if c in biz.columns:\n",
    "        print(c, \"→\", list(biz[c].cat.categories) if pd.api.types.is_categorical_dtype(biz[c]) else \"not categorical\")\n",
    "\n",
    "# Save a cleaned copy (optional)\n",
    "out = RAW / \"3_yelp_business_flat_attr_formatted.csv\"\n",
    "biz.to_csv(out, index=False)\n",
    "print(\"Saved:\", out)\n",
    "\n",
    "biz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec57af",
   "metadata": {},
   "source": [
    "## Categories (Top 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e323d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top categories kept: ['Sandwiches', 'American (Traditional)', 'Pizza', 'Fast Food', 'Breakfast & Brunch', 'American (New)', 'Burgers', 'Mexican', 'Italian', 'Coffee & Tea', 'Seafood', 'Chinese', 'Salad', 'Chicken Wings', 'Cafes', 'Delis', 'Caterers', 'Specialty Food', 'Bakeries', 'Desserts']\n",
      "biz shape after cat features: (52268, 55)\n",
      "Saved: ../data/raw/4_yelp_business_top_category.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52268, 55)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Top-20 categories → tri-state features (1/0/NaN) ---\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Ensure we’re marking restaurants\n",
    "is_rest = biz[\"categories_norm\"].fillna(\"\").str.contains(r\"\\bRestaurants\\b\", case=False, regex=True)\n",
    "\n",
    "# 1) Split categories_norm into unique, trimmed labels (handle ';' or ',')\n",
    "def split_cats(val):\n",
    "    if pd.isna(val): \n",
    "        return None\n",
    "    parts = [p.strip() for p in re.split(r\"[;,]\", str(val)) if p.strip()]\n",
    "    return sorted(set(parts)) if parts else None\n",
    "\n",
    "cats_parsed = biz[\"categories_norm\"].map(split_cats)\n",
    "\n",
    "# 2) Filter out umbrella / non-food verticals for counting\n",
    "drop_umbrella = {\n",
    "    \"Restaurants\",\"Food\",\"Nightlife\",\"Bars\",\"Local Services\",\"Shopping\",\n",
    "    \"Event Planning & Services\",\"Active Life\",\"Hotels & Travel\",\"Health & Medical\",\n",
    "    \"Beauty & Spas\",\"Automotive\",\"Home Services\",\"Arts & Entertainment\",\n",
    "    \"Professional Services\"\n",
    "}\n",
    "drop_non_food = {\n",
    "    \"Pets\",\"Pet Services\",\"Real Estate\",\"Doctors\",\"Dentists\",\"Auto Repair\",\n",
    "    \"Home & Garden\",\"Fashion\",\"Hair Salons\",\"Nail Salons\",\"Medical Centers\",\n",
    "    \"Education\",\"Lawyers\",\"Financial Services\",\"Contractors\"\n",
    "}\n",
    "\n",
    "# 3) Count among restaurants only\n",
    "counts = Counter()\n",
    "for lst in cats_parsed[is_rest].dropna():\n",
    "    for c in lst:\n",
    "        if c not in drop_umbrella and c not in drop_non_food:\n",
    "            counts[c] += 1\n",
    "\n",
    "# 4) Keep Top-N deterministically\n",
    "TOP_N = 20\n",
    "kept_cats = [c for c, _ in sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))[:TOP_N]]\n",
    "print(\"Top categories kept:\", kept_cats)\n",
    "\n",
    "# (optional) save coverage table\n",
    "cov = (pd.Series(counts, name=\"count\")\n",
    "         .reindex(kept_cats)\n",
    "         .to_frame()\n",
    "         .assign(coverage_pct=lambda d: 100 * d[\"count\"] / is_rest.sum()))\n",
    "Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "cov.to_csv(\"../data/processed/top20_categories_coverage.csv\", index_label=\"category\")\n",
    "\n",
    "# 5) Build tri-state features: 1 present, 0 absent, NaN if categories missing for that row\n",
    "cat_feats = pd.DataFrame(index=biz.index)\n",
    "for k in kept_cats:\n",
    "    cat_feats[f\"cat__{k}\"] = cats_parsed.map(\n",
    "        lambda lst: np.nan if lst is None else (1.0 if k in lst else 0.0)\n",
    "    ).astype(\"Float32\")\n",
    "\n",
    "# 6) Join to your DataFrame (and optionally drop the raw text column)\n",
    "biz = pd.concat([biz, cat_feats], axis=1)\n",
    "biz = biz.drop(columns=[\"categories_norm\"])  # uncomment if you no longer need the raw text\n",
    "\n",
    "print(\"biz shape after cat features:\", biz.shape)\n",
    "\n",
    "# Save a cleaned copy (optional)\n",
    "out = RAW / \"4_yelp_business_top_category.csv\"\n",
    "biz.to_csv(out, index=False)\n",
    "print(\"Saved:\", out)\n",
    "biz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c33b02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28649240",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2215b00",
   "metadata": {},
   "source": [
    "Normalizes city + state.\n",
    "\n",
    "Builds city_slim (Top-20 vs “Other”).\n",
    "\n",
    "One-hot encodes into city_* columns.\n",
    "\n",
    "Drops the helper columns (city_clean, city_slim) so your modeling table only keeps the dummies.\n",
    "\n",
    "Saves the Top-20 list for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9207dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City dummies added: ['city_Boise', 'city_Brandon', 'city_Cherry Hill', 'city_Clearwater', 'city_Franklin', 'city_Indianapolis', 'city_Largo', 'city_Meridian', 'city_Metairie', 'city_Nashville', 'city_New Orleans', 'city_Other', 'city_Philadelphia', 'city_Reno', 'city_Saint Louis', 'city_Saint Petersburg', 'city_Santa Barbara', 'city_Sparks', 'city_Tampa', 'city_Tucson', 'city_Wilmington']\n",
      "Shape after city encoding: (52268, 76)\n",
      "Saved: ../data/raw/5_yelp_business_top_city.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52268, 76)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- US state codes ---\n",
    "US_STATES = {\n",
    "    'AL','AK','AZ','AR','CA','CO','CT','DC','DE','FL','GA','HI','IA','ID','IL','IN','KS','KY',\n",
    "    'LA','MA','MD','ME','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV','NY','OH',\n",
    "    'OK','OR','PA','RI','SC','SD','TN','TX','UT','VA','VT','WA','WI','WV','WY'\n",
    "}\n",
    "\n",
    "# --- normalize city/state ---\n",
    "norm_map = {\n",
    "    \"St. Louis\": \"Saint Louis\",\n",
    "    \"St Louis\": \"Saint Louis\",\n",
    "    \"St. Petersburg\": \"Saint Petersburg\",\n",
    "    \"St Petersburg\": \"Saint Petersburg\",\n",
    "}\n",
    "biz[\"city_clean\"] = biz[\"city\"].astype(str).str.strip().replace(norm_map)\n",
    "biz[\"state\"] = biz[\"state\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# --- compute Top-20 US cities ---\n",
    "us_mask = biz[\"state\"].isin(US_STATES)\n",
    "top20_us_cities = (\n",
    "    biz.loc[us_mask, \"city_clean\"]\n",
    "       .value_counts()\n",
    "       .head(20)\n",
    "       .index\n",
    ")\n",
    "\n",
    "# --- collapse others to \"Other\" ---\n",
    "biz[\"city_slim\"] = biz[\"city_clean\"].where(biz[\"city_clean\"].isin(top20_us_cities), \"Other\")\n",
    "biz[\"city_slim\"] = biz[\"city_slim\"].fillna(\"Other\")\n",
    "\n",
    "# --- create dummies ---\n",
    "city_ohe = pd.get_dummies(biz[\"city_slim\"], prefix=\"city\", dtype=np.float32)\n",
    "biz = pd.concat([biz, city_ohe], axis=1)\n",
    "\n",
    "# --- drop helper cols ---\n",
    "cols_to_drop = [c for c in [\"city_clean\", \"city_slim\"] if c in biz.columns]\n",
    "biz = biz.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"City dummies added:\", list(city_ohe.columns))\n",
    "print(\"Shape after city encoding:\", biz.shape)\n",
    "\n",
    "\n",
    "out = RAW / \"5_yelp_business_top_city.csv\" \n",
    "biz.to_csv(out, index=False) \n",
    "print(\"Saved:\", out) \n",
    "biz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bde1c5",
   "metadata": {},
   "source": [
    "## Create Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b811aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.api.types import (\n",
    "    is_numeric_dtype,\n",
    "    is_categorical_dtype,\n",
    "    is_object_dtype,\n",
    "    is_datetime64_any_dtype,\n",
    ")\n",
    "\n",
    "def _safe_nunique(s: pd.Series) -> int:\n",
    "    \"\"\"nunique that tolerates unhashable objects like dict/list/set.\"\"\"\n",
    "    try:\n",
    "        return s.nunique(dropna=True)\n",
    "    except TypeError:\n",
    "        # Convert unhashables to a stable string form then count\n",
    "        return (\n",
    "            s.dropna()\n",
    "             .apply(lambda x: json.dumps(x, sort_keys=True) if isinstance(x, (dict, list, set)) else x)\n",
    "             .nunique(dropna=True)\n",
    "        )\n",
    "\n",
    "def _safe_samples(s: pd.Series, k: int = 5):\n",
    "    \"\"\"Return up to k sample values, robust to unhashables.\"\"\"\n",
    "    try:\n",
    "        # If hashable, use unique() for a quick look\n",
    "        vals = s.dropna().head(1000).unique()\n",
    "        return list(vals[:k])\n",
    "    except TypeError:\n",
    "        # For unhashables (dict/list/set), stringify a few rows\n",
    "        return [json.dumps(v, sort_keys=True) if isinstance(v, (dict, list, set)) else str(v)\n",
    "                for v in s.dropna().head(k)]\n",
    "\n",
    "def create_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    meta = pd.DataFrame(index=df.columns)\n",
    "\n",
    "    # Core stats\n",
    "    meta[\"dtype\"]       = df.dtypes.astype(str)\n",
    "    meta[\"n_unique\"]    = [ _safe_nunique(df[c]) for c in df.columns ]\n",
    "    meta[\"missing_sum\"] = df.isna().sum()\n",
    "\n",
    "    # Type flags\n",
    "    meta[\"is_numeric\"]     = [is_numeric_dtype(df[c]) for c in df.columns]\n",
    "    meta[\"is_categorical\"] = [is_categorical_dtype(df[c]) for c in df.columns]\n",
    "    meta[\"is_string\"]      = [is_object_dtype(df[c]) for c in df.columns]  # note: includes dicts too\n",
    "    meta[\"is_datetime\"]    = [is_datetime64_any_dtype(df[c]) for c in df.columns]\n",
    "\n",
    "    # Min / Max only for numeric or datetime\n",
    "    mins, maxs = {}, {}\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            if is_datetime64_any_dtype(df[c]) or is_numeric_dtype(df[c]):\n",
    "                mins[c] = df[c].min()\n",
    "                maxs[c] = df[c].max()\n",
    "            else:\n",
    "                mins[c], maxs[c] = None, None\n",
    "        except Exception:\n",
    "            mins[c], maxs[c] = None, None\n",
    "    meta[\"min_value\"] = pd.Series(mins)\n",
    "    meta[\"max_value\"] = pd.Series(maxs)\n",
    "\n",
    "    # Sample values (robust to unhashables)\n",
    "    samples = { c: _safe_samples(df[c], k=5) for c in df.columns }\n",
    "    meta[\"sample_values\"] = pd.Series(samples)\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19d4b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/1688460008.py:43: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  meta[\"is_categorical\"] = [is_categorical_dtype(df[c]) for c in df.columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meta_business = create_metadata(biz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81927d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../data/processed/6_business_metadata_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Save metadata DataFrame to CSV\n",
    "from pathlib import Path\n",
    "PROCESSED = Path(\"../data/processed\"); PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "meta_business.to_csv(PROCESSED / \"6_business_metadata_report.csv\", index=True)\n",
    "print(\"Saved to\", PROCESSED / \"6_business_metadata_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4641af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db323fbc",
   "metadata": {},
   "source": [
    "# Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "241bd549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2111695, 9)\n",
      "Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny',\n",
      "       'cool', 'text', 'date'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111695 entries, 0 to 2111694\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   review_id    object        \n",
      " 1   user_id      object        \n",
      " 2   business_id  object        \n",
      " 3   stars        int64         \n",
      " 4   useful       int64         \n",
      " 5   funny        int64         \n",
      " 6   cool         int64         \n",
      " 7   text         object        \n",
      " 8   date         datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(4), object(4)\n",
      "memory usage: 145.0+ MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RAW = Path(\"../data/raw\")\n",
    "review_df_2019 = pd.read_json(RAW / \"yelp_reviews_2019_latest.json\", lines=True)\n",
    "\n",
    "print(review_df_2019.shape)       # rows, columns\n",
    "print(review_df_2019.columns)     # column names\n",
    "review_df_2019.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fcacaafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "# from IPython.display import display  # for display()\n",
    "\n",
    "# RAW = Path(\"../data/raw\")\n",
    "# rev_path = RAW / \"yelp_reviews_2019_latest.json\"  # change to .json.gz if needed\n",
    "# assert rev_path.exists(), f\"File not found: {rev_path}\"\n",
    "\n",
    "# read_kwargs = dict(lines=True)\n",
    "# if rev_path.suffix == \".gz\":\n",
    "#     read_kwargs[\"compression\"] = \"gzip\"\n",
    "\n",
    "# review_df_2019 = pd.read_json(rev_path, **read_kwargs)\n",
    "\n",
    "# print(\"Loaded from:\", rev_path)\n",
    "# print(\"Shape:\", review_df_2019.shape)\n",
    "# print(\"Columns:\", review_df_2019.columns.tolist())\n",
    "# display(review_df_2019.head())\n",
    "\n",
    "# # make sure 'date' is datetime\n",
    "# review_df_2019[\"date\"] = pd.to_datetime(review_df_2019[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# print(\"\\nMissing values per column:\\n\", review_df_2019.isna().sum())\n",
    "# print(\"\\nNumeric summary:\\n\", review_df_2019.select_dtypes(\"number\").describe())\n",
    "\n",
    "# # (optional) quick year sanity check\n",
    "# if \"date\" in review_df_2019:\n",
    "#     yrs = review_df_2019[\"date\"].dt.year.dropna()\n",
    "#     if not yrs.empty:\n",
    "#         print(\"\\nYear range:\", int(yrs.min()), \"→\", int(yrs.max()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e320eb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2111712\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/raw/yelp_reviews_2019_latest.json\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    row_count = sum(1 for _ in f)\n",
    "\n",
    "print(\"Total rows:\", row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "152cf04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After converting some int columns to category:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111695 entries, 0 to 2111694\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   review_id    object        \n",
      " 1   user_id      object        \n",
      " 2   business_id  object        \n",
      " 3   stars        category      \n",
      " 4   useful       int64         \n",
      " 5   funny        int64         \n",
      " 6   cool         int64         \n",
      " 7   text         object        \n",
      " 8   date         datetime64[ns]\n",
      "dtypes: category(1), datetime64[ns](1), int64(3), object(4)\n",
      "memory usage: 130.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Function: Coerce integer-encoded features to categorical if few unique values\n",
    "def int_to_categorical(df, max_unique_values=10):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.select_dtypes(include=[\"int64\", \"int32\"]).columns:\n",
    "        n_unique = df_copy[col].nunique()\n",
    "        if n_unique <= max_unique_values:\n",
    "            df_copy[col] = df_copy[col].astype(\"category\")\n",
    "    return df_copy\n",
    "\n",
    "# Apply to review dataset\n",
    "review2019_df_cat = int_to_categorical(review_df_2019)\n",
    "print(\"\\nAfter converting some int columns to category:\")\n",
    "review2019_df_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c70bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a20c8b",
   "metadata": {},
   "source": [
    "## Create metadata review 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b654874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/1688460008.py:43: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  meta[\"is_categorical\"] = [is_categorical_dtype(df[c]) for c in df.columns]\n"
     ]
    }
   ],
   "source": [
    "review2019_metadata_report = create_metadata(review2019_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed661396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../data/processed/7_review2019_metadata_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Save metadata DataFrame to CSV\n",
    "from pathlib import Path\n",
    "PROCESSED = Path(\"../data/processed\")\n",
    "review2019_metadata_report.to_csv(PROCESSED / \"7_review2019_metadata_report.csv\", index=True)\n",
    "print(\"Saved to\", PROCESSED / \"7_review2019_metadata_report.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0662a910",
   "metadata": {},
   "source": [
    "## Aggregate review 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef507846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # --- 1) Aggregate 2019 reviews to business-level targets ---\n",
    "# rev_tmp = review2019_df_cat[[\"business_id\", \"stars\", \"date\"]].copy()\n",
    "# rev_tmp[\"stars_num\"] = pd.to_numeric(rev_tmp[\"stars\"], errors=\"coerce\")\n",
    "# rev_tmp[\"date\"]      = pd.to_datetime(rev_tmp[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# agg19 = (rev_tmp.dropna(subset=[\"stars_num\"])\n",
    "#                .groupby(\"business_id\", as_index=False)\n",
    "#                .agg(\n",
    "#                    rev_count_2019=(\"stars_num\",\"size\"),\n",
    "#                    avg_stars_2019=(\"stars_num\",\"mean\"),\n",
    "#                    first_review_2019=(\"date\",\"min\"),\n",
    "#                    last_review_2019=(\"date\",\"max\"),\n",
    "#                ))\n",
    "\n",
    "# # Optional: keep only businesses with enough 2019 reviews\n",
    "# MIN_REV = 3     # use 1/3/5 depending on coverage you want\n",
    "# agg19 = agg19[agg19[\"rev_count_2019\"] >= MIN_REV].copy()\n",
    "\n",
    "# # Set dtypes for NEW cols only (does NOT touch business_df dtypes)\n",
    "# agg19[\"rev_count_2019\"] = agg19[\"rev_count_2019\"].astype(\"int32\")\n",
    "# agg19[\"avg_stars_2019\"] = agg19[\"avg_stars_2019\"].astype(\"float32\")\n",
    "\n",
    "# # --- 2) Merge with your business features (keeps business_df dtypes) ---\n",
    "# assert biz[\"business_id\"].is_unique\n",
    "# Xy19 = biz.merge(agg19, on=\"business_id\", how=\"inner\", validate=\"one_to_one\")\n",
    "# print(\"Joined rows:\", len(Xy19))\n",
    "# display(Xy19.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef29ec8",
   "metadata": {},
   "source": [
    "## add review word length "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a70be2",
   "metadata": {},
   "source": [
    "rl_share_long200w is one of the aggregate features you created when you added review length signals at the business level.\n",
    "\n",
    "Let’s break it down:\n",
    "\n",
    "rl → shorthand for review length\n",
    "\n",
    "share → proportion (a fraction between 0 and 1)\n",
    "\n",
    "long200w → reviews that are “long,” defined as having ≥ 200 words\n",
    "\n",
    "So:\n",
    "\n",
    "\\text{rl\\_share\\_long200w for business X} \\;=\\; \\frac{\\text{# of reviews with ≥200 words for business X in 2019}}{\\text{total # of 2019 reviews for business X}}\n",
    "\n",
    "Example:\n",
    "\n",
    "If a restaurant had 20 reviews in 2019\n",
    "\n",
    "Out of those, 5 reviews had ≥200 words\n",
    "\n",
    "Then rl_share_long200w = 5 / 20 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1c3bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Start from your review df (already loaded as review2019_df_cat) ---\n",
    "rev_tmp = review2019_df_cat[[\"business_id\", \"stars\", \"date\", \"text\"]].copy()\n",
    "rev_tmp[\"stars_num\"] = pd.to_numeric(rev_tmp[\"stars\"], errors=\"coerce\")\n",
    "rev_tmp[\"date\"]      = pd.to_datetime(rev_tmp[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# --- Per-review length (words) and short flag ---\n",
    "text_s = rev_tmp[\"text\"].astype(str)                                # guard against NaN\n",
    "rev_tmp[\"len_word\"] = text_s.str.count(r\"\\b\\w+\\b\").astype(\"Int32\")  # word count\n",
    "rev_tmp[\"is_short24\"] = (rev_tmp[\"len_word\"] <= 24).astype(\"Int8\")  # short review flag\n",
    "\n",
    "# --- Aggregate to business level (add the two features you want) ---\n",
    "agg19 = (\n",
    "    rev_tmp.dropna(subset=[\"stars_num\"])\n",
    "           .groupby(\"business_id\", as_index=False)\n",
    "           .agg(\n",
    "               rev_count_2019    = (\"stars_num\",\"size\"),\n",
    "               avg_stars_2019    = (\"stars_num\",\"mean\"),\n",
    "               first_review_2019 = (\"date\",\"min\"),\n",
    "               last_review_2019  = (\"date\",\"max\"),\n",
    "\n",
    "               # the two new features:\n",
    "               rl_word_mean      = (\"len_word\",\"mean\"),\n",
    "               rl_share_short24  = (\"is_short24\",\"mean\"),   # <-- consistent name\n",
    "           )\n",
    ")\n",
    "\n",
    "# --- Stability filter & dtypes (same as your pipeline) ---\n",
    "MIN_REV = 3\n",
    "agg19 = agg19.loc[agg19[\"rev_count_2019\"] >= MIN_REV].copy()\n",
    "\n",
    "agg19[\"rev_count_2019\"]   = agg19[\"rev_count_2019\"].astype(\"int32\")\n",
    "agg19[\"avg_stars_2019\"]   = agg19[\"avg_stars_2019\"].astype(\"float32\")\n",
    "agg19[\"rl_word_mean\"]     = agg19[\"rl_word_mean\"].astype(\"float32\")\n",
    "agg19[\"rl_share_short24\"] = agg19[\"rl_share_short24\"].astype(\"float32\")\n",
    "\n",
    "# --- Merge with business features (unchanged) ---\n",
    "assert biz[\"business_id\"].is_unique\n",
    "Xy19 = biz.merge(agg19, on=\"business_id\", how=\"inner\", validate=\"one_to_one\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7b55bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/processed/8_biz_merged_2019.csv\n"
     ]
    }
   ],
   "source": [
    "# Save BEFORE EDA & BEFORE IMPUTATION (correct)\n",
    "PROC = Path(\"../data/processed\"); PROC.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = PROC / \"8_biz_merged_2019.csv\"\n",
    "Xy19.to_csv(csv_path, index=False)\n",
    "print(\"Saved:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b620ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 18.333334\n",
      "Max: 540.5\n",
      "count    36261.000000\n",
      "mean        88.404472\n",
      "std         28.092167\n",
      "min         18.333334\n",
      "25%         70.428574\n",
      "50%         85.000000\n",
      "75%        102.000000\n",
      "max        540.500000\n",
      "Name: rl_word_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# If you want just min and max:\n",
    "print(\"Min:\", Xy19[\"rl_word_mean\"].min())\n",
    "print(\"Max:\", Xy19[\"rl_word_mean\"].max())\n",
    "\n",
    "# Or use describe() for more stats:\n",
    "print(Xy19[\"rl_word_mean\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5adc8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th percentile (short): 24.0\n",
      "90th percentile (long): 200.0\n"
     ]
    }
   ],
   "source": [
    "# Compute per-review word counts\n",
    "rev_tmp[\"len_word\"] = rev_tmp[\"text\"].astype(str).str.count(r\"\\b\\w+\\b\")\n",
    "\n",
    "# Check distribution & find 90th percentile\n",
    "long_cutoff = rev_tmp[\"len_word\"].quantile(0.90)\n",
    "short_cutoff = rev_tmp[\"len_word\"].quantile(0.10)\n",
    "\n",
    "print(\"10th percentile (short):\", short_cutoff)\n",
    "print(\"90th percentile (long):\", long_cutoff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d677b8f",
   "metadata": {},
   "source": [
    "short cut off is 10% cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68658849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'city', 'state', 'latitude', 'longitude', 'review_count',\n",
       "       'is_open', 'review_count_log1p', 'attr_ByAppointmentOnly',\n",
       "       'attr_BusinessAcceptsCreditCards', 'attr_BikeParking',\n",
       "       'attr_RestaurantsPriceRange2', 'attr_RestaurantsTakeOut',\n",
       "       'attr_RestaurantsDelivery', 'attr_Caters', 'attr_WiFi',\n",
       "       'attr_WheelchairAccessible', 'attr_HappyHour', 'attr_OutdoorSeating',\n",
       "       'attr_HasTV', 'attr_RestaurantsReservations', 'attr_DogsAllowed',\n",
       "       'attr_Alcohol', 'attr_GoodForKids', 'attr_RestaurantsAttire',\n",
       "       'attr_RestaurantsTableService', 'attr_RestaurantsGoodForGroups',\n",
       "       'attr_DriveThru', 'attr_NoiseLevel', 'attr_Smoking',\n",
       "       'total_weekly_hours', 'days_open', 'weekend_hours', 'avg_daily_hours',\n",
       "       'has_hours_info', 'cat__Sandwiches', 'cat__American (Traditional)',\n",
       "       'cat__Pizza', 'cat__Fast Food', 'cat__Breakfast & Brunch',\n",
       "       'cat__American (New)', 'cat__Burgers', 'cat__Mexican', 'cat__Italian',\n",
       "       'cat__Coffee & Tea', 'cat__Seafood', 'cat__Chinese', 'cat__Salad',\n",
       "       'cat__Chicken Wings', 'cat__Cafes', 'cat__Delis', 'cat__Caterers',\n",
       "       'cat__Specialty Food', 'cat__Bakeries', 'cat__Desserts', 'city_Boise',\n",
       "       'city_Brandon', 'city_Cherry Hill', 'city_Clearwater', 'city_Franklin',\n",
       "       'city_Indianapolis', 'city_Largo', 'city_Meridian', 'city_Metairie',\n",
       "       'city_Nashville', 'city_New Orleans', 'city_Other', 'city_Philadelphia',\n",
       "       'city_Reno', 'city_Saint Louis', 'city_Saint Petersburg',\n",
       "       'city_Santa Barbara', 'city_Sparks', 'city_Tampa', 'city_Tucson',\n",
       "       'city_Wilmington', 'rev_count_2019', 'avg_stars_2019',\n",
       "       'first_review_2019', 'last_review_2019', 'rl_word_mean',\n",
       "       'rl_share_short24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy19.columns  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae0f17",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "Normalize text (case/spacing/variants)\n",
    "\n",
    "Map your specified attributes to consistent numeric codes\n",
    "\n",
    "Keep missing values as <NA> (nullable integers)\n",
    "\n",
    "Save the result to ../data/processed/biz_merge.csv\n",
    "\n",
    "I followed your exact mappings:\n",
    "\n",
    "Booleans (False, True) → 1, 2\n",
    "\n",
    "attr_WiFi: free, no, paid → 1, 2, 3\n",
    "\n",
    "attr_RestaurantsAttire: casual, formal, dressy → 1, 2, 3\n",
    "\n",
    "attr_NoiseLevel: average, quiet, loud, very loud → 1, 2, 3, 4 (your order)\n",
    "\n",
    "attr_Alcohol: full bar, beer and wine → 1, 2\n",
    "\n",
    "If a value doesn’t match the mapping after normalization, it becomes <NA>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58c07d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_ByAppointmentOnly:\n",
      "attr_ByAppointmentOnly\n",
      "0    33122\n",
      "1     3032\n",
      "2      107\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_BusinessAcceptsCreditCards:\n",
      "attr_BusinessAcceptsCreditCards\n",
      "0     4889\n",
      "1      812\n",
      "2    30560\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_BikeParking:\n",
      "attr_BikeParking\n",
      "0     9408\n",
      "1     6942\n",
      "2    19911\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_RestaurantsTakeOut:\n",
      "attr_RestaurantsTakeOut\n",
      "0     3074\n",
      "1     1323\n",
      "2    31864\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_RestaurantsDelivery:\n",
      "attr_RestaurantsDelivery\n",
      "0     4898\n",
      "1     8590\n",
      "2    22773\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_Caters:\n",
      "attr_Caters\n",
      "0    10665\n",
      "1    10248\n",
      "2    15348\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_WheelchairAccessible:\n",
      "attr_WheelchairAccessible\n",
      "0    24474\n",
      "1      847\n",
      "2    10940\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_HappyHour:\n",
      "attr_HappyHour\n",
      "0    25391\n",
      "1     4256\n",
      "2     6614\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_OutdoorSeating:\n",
      "attr_OutdoorSeating\n",
      "0     7938\n",
      "1    14250\n",
      "2    14073\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_HasTV:\n",
      "attr_HasTV\n",
      "0     6543\n",
      "1     5692\n",
      "2    24026\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_RestaurantsReservations:\n",
      "attr_RestaurantsReservations\n",
      "0     6953\n",
      "1    19942\n",
      "2     9366\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_DogsAllowed:\n",
      "attr_DogsAllowed\n",
      "0    25718\n",
      "1     8039\n",
      "2     2504\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_GoodForKids:\n",
      "attr_GoodForKids\n",
      "0     9158\n",
      "1     3426\n",
      "2    23677\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_RestaurantsTableService:\n",
      "attr_RestaurantsTableService\n",
      "0    19729\n",
      "1     5823\n",
      "2    10709\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_RestaurantsGoodForGroups:\n",
      "attr_RestaurantsGoodForGroups\n",
      "0     8730\n",
      "1     3724\n",
      "2    23807\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_DriveThru:\n",
      "attr_DriveThru\n",
      "0    31014\n",
      "1     2059\n",
      "2     3188\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_Smoking:\n",
      "attr_Smoking\n",
      "0    34446\n",
      "1     1698\n",
      "2      117\n",
      "Name: count, dtype: Int64 \n",
      "\n",
      "attr_RestaurantsPriceRange2:\n",
      "attr_RestaurantsPriceRange2\n",
      "0.0     6589\n",
      "1.0    13145\n",
      "2.0    15485\n",
      "3.0      938\n",
      "4.0      104\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "attr_WiFi:\n",
      "attr_WiFi\n",
      "0.0     8736\n",
      "1.0    15631\n",
      "2.0    11728\n",
      "3.0      166\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "attr_RestaurantsAttire:\n",
      "attr_RestaurantsAttire\n",
      "0.0    10843\n",
      "1.0    24913\n",
      "2.0       44\n",
      "3.0      461\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "attr_NoiseLevel:\n",
      "attr_NoiseLevel\n",
      "0.0    12587\n",
      "1.0    17681\n",
      "2.0     3910\n",
      "3.0     1612\n",
      "4.0      471\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "attr_Alcohol:\n",
      "attr_Alcohol\n",
      "0.0    22886\n",
      "1.0     9328\n",
      "2.0     4047\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Saved: ../data/processed/9_biz_merged_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "def norm_token(x):\n",
    "    \"\"\"Lowercase, trim, collapse whitespace/underscores; None for empty/none-ish.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip().strip(\"'\\\"\")\n",
    "    s = s.replace(\"u'\", \"'\")\n",
    "    s = s.replace(\"_\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).lower().strip()\n",
    "    if s in {\"\", \"none\", \"null\", \"nan\"}:\n",
    "        return None\n",
    "    return s\n",
    "\n",
    "def map_bool_012(x):\n",
    "    \"\"\"NaN/unknown -> 0, falsey -> 1, truey -> 2.\"\"\"\n",
    "    t = norm_token(x)\n",
    "    if t is None:\n",
    "        return 0\n",
    "    if t in {\"false\",\"f\",\"no\",\"n\",\"0\"}:\n",
    "        return 1\n",
    "    if t in {\"true\",\"t\",\"yes\",\"y\",\"1\"}:\n",
    "        return 2\n",
    "    # raw numerics that slipped through\n",
    "    if t.isdigit():\n",
    "        v = int(t)\n",
    "        if v == 0: return 1\n",
    "        if v == 1: return 2\n",
    "    return 0  # unexpected -> treat as unknown\n",
    "\n",
    "# ----------------- columns -----------------\n",
    "bool_cols = [\n",
    "    'attr_ByAppointmentOnly','attr_BusinessAcceptsCreditCards','attr_BikeParking',\n",
    "    'attr_RestaurantsTakeOut','attr_RestaurantsDelivery','attr_Caters',\n",
    "    'attr_WheelchairAccessible','attr_HappyHour','attr_OutdoorSeating','attr_HasTV',\n",
    "    'attr_RestaurantsReservations','attr_DogsAllowed','attr_GoodForKids',\n",
    "    'attr_RestaurantsTableService','attr_RestaurantsGoodForGroups','attr_DriveThru',\n",
    "    'attr_Smoking'\n",
    "]\n",
    "\n",
    "# mappings for multi-class attrs (include common variants)\n",
    "wifi_map = {\"free\": 1, \"no\": 2, \"paid\": 3}\n",
    "attire_map = {\"casual\": 1, \"formal\": 2, \"dressy\": 3}\n",
    "noise_map = {\"average\": 1, \"quiet\": 2, \"loud\": 3, \"very loud\": 4, \"very_loud\": 4}\n",
    "alcohol_map = {\n",
    "    \"full bar\": 1, \"fullbar\": 1, \"full_bar\": 1,\n",
    "    \"beer and wine\": 2, \"beer_and_wine\": 2, \"beer & wine\": 2, \"beer and wind\": 2  # handles the typo\n",
    "}\n",
    "\n",
    "# ----------------- apply to Xy19 -----------------\n",
    "df = Xy19.copy()\n",
    "\n",
    "# 1) boolean-like → 0/1/2\n",
    "for col in bool_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(map_bool_012).astype(\"Int8\")\n",
    "\n",
    "# 2) RestaurantsPriceRange2 → 0–4 (0 for missing)\n",
    "if \"attr_RestaurantsPriceRange2\" in df.columns:\n",
    "    pr = pd.to_numeric(df[\"attr_RestaurantsPriceRange2\"], errors=\"coerce\")\n",
    "    pr = pr.where(pr.isin([1,2,3,4]))\n",
    "    df[\"attr_RestaurantsPriceRange2\"] = pr.fillna(0).astype(\"float32\")\n",
    "\n",
    "# 3) WiFi → 0(no value)/1/2/3\n",
    "if \"attr_WiFi\" in df.columns:\n",
    "    df[\"attr_WiFi\"] = df[\"attr_WiFi\"].map(lambda v: wifi_map.get(norm_token(v), 0)).astype(\"float32\")\n",
    "\n",
    "# 4) RestaurantsAttire → 0/1/2/3\n",
    "if \"attr_RestaurantsAttire\" in df.columns:\n",
    "    df[\"attr_RestaurantsAttire\"] = df[\"attr_RestaurantsAttire\"].map(\n",
    "        lambda v: attire_map.get(norm_token(v), 0)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "# 5) NoiseLevel → 0/1/2/3/4\n",
    "if \"attr_NoiseLevel\" in df.columns:\n",
    "    df[\"attr_NoiseLevel\"] = df[\"attr_NoiseLevel\"].map(\n",
    "        lambda v: noise_map.get(norm_token(v), 0)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "# 6) Alcohol → 0/1/2\n",
    "if \"attr_Alcohol\" in df.columns:\n",
    "    df[\"attr_Alcohol\"] = df[\"attr_Alcohol\"].map(\n",
    "        lambda v: alcohol_map.get(norm_token(v), 0)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "# ----------------- (optional) quick sanity check -----------------\n",
    "check_cols = (\n",
    "    bool_cols\n",
    "    + [c for c in [\"attr_RestaurantsPriceRange2\",\"attr_WiFi\",\"attr_RestaurantsAttire\",\"attr_NoiseLevel\",\"attr_Alcohol\"] if c in df.columns]\n",
    ")\n",
    "for c in check_cols:\n",
    "    vc = df[c].value_counts(dropna=False).sort_index()\n",
    "    print(f\"{c}:\")\n",
    "    print(vc, \"\\n\")\n",
    "\n",
    "# Now df has consistent numeric codes for the attributes you listed\n",
    "\n",
    "\n",
    "# Save\n",
    "OUT = Path(\"../data/processed\") / \"9_biz_merged_normalized.csv\"\n",
    "OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUT, index=False)\n",
    "print(\"Saved:\", OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e9573",
   "metadata": {},
   "source": [
    "## This file creates merge business file and review files \n",
    "\n",
    "We build our dataset from the Yelp Open Dataset (2024 mirror), focusing on food venues identified through the categories field and excluding the stars column to prevent label leakage. From business.json, we derive structured features: (i) numerical variables such as review_count, its log transform, is_open, latitude, longitude, and weekly_open_hours (parsed from JSON); (ii) selected high-coverage attributes (e.g., RestaurantsReservations, OutdoorSeating, BusinessAcceptsCreditCards, BikeParking, GoodForKids, RestaurantsDelivery, RestaurantsTakeOut, WheelchairAccessible, HasTV, DogsAllowed), represented as binary indicators with missing values preserved as NaN; (iii) categorical indicators for the top 20 cuisine/venue labels after removing umbrella tags, encoded as 1 (present), 0 (absent), or NaN (if the entire field is missing), along with an optional missingness flag; and (iv) geographic features, including normalized city names and one-hot encodings of the 20 most common U.S. cities, with other cities collapsed into “Other.”\n",
    "\n",
    "We then aggregate reviews from a pre-extracted 2019 subset to compute business-level targets: average star rating, review count, and first/last review dates, applying a minimum threshold of three reviews per business. Check-in records are similarly summarized as totals, unique days, and temporal spans. All features are merged on business_id to form the modeling table (biz_merged_2019.csv). Missing values are deliberately preserved and handled later in the modeling pipeline (e.g., imputing binary features to 0, continuous features to the median or group-wise statistics). Numeric variables are stored as float32, while identifiers and dates are retained only for joins and reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad46e49",
   "metadata": {},
   "source": [
    "## Review Dataset\n",
    "\n",
    "We use reviews from the Yelp Open Dataset (2019 subset). The raw review file (`yelp_reviews_2019_latest.json`) is loaded in JSON lines format, with gzip compression support if required. We ensure the `date` field is parsed as a datetime object, and we check for missing values and basic statistics. Integer-encoded fields with few unique values are optionally coerced to categorical type for efficiency. We preserve missing values in the raw review data, deferring imputation and handling to the modeling pipeline.  \n",
    "\n",
    "We create a metadata report for the review dataset to summarize column data types, unique value counts, missingness, and sample values. At the business level, we aggregate reviews by `business_id` to compute labels and activity signals: total 2019 review count (`rev_count_2019`), average 2019 star rating (`avg_stars_2019`), and first/last review dates (`first_review_2019`, `last_review_2019`). We apply a stability rule requiring `MIN_REV ≥ 3` reviews per business to ensure reliable targets. Aggregated review features are stored as float32 for consistency.  \n",
    "\n",
    "The resulting business-level aggregates are merged with the engineered business feature table on `business_id` to produce the final modeling dataset (`biz_merged_2019.csv`). Identifiers and dates are retained only for joins and reporting, not as model inputs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a35f7",
   "metadata": {},
   "source": [
    "### To quick count where losing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "764cb1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/2955945496.py:10: DtypeWarning: Columns (44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  biz = pd.read_csv(RAW / \"1_yelp_business_flat.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business.json rows: 150346\n",
      "after Restaurants-only filter: 52268\n",
      "after Restaurants+Food filter: 64616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/bfn4zmvj11j3519tmtl4xcd40000gn/T/ipykernel_23648/2955945496.py:24: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  is_food_or_rest = biz[\"categories_norm\"].fillna(\"\").str.contains(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique business_ids in agg19: 97861\n",
      "inner join rows: 36261\n",
      "left  join rows: 52268  (NaN targets: 16007 )\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW = Path(\"../data/raw\")\n",
    "PROC = Path(\"../data/processed\")\n",
    "\n",
    "# --- 1) Business table with categories_norm ---\n",
    "# Use the flattened CSV you saved earlier (adjust name if yours differs)\n",
    "biz = pd.read_csv(RAW / \"1_yelp_business_flat.csv\")\n",
    "\n",
    "# Simple sanity check\n",
    "assert \"business_id\" in biz.columns, \"business_id missing in biz\"\n",
    "assert \"categories_norm\" in biz.columns, \"categories_norm missing in biz\"\n",
    "\n",
    "# --- 2) Raw business row count (from JSON) ---\n",
    "biz0 = pd.read_json(RAW / \"yelp_academic_dataset_business.json\", lines=True)\n",
    "print(\"business.json rows:\", len(biz0))\n",
    "\n",
    "# --- 3) Filters: Restaurants-only vs Restaurants+Food ---\n",
    "is_restaurants_only = biz[\"categories_norm\"].fillna(\"\").str.contains(r\"\\bRestaurants\\b\", case=False, regex=True)\n",
    "\n",
    "# broader scope similar to your classmate’s description\n",
    "is_food_or_rest = biz[\"categories_norm\"].fillna(\"\").str.contains(\n",
    "    r\"\\b(Restaurants|Food|Cafes|Bakeries|Coffee & Tea|Delis|Desserts)\\b\",\n",
    "    case=False, regex=True\n",
    ")\n",
    "\n",
    "print(\"after Restaurants-only filter:\", int(is_restaurants_only.sum()))\n",
    "print(\"after Restaurants+Food filter:\", int(is_food_or_rest.sum()))\n",
    "\n",
    "# choose which scope to use downstream:\n",
    "biz_scoped = biz.loc[is_restaurants_only].copy()       # OR use is_food_or_rest\n",
    "\n",
    "# --- 4) Build 2019 review aggregate with MIN_REV >= 3 ---\n",
    "rev_path = RAW / \"yelp_reviews_2019_latest.json\"   # update if your file name differs\n",
    "read_kwargs = dict(lines=True)\n",
    "if rev_path.suffix == \".gz\":\n",
    "    read_kwargs[\"compression\"] = \"gzip\"\n",
    "\n",
    "reviews = pd.read_json(rev_path, **read_kwargs)\n",
    "reviews[\"stars_num\"] = pd.to_numeric(reviews[\"stars\"], errors=\"coerce\")\n",
    "reviews[\"date\"]      = pd.to_datetime(reviews[\"date\"], errors=\"coerce\")\n",
    "\n",
    "agg19 = (reviews.dropna(subset=[\"stars_num\"])\n",
    "                 .groupby(\"business_id\", as_index=False)\n",
    "                 .agg(\n",
    "                     rev_count_2019=(\"stars_num\",\"size\"),\n",
    "                     avg_stars_2019=(\"stars_num\",\"mean\"),\n",
    "                     first_review_2019=(\"date\",\"min\"),\n",
    "                     last_review_2019=(\"date\",\"max\"),\n",
    "                 ))\n",
    "\n",
    "MIN_REV = 3\n",
    "agg19 = agg19.loc[agg19[\"rev_count_2019\"] >= MIN_REV].copy()\n",
    "\n",
    "print(\"unique business_ids in agg19:\", agg19[\"business_id\"].nunique())\n",
    "\n",
    "# --- 5) Join type effect ---\n",
    "m_inner = biz_scoped.merge(agg19, on=\"business_id\", how=\"inner\", validate=\"one_to_one\")\n",
    "m_left  = biz_scoped.merge(agg19, on=\"business_id\", how=\"left\")\n",
    "\n",
    "print(\"inner join rows:\", len(m_inner))\n",
    "print(\"left  join rows:\", len(m_left), \" (NaN targets:\", m_left[\"avg_stars_2019\"].isna().sum(), \")\")\n",
    "\n",
    "# Optional: save the inner-join modeling table\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "m_inner.to_csv(PROC / \"biz_merged_2019_inner.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63fbd5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants in scope: 52268\n",
      "With ≥3 reviews (inner): 36261\n",
      "Dropped due to no target: 16007\n"
     ]
    }
   ],
   "source": [
    "print(\"Restaurants in scope:\", len(biz_scoped))\n",
    "print(\"With ≥3 reviews (inner):\", len(m_inner))\n",
    "print(\"Dropped due to no target:\", len(biz_scoped) - len(m_inner))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9b64a",
   "metadata": {},
   "source": [
    "## Which join to use?\n",
    "\n",
    "Inner join\n",
    "✅ Best for supervised modeling (predicting ratings, finding feature importances).\n",
    "You only keep businesses where the target (average stars) is actually defined.\n",
    "→ That’s why you see ~36k rows.\n",
    "\n",
    "Left join\n",
    "Useful if you want to keep the entire restaurant universe for EDA or for later prediction on new businesses with no reviews yet.\n",
    "But those 16k rows with NaN labels can’t be used for training supervised models.\n",
    "\n",
    "Outer join\n",
    "Rarely useful here — would just add even more NaNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc4467",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323dc36-8349-44ee-8df4-c84853c158b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = Path(\"/Users/yenkopro/Desktop/Metadata_Yelp\")\n",
    "PATH = BASE / \"11_biz_merged_clean.parquet\"\n",
    "\n",
    "\n",
    "if not PATH.exists():\n",
    "    print(\"Parquet file not found at:\", PATH)\n",
    "    print(\"Parquet files in the folder:\")\n",
    "    for p in BASE.glob(\"*.parquet\"):\n",
    "        print(\"  -\", p.name)\n",
    "    raise FileNotFoundError(PATH)\n",
    "\n",
    "\n",
    "df = pd.read_parquet(PATH)  # or: pd.read_parquet(PATH, engine=\"pyarrow\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39099e4-728e-40b7-a6a5-0ec58b71ecb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208c85a-92ed-4565-974d-a49e659bdd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- load your business-level table (with business_id) ---\n",
    "PATH = \"/Users/yenkopro/Desktop/Metadata_Yelp/11_biz_merged_clean.parquet\"\n",
    "df = pd.read_parquet(PATH)\n",
    "\n",
    "# drop columns that are entirely missing (avoids imputer warnings like attr_Smoking)\n",
    "all_null = [c for c in df.columns if df[c].isna().all()]\n",
    "if all_null:\n",
    "    df = df.drop(columns=all_null)\n",
    "\n",
    "# columns we should NEVER use as features\n",
    "ban = {\n",
    "    \"business_id\", \"name\", \"address\", \"postal_code\", \"phone\",\n",
    "    # any labels / leak-prone targets if present\n",
    "    \"avg_stars_2019\", \"avg_stars\", \"stars\", \"rev_count_2019\",\n",
    "    \"y_cls\", \"label\", \"target\", \"y_reg\", \"label_reg\",\n",
    "    # free-text or raw nested if present\n",
    "    \"categories\", \"hours\"\n",
    "}\n",
    "feat_cols = [c for c in df.columns if c not in ban]\n",
    "\n",
    "# split numeric vs categorical automatically\n",
    "num_cols = [c for c in feat_cols if is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in feat_cols if c not in num_cols]\n",
    "\n",
    "print(f\"Rows: {len(df):,}  | feature columns: {len(feat_cols)} \"\n",
    "      f\"(num={len(num_cols)}, cat={len(cat_cols)})\")\n",
    "\n",
    "# build the sparse preprocessing pipeline\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\",  StandardScaler(with_mean=False)),\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            # NOTE: scikit-learn >=1.2 uses 'sparse_output', not 'sparse'\n",
    "            (\"oh\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    sparse_threshold=1.0,                 # keep overall output sparse\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# this is the full feature frame we’ll feed to 'pre'\n",
    "X_all = df[feat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6945480-bc41-48b9-9b9a-b3e5ae86c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b832ae-d5df-4785-b92a-7a1aaabb1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kmodes gower scikit-learn-extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a39430-343d-4809-b46a-fd0b83352585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab3709-8ee1-4de4-b751-684f5ca03e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Build a compact dense embedding once (sparse -> SVD -> L2 normalize) ---\n",
    "Z_sparse = pre.fit_transform(X_all)                   # sparse matrix\n",
    "svd = TruncatedSVD(n_components=80, random_state=42)\n",
    "Z80 = svd.fit_transform(Z_sparse)                     # dense (n x 80)\n",
    "Z80 = Normalizer(copy=False).fit_transform(Z80)       # spherical (L2=1)\n",
    "\n",
    "def scan_k(Z, ks=(3,4,5,6,7,8,10,12), sample=6000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.choice(Z.shape[0], size=min(sample, Z.shape[0]), replace=False)\n",
    "    Zs  = Z[idx]\n",
    "    rows = []\n",
    "    for k in ks:\n",
    "        print(f\"fitting k={k} ...\", end=\"\")\n",
    "        km = MiniBatchKMeans(\n",
    "            n_clusters=k, batch_size=2048, max_iter=100,\n",
    "            n_init=\"auto\", random_state=seed, verbose=0\n",
    "        )\n",
    "        lbl = km.fit_predict(Zs)\n",
    "        sil = silhouette_score(\n",
    "            Zs, lbl, metric=\"cosine\",\n",
    "            sample_size=min(2000, len(Zs)), random_state=seed\n",
    "        )\n",
    "        rows.append((k, sil, km.inertia_))\n",
    "        print(f\"  silhouette={sil:.4f}\")\n",
    "    return pd.DataFrame(rows, columns=[\"k\",\"silhouette\",\"inertia\"]).sort_values(\"k\")\n",
    "\n",
    "scan_results = scan_k(Z80)\n",
    "display(scan_results)\n",
    "\n",
    "best_k = int(scan_results.sort_values(\"silhouette\", ascending=False).iloc[0][\"k\"])\n",
    "print(\"Chosen k =\", best_k)\n",
    "\n",
    "# --- Fit final model on ALL rows ---\n",
    "km_final = MiniBatchKMeans(\n",
    "    n_clusters=best_k, batch_size=2048, max_iter=200,\n",
    "    n_init=\"auto\", random_state=42\n",
    ")\n",
    "labels = km_final.fit_predict(Z80)\n",
    "df[\"cluster_mbk\"] = labels\n",
    "\n",
    "# --- Quick 2D plot for the report ---\n",
    "XY = PCA(n_components=2, random_state=42).fit_transform(Z80)\n",
    "plt.figure(figsize=(7,6))\n",
    "sc = plt.scatter(XY[:,0], XY[:,1], c=df[\"cluster_mbk\"], s=6, alpha=0.35, cmap=\"tab10\")\n",
    "plt.title(f\"MiniBatch Spherical K-Means (k={best_k})\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.legend(*sc.legend_elements(title=\"cluster\"), loc=\"best\", fontsize=8)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- Optional: cluster summary if avg_stars_2019 exists ---\n",
    "if \"avg_stars_2019\" in df.columns:\n",
    "    summ = (df.assign(y=(df[\"avg_stars_2019\"]>=4).astype(int))\n",
    "              .groupby(\"cluster_mbk\")\n",
    "              .agg(n=(\"business_id\",\"size\"),\n",
    "                   avg_stars=(\"avg_stars_2019\",\"mean\"),\n",
    "                   pct_4plus=(\"y\",\"mean\"))\n",
    "              .sort_index())\n",
    "    display(summ)\n",
    "\n",
    "# Save cluster assignments for later supervised blending\n",
    "df[[\"business_id\",\"cluster_mbk\"]].to_csv(\"clusters_mbkmeans.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11858a-01cd-405e-91a5-517ab9db041e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1b6d0-a394-461a-814a-adcfd8fedadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer, normalize\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "\n",
    "# -------- Label for external eval (optional) --------\n",
    "label_col = None\n",
    "for cand in [\"avg_stars_2019\", \"avg_stars\", \"stars\", \"y_cls\", \"label\", \"target\"]:\n",
    "    if cand in df.columns:\n",
    "        label_col = cand\n",
    "        break\n",
    "\n",
    "y = None\n",
    "if label_col is not None:\n",
    "    # binary ≥4★\n",
    "    if df[label_col].dropna().isin([0,1]).all():\n",
    "        y = df[label_col].astype(int)\n",
    "    else:\n",
    "        y = (df[label_col] >= 4.0).astype(int)\n",
    "    print(\"Using label:\", label_col, \" (binary target constructed)\")\n",
    "\n",
    "# -------- Feature table --------\n",
    "ban = {\n",
    "    \"business_id\", \"checkin_count\", \"rev_count_2019\", \"stars\", \"avg_stars\",\n",
    "    \"avg_stars_2019\", \"y_cls\", \"label\", \"target\"\n",
    "}\n",
    "# drop all-NA columns to avoid imputer warnings\n",
    "all_na_cols = [c for c in df.columns if df[c].isna().all()]\n",
    "if all_na_cols:\n",
    "    print(\"Dropping all-NA columns:\", all_na_cols)\n",
    "use_cols = [c for c in df.columns if c not in ban and c not in all_na_cols]\n",
    "\n",
    "Xfeat = df[use_cols].copy()\n",
    "\n",
    "# split by dtype\n",
    "num_cols = Xfeat.select_dtypes(include=[np.number, \"boolean\", \"bool\"]).columns.tolist()\n",
    "cat_cols = Xfeat.columns.difference(num_cols).tolist()\n",
    "\n",
    "# Keep common continuous columns up front if present (not required, just nice)\n",
    "preferred_num = [\n",
    "    \"latitude\",\"longitude\",\"review_count_log1p\",\"review_count\",\n",
    "    \"total_weekly_hours\",\"days_open\",\"weekend_hours\",\"avg_daily_hours\",\n",
    "    \"attr_RestaurantsPriceRange2\"\n",
    "]\n",
    "num_cols = [c for c in preferred_num if c in num_cols] + [c for c in num_cols if c not in preferred_num]\n",
    "\n",
    "print(f\"num={len(num_cols)}  cat={len(cat_cols)}  total={len(use_cols)}\")\n",
    "\n",
    "# -------- Sparse preprocessing (same pattern as earlier) --------\n",
    "pre_unsup = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"to_float\", FunctionTransformer(lambda X: X.astype(float), feature_names_out=\"one-to-one\")),\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler(with_mean=False)),\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    sparse_threshold=1.0,\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "Xs = pre_unsup.fit_transform(Xfeat)   # sparse matrix\n",
    "print(\"Xs shape (sparse):\", Xs.shape)\n",
    "\n",
    "# -------- SVD → 80D + L2 row-normalize (spherical) --------\n",
    "svd = TruncatedSVD(n_components=80, random_state=42)\n",
    "Z = svd.fit_transform(Xs)             # dense (n, 80)\n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "Zs = sk_normalize(Z, norm=\"l2\", axis=1)  # L2 row normalization\n",
    "print(\"Zs shape:\", Zs.shape, \"  explained_var(80)≈\", svd.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde834b2-0d0f-49ce-b702-bcf3b680e3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5799f8-5421-4080-855c-74968a9d693b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31bfa4-026e-40e5-b711-44654ac5bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MiniBatch “spherical” K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bb818-4e98-4ea2-a7a1-0fb32335e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Zs: your 80-D embedding (already computed)\n",
    "# y : your binary label (0/1), index-aligned with df\n",
    "\n",
    "# 1) L2-normalize rows (spherical K-Means)\n",
    "Z_unit = normalize(Zs)\n",
    "\n",
    "# 2) Search k and fit\n",
    "k_grid = [3,4,5,6,7]\n",
    "results, models = [], {}\n",
    "for k in k_grid:\n",
    "    mb = MiniBatchKMeans(\n",
    "        n_clusters=k, init=\"k-means++\", n_init=10,\n",
    "        batch_size=2048, max_iter=100, reassignment_ratio=0.01,\n",
    "        random_state=42\n",
    "    )\n",
    "    labels = mb.fit_predict(Z_unit)\n",
    "    sil = silhouette_score(Z_unit, labels, metric=\"cosine\")\n",
    "    results.append((k, sil, float(mb.inertia_)))\n",
    "    models[k] = (mb, labels)\n",
    "\n",
    "res_df = pd.DataFrame(results, columns=[\"k\",\"silhouette\",\"inertia\"]).sort_values(\"k\")\n",
    "best_k = int(res_df.loc[res_df.silhouette.idxmax(), \"k\"])\n",
    "mbkm, labels = models[best_k]\n",
    "df[\"cluster_sph\"] = labels  # keep for later\n",
    "\n",
    "print(\"MiniBatch spherical K-Means — chosen k =\", best_k)\n",
    "print(res_df)\n",
    "\n",
    "# 3) External metrics by mapping clusters → classes (Hungarian assignment)\n",
    "c = pd.Series(labels, index=df.index, name=\"cluster_sph\")\n",
    "cm_tc = confusion_matrix(y, c)                        # rows=true (0/1), cols=clusters\n",
    "cost = cm_tc.max() - cm_tc\n",
    "rows, cols = linear_sum_assignment(cost)\n",
    "cluster_to_class = {cols[i]: rows[i] for i in range(len(rows))}\n",
    "majority = int(y.mode()[0])\n",
    "y_pred  = c.map(cluster_to_class).fillna(majority).astype(int)\n",
    "\n",
    "# calibrated score: per-cluster positive rate\n",
    "p_pos   = y.groupby(c).mean()\n",
    "y_proba = c.map(p_pos).fillna(y.mean()).astype(float)\n",
    "\n",
    "acc = float((y_pred == y).mean())\n",
    "f1m = float(f1_score(y, y_pred, average=\"macro\"))\n",
    "auc = float(roc_auc_score(y, y_proba))\n",
    "\n",
    "print(\"\\naccuracy=%.3f  macro-F1=%.3f  ROC-AUC=%.3f\" % (acc, f1m, auc))\n",
    "print(\"\\nConfusion matrix (mapped):\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y, y_pred, digits=3))\n",
    "\n",
    "# 4) Handy dicts to paste into the paper\n",
    "sph_params = {\n",
    "    \"svd_components\": Zs.shape[1], \"row_normalize\": \"l2\",\n",
    "    \"k\": best_k, \"batch_size\": 2048, \"n_init\": 10,\n",
    "    \"max_iter\": 100, \"reassignment_ratio\": 0.01, \"random_state\": 42\n",
    "}\n",
    "sph_scores = {\n",
    "    \"silhouette\": float(res_df.loc[res_df.k==best_k, \"silhouette\"].iloc[0]),\n",
    "    \"inertia\": float(mbkm.inertia_),\n",
    "    \"accuracy\": acc, \"macro_f1\": f1m, \"roc_auc\": auc\n",
    "}\n",
    "print(\"\\nHYPERPARAMS:\", sph_params)\n",
    "print(\"SCORES:\", sph_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51094752-f512-45f1-b7e0-9097cc046482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236f083-f238-4a58-b382-ea27a8f8ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the metrics (use mapped predictions)\n",
    "#confusion matrix + classification report are using raw cluster IDs (0..6), \n",
    "#not the binary mapped predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f5ca9-10a9-4b79-b785-bab30e0d7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# c: raw cluster labels from your chosen model\n",
    "c = pd.Series(df[\"cluster_sph\"], index=df.index, name=\"cluster_sph\")\n",
    "\n",
    "# --- raw audit: true class (rows) x cluster (cols) ---\n",
    "cm_raw = pd.crosstab(y, c)\n",
    "print(\"Raw confusion (true class x cluster):\\n\", cm_raw)\n",
    "\n",
    "# --- optimal mapping cluster -> {0,1} via Hungarian ---\n",
    "cm_tc = confusion_matrix(y, c)  # rows=true labels (0/1), cols=clusters\n",
    "cost = cm_tc.max() - cm_tc\n",
    "rows, cols = linear_sum_assignment(cost)\n",
    "cluster_to_class = {cols[i]: rows[i] for i in range(len(rows))}\n",
    "majority = int(y.mode()[0])\n",
    "\n",
    "# mapped hard predictions\n",
    "y_pred = c.map(cluster_to_class).fillna(majority).astype(int)\n",
    "\n",
    "# calibrated “probability” = per-cluster positive rate\n",
    "p_pos = y.groupby(c).mean()\n",
    "y_proba = c.map(p_pos).fillna(y.mean()).astype(float)\n",
    "\n",
    "# --- binary metrics ---\n",
    "acc = float((y_pred == y).mean())\n",
    "f1m = float(f1_score(y, y_pred, average=\"macro\"))\n",
    "auc = float(roc_auc_score(y, y_proba))\n",
    "\n",
    "print(\"\\nMapped confusion (true x predicted):\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification report (binary):\\n\", classification_report(y, y_pred, digits=3))\n",
    "print(\"accuracy=%.3f  macro-F1=%.3f  ROC-AUC=%.3f\" % (acc, f1m, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14375df-c323-44d8-a4c5-f4a133c64302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c902a3-1446-411f-891d-a67b645d7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small improvements you can try on the spherical K-Means (quick wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166556e-9490-45f0-8e3a-9388486e3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep SVD dimensionality and k\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "svd_dims = [60, 80, 120]\n",
    "k_grid   = [5, 6, 7, 8, 9]\n",
    "records = []\n",
    "\n",
    "Xs_norm = Xs  # your sparse matrix from ColumnTransformer\n",
    "for d in svd_dims:\n",
    "    svd = TruncatedSVD(n_components=d, random_state=42)\n",
    "    Z   = svd.fit_transform(Xs_norm)\n",
    "    Z   = normalize(Z)\n",
    "    for k in k_grid:\n",
    "        mb = MiniBatchKMeans(n_clusters=k, init=\"k-means++\", n_init=10,\n",
    "                             batch_size=2048, max_iter=100, reassignment_ratio=0.01,\n",
    "                             random_state=42)\n",
    "        lab = mb.fit_predict(Z)\n",
    "        sil = silhouette_score(Z, lab, metric=\"cosine\")\n",
    "        records.append((d, k, sil, mb.inertia_))\n",
    "\n",
    "pd.DataFrame(records, columns=[\"svd_dim\",\"k\",\"silhouette\",\"inertia\"]).sort_values([\"silhouette\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c62817-fc94-4a07-b991-10d50fc43154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d22555-bdd6-4e93-9d26-7485e176dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k search table\n",
    "res_df.to_csv(\"spherical_kmeans_k_sweep.csv\", index=False)\n",
    "\n",
    "# cluster assignments\n",
    "df[[\"business_id\",\"cluster_sph\"]].to_csv(\"cluster_sph_assignments.csv\", index=False)\n",
    "\n",
    "# hyperparams & scores you already printed (paste these in Methods/Results)\n",
    "# HYPERPARAMS: {'svd_components': 80, 'row_normalize': 'l2', 'k': 7, ...}\n",
    "# SCORES: {'silhouette': 0.0926, 'inertia': 5320.82, 'accuracy': ..., 'macro_f1': ..., 'roc_auc': ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31bf32-a8c3-4b41-8807-425cb4ddabc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3b284-b664-45c1-a64e-4f35e32d6044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b646ef9-4ba5-4130-aee5-900c935d9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 K-Modes: search k, fit best, and evaluate vs. your binary label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b9f9d-f3ca-47e0-a06d-79e3a23176b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Re-embed with SVD=60 and L2-normalize ---\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "svd_dim = 60\n",
    "svd = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "Zs = svd.fit_transform(Xs)          # Xs is your sparse matrix from ColumnTransformer\n",
    "Zs = normalize(Zs)                  # spherical (cosine) geometry\n",
    "\n",
    "# --- 2) Fit MiniBatch K-Means (spherical via normalized Zs) ---\n",
    "k = 7\n",
    "mbkm = MiniBatchKMeans(\n",
    "    n_clusters=k, init=\"k-means++\", n_init=10,\n",
    "    batch_size=2048, max_iter=100, reassignment_ratio=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "labels = mbkm.fit_predict(Zs)\n",
    "\n",
    "sil = float(silhouette_score(Zs, labels, metric=\"cosine\"))\n",
    "inertia = float(mbkm.inertia_)\n",
    "print(f\"MiniBatch spherical K-Means (svd_dim={svd_dim}, k={k})  silhouette={sil:.4f}  inertia={inertia:.1f}\")\n",
    "\n",
    "# Persist cluster ids on df\n",
    "df[\"cluster_sph\"] = labels\n",
    "\n",
    "# --- 3) External mapping to binary label (ONLY if y exists) ---\n",
    "cm_true_vs_cluster = confusion_matrix(y, labels)\n",
    "cost = cm_true_vs_cluster.max() - cm_true_vs_cluster\n",
    "rows, cols = linear_sum_assignment(cost)\n",
    "cluster_to_class = {cols[i]: rows[i] for i in range(len(rows))}\n",
    "majority = int(y.mode()[0])\n",
    "\n",
    "y_pred  = pd.Series(labels, index=df.index).map(cluster_to_class).fillna(majority).astype(int)\n",
    "p_pos   = y.groupby(labels).mean()\n",
    "y_proba = pd.Series(labels, index=df.index).map(p_pos).fillna(y.mean()).astype(float)\n",
    "\n",
    "acc = float((y_pred == y).mean())\n",
    "f1m = float(f1_score(y, y_pred, average=\"macro\"))\n",
    "auc = float(roc_auc_score(y, y_proba))\n",
    "\n",
    "print(\"\\nMapped confusion (true x predicted):\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification report (binary):\\n\", classification_report(y, y_pred, digits=3))\n",
    "print(f\"accuracy={acc:.3f}  macro-F1={f1m:.3f}  ROC-AUC={auc:.3f}\")\n",
    "\n",
    "# --- 4) Optional: distances for later hybrid features (cosine distance to centroids) ---\n",
    "C = normalize(mbkm.cluster_centers_)\n",
    "dist_cos = cosine_distances(Zs, C)            # shape: (n_samples, k)\n",
    "dist_cols = [f\"sphcosdist_{i}\" for i in range(k)]\n",
    "dist_df = pd.DataFrame(dist_cos, index=df.index, columns=dist_cols)\n",
    "df[dist_cols] = dist_df\n",
    "\n",
    "# --- 5) Save artifacts for the paper ---\n",
    "pd.DataFrame({\"business_id\": df[\"business_id\"], \"cluster_sph\": df[\"cluster_sph\"]}).to_csv(\"cluster_sph_assignments.csv\", index=False)\n",
    "pd.DataFrame({\"svd_dim\":[svd_dim], \"k\":[k], \"silhouette\":[sil], \"inertia\":[inertia],\n",
    "              \"acc\":[acc], \"macro_f1\":[f1m], \"roc_auc\":[auc]}).to_csv(\"spherical_kmeans_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nHYPERPARAMS:\", {\"svd_components\": svd_dim, \"row_normalize\": \"l2\", \"k\": k,\n",
    "                          \"batch_size\": 2048, \"n_init\": 10, \"max_iter\": 100,\n",
    "                          \"reassignment_ratio\": 0.01, \"random_state\": 42})\n",
    "print(\"SCORES:\", {\"silhouette\": sil, \"inertia\": inertia, \"accuracy\": acc, \"macro_f1\": f1m, \"roc_auc\": auc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce080c2c-0d2b-4f1a-916b-4ef3e0626ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc736712-7284-4049-96de-2c4cd6a8a669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada76a2-85c8-48d5-a432-13cdef15475e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba176b-2d61-4ffd-83d3-46f6f94d5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Modes (categoricals only): sweep k, pick best, report metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67701e5-6ec7-4946-8354-d1e583f9e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- K-Modes on raw categoricals only ---\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# helper: align clusters to binary label and compute metrics\n",
    "def eval_clusters_vs_binary(labels, y, verbose=True):\n",
    "    cm = confusion_matrix(y, labels)\n",
    "    cost = cm.max() - cm\n",
    "    rows, cols = linear_sum_assignment(cost)\n",
    "    mapping = {cols[i]: rows[i] for i in range(len(rows))}\n",
    "    majority = int(y.mode()[0])\n",
    "    y_pred  = pd.Series(labels, index=y.index).map(mapping).fillna(majority).astype(int)\n",
    "    p_pos   = y.groupby(labels).mean()\n",
    "    y_proba = pd.Series(labels, index=y.index).map(p_pos).fillna(y.mean()).astype(float)\n",
    "    acc = float((y_pred==y).mean())\n",
    "    f1m = float(f1_score(y, y_pred, average=\"macro\"))\n",
    "    auc = float(roc_auc_score(y, y_proba))\n",
    "    if verbose:\n",
    "        print(\"\\nConfusion (mapped):\\n\", confusion_matrix(y, y_pred))\n",
    "        print(\"\\nReport:\\n\", classification_report(y, y_pred, digits=3))\n",
    "    return acc, f1m, auc, mapping\n",
    "\n",
    "# pick the categorical columns (those *not* numeric in your current use_cols)\n",
    "Xcat = df[[c for c in use_cols if c not in num_cols]].copy()\n",
    "\n",
    "# coerce dtypes so imputation/string conversion is safe\n",
    "Xcat = Xcat.replace({pd.NA: np.nan})\n",
    "for c in Xcat.columns:\n",
    "    # ensure extension booleans etc. don't block fillna\n",
    "    Xcat[c] = Xcat[c].astype(\"object\")\n",
    "Xcat = Xcat.fillna(\"missing\").astype(str)\n",
    "\n",
    "results, best = [], None\n",
    "for k in [3,4,5,6,7,8,9]:\n",
    "    km = KModes(n_clusters=k, init=\"Huang\", n_init=5, max_iter=50, random_state=42, verbose=0)\n",
    "    labels_km = km.fit_predict(Xcat)\n",
    "    acc, f1m, auc, _ = eval_clusters_vs_binary(labels_km, y, verbose=False)\n",
    "    results.append({\"algo\":\"KModes\",\"k\":k,\"init\":\"Huang\",\"n_init\":5,\"max_iter\":50,\n",
    "                    \"cost\": float(km.cost_), \"accuracy\":acc, \"macro_f1\":f1m, \"roc_auc\":auc})\n",
    "    if best is None or f1m > best[\"macro_f1\"]:\n",
    "        best = {\"k\":k, \"km\":km, \"labels\":labels_km, \"accuracy\":acc, \"macro_f1\":f1m, \"roc_auc\":auc}\n",
    "\n",
    "pd.DataFrame(results).sort_values([\"macro_f1\",\"accuracy\"], ascending=False)\n",
    "print(f\"\\nBest K-Modes (k={best['k']})  acc={best['accuracy']:.3f}  macro-F1={best['macro_f1']:.3f}  ROC-AUC={best['roc_auc']:.3f}\")\n",
    "_ = eval_clusters_vs_binary(best[\"labels\"], y, verbose=True)\n",
    "\n",
    "# persist assignments for hybrid\n",
    "df[\"cluster_kmodes\"] = best[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89340f0f-2e40-4423-a544-66a0d7d50bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db392a5-d929-44ea-b457-119dd51b0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid (spherical K-Means + K-Modes → supervised logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867541c-d27c-4967-9dce-e8034972f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Build clean hybrid feature table -------------------------------------\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "# extra features from clustering\n",
    "extra_num = [c for c in df.columns if c.startswith(\"sphcosdist_\")]         # cosine dists\n",
    "extra_cat = [c for c in [\"cluster_sph\", \"cluster_kmodes\"] if c in df]      # cluster IDs\n",
    "\n",
    "hyb_cols = list(dict.fromkeys(use_cols + extra_num + extra_cat))           # keep order, drop dups\n",
    "Xh = df[hyb_cols].copy()\n",
    "\n",
    "# Treat cluster IDs as categoricals (so they go through the OHE branch)\n",
    "for c in extra_cat:\n",
    "    Xh[c] = Xh[c].astype(\"object\")\n",
    "\n",
    "# ---- critical sanitization: remove pandas extension dtypes / pd.NA ----------\n",
    "# (a) numeric extension -> plain float64 so np.nan is valid\n",
    "num_ext = Xh.select_dtypes(include=[\"Int64\", \"UInt64\", \"Float64\"]).columns\n",
    "if len(num_ext):\n",
    "    Xh[num_ext] = Xh[num_ext].astype(\"float64\")\n",
    "\n",
    "# (b) booleans / strings -> plain object\n",
    "bool_ext = Xh.select_dtypes(include=[\"boolean\"]).columns\n",
    "if len(bool_ext):\n",
    "    Xh[bool_ext] = Xh[bool_ext].astype(\"object\")\n",
    "\n",
    "str_ext = Xh.select_dtypes(include=[\"string\"]).columns\n",
    "if len(str_ext):\n",
    "    Xh[str_ext] = Xh[str_ext].astype(\"object\")\n",
    "\n",
    "# (c) replace *all* pd.NA with np.nan, then ensure object cols only carry np.nan\n",
    "Xh = Xh.replace({pd.NA: np.nan})\n",
    "obj_cols_all = Xh.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "for c in obj_cols_all:\n",
    "    # .isna() handles pd.NA masks safely; assignment writes real np.nan scalars\n",
    "    mask = Xh[c].isna()\n",
    "    if mask.any():\n",
    "        Xh.loc[mask, c] = np.nan\n",
    "\n",
    "# Re-detect numeric vs categorical after coercions\n",
    "num_cols_h = list(Xh.select_dtypes(include=[np.number]).columns)\n",
    "cat_cols_h = [c for c in Xh.columns if c not in num_cols_h]\n",
    "\n",
    "# --- 2) Preprocess + model ----------------------------------------------------\n",
    "pre_h = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\",  StandardScaler(with_mean=False)),\n",
    "        ]), num_cols_h),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"oh\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "        ]), cat_cols_h),\n",
    "    ],\n",
    "    sparse_threshold=1.0,\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    Xh, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "logit = LogisticRegression(\n",
    "    solver=\"saga\", penalty=\"elasticnet\", l1_ratio=0.2, C=0.3,\n",
    "    max_iter=2000, class_weight=\"balanced\", n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe_hybrid = Pipeline([(\"pre\", pre_h), (\"clf\", logit)])\n",
    "pipe_hybrid.fit(Xtr, ytr)\n",
    "\n",
    "# --- 3) Metrics ---------------------------------------------------------------\n",
    "proba = pipe_hybrid.predict_proba(Xte)[:, 1]\n",
    "pred  = (proba >= 0.50).astype(int)\n",
    "\n",
    "acc = float((pred == yte).mean())\n",
    "f1m = float(f1_score(yte, pred, average=\"macro\"))\n",
    "auc = float(roc_auc_score(yte, proba))\n",
    "\n",
    "print(f\"\\nHYBRID Logistic — acc={acc:.3f}  macro-F1={f1m:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"\\nConfusion matrix @0.5:\\n\", confusion_matrix(yte, pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(yte, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf933f8c-0fff-43e4-b473-b6ba47984438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- clean hybrid feature table (safe dtypes + safe NaNs) ---\n",
    "Xh = df[hyb_cols].copy(deep=True)\n",
    "\n",
    "# cluster ids should be categorical\n",
    "for c in extra_cat:\n",
    "    if c in Xh:\n",
    "        Xh[c] = Xh[c].astype(\"object\")\n",
    "\n",
    "# 1) extension numerics -> float64 (so np.nan works)\n",
    "to_float = Xh.select_dtypes(include=[\"Int64\",\"UInt64\",\"Float64\"]).columns\n",
    "if len(to_float):\n",
    "    Xh[to_float] = Xh[to_float].astype(\"float64\")\n",
    "\n",
    "# 2) extension categoricals -> plain object (string/boolean/category)\n",
    "to_obj = Xh.select_dtypes(include=[\"string\",\"boolean\",\"category\"]).columns\n",
    "if len(to_obj):\n",
    "    Xh[to_obj] = Xh[to_obj].astype(\"object\")\n",
    "\n",
    "# 3) unify missing values WITHOUT per-cell assignment\n",
    "Xh = Xh.replace({pd.NA: np.nan}).infer_objects(copy=False)  # silences the FutureWarning\n",
    "\n",
    "# 4) re-detect column sets\n",
    "num_cols_h = list(Xh.select_dtypes(include=[np.number]).columns)\n",
    "cat_cols_h = [c for c in Xh.columns if c not in num_cols_h]\n",
    "\n",
    "print(f\"num={len(num_cols_h)}  cat={len(cat_cols_h)}  total={len(Xh.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc47fd5-dcab-4217-860f-c36830b0c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c044b-5bb4-42a8-bc97-3ba7f7deb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit & evaluate the Hybrid (clusters-as-features) → Logistic (elastic-net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ae1bc-9053-417b-a6ea-79b96fc8a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/test split (uses your existing binary y) ---\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    ")\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    Xh, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Preprocess (sparse-safe) ---\n",
    "pre_h = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\",  StandardScaler(with_mean=False)),\n",
    "        ]), num_cols_h),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"oh\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "        ]), cat_cols_h),\n",
    "    ],\n",
    "    sparse_threshold=1.0,\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# --- Classifier (your best params from earlier) ---\n",
    "logit = LogisticRegression(\n",
    "    solver=\"saga\", penalty=\"elasticnet\",\n",
    "    l1_ratio=0.2, C=0.3, max_iter=2000,\n",
    "    class_weight=\"balanced\", n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe_hybrid = Pipeline([(\"pre\", pre_h), (\"clf\", logit)])\n",
    "\n",
    "pipe_hybrid.fit(Xtr, ytr)\n",
    "\n",
    "# --- Metrics (holdout) ---\n",
    "proba = pipe_hybrid.predict_proba(Xte)[:, 1]\n",
    "pred  = (proba >= 0.50).astype(int)\n",
    "\n",
    "acc = float((pred == yte).mean())\n",
    "f1m = float(f1_score(yte, pred, average=\"macro\"))\n",
    "auc = float(roc_auc_score(yte, proba))\n",
    "\n",
    "print(f\"\\nHYBRID Logistic — acc={acc:.3f}  macro-F1={f1m:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"\\nConfusion matrix @0.50:\\n\", confusion_matrix(yte, pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(yte, pred, digits=3))\n",
    "\n",
    "# hyperparams \n",
    "hyb_params = {\n",
    "    \"model\": \"Hybrid(LogReg-elasticnet)\",\n",
    "    \"C\": 0.3, \"l1_ratio\": 0.2, \"solver\": \"saga\",\n",
    "    \"max_iter\": 2000, \"class_weight\": \"balanced\",\n",
    "    \"pre_num_imp\": \"median\", \"pre_num_scaler\": \"StandardScaler(with_mean=False)\",\n",
    "    \"pre_cat_imp\": \"most_frequent\", \"pre_cat_enc\": \"OHE(ignore)\",\n",
    "    \"features_num\": len(num_cols_h), \"features_cat\": len(cat_cols_h),\n",
    "}\n",
    "hyb_scores = {\"accuracy\": acc, \"macro_f1\": f1m, \"roc_auc\": auc}\n",
    "print(\"\\nHYPERPARAMS:\", hyb_params)\n",
    "print(\"SCORES:\", hyb_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b16e3c-1504-42bb-b770-274634678996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345499c3-ff66-4b4d-80f3-f878af8d3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebfb8b-c066-4b45-8aac-1ce67989193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\"acc\": \"accuracy\", \"f1m\": \"f1_macro\", \"auc\": \"roc_auc\"}\n",
    "\n",
    "cv_res = cross_validate(\n",
    "    pipe_hybrid, Xh, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False\n",
    ")\n",
    "print(\"\\nCV means (±std):\",\n",
    "      f\"acc={cv_res['test_acc'].mean():.3f}±{cv_res['test_acc'].std():.3f}  \",\n",
    "      f\"f1m={cv_res['test_f1m'].mean():.3f}±{cv_res['test_f1m'].std():.3f}  \",\n",
    "      f\"auc={cv_res['test_auc'].mean():.3f}±{cv_res['test_auc'].std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798c016-fe2a-4a87-a911-b376dd0751f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402f76a-dc8b-40f6-8121-4b6cb702ee27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa29f8-6325-4b54-934b-d527daf2cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DO NOT RUN.... TAKES 5-6 hrs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__C\": np.logspace(-2, 1, 30),             # 0.01 … 10\n",
    "    \"clf__l1_ratio\": np.linspace(0.0, 1.0, 21),   # 0 (pure L2) … 1 (pure L1)\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=pipe_hybrid,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,               \n",
    "    cv=cv,\n",
    "    scoring={\"acc\":\"accuracy\", \"f1m\":\"f1_macro\", \"auc\":\"roc_auc\"},\n",
    "    refit=\"f1m\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(Xh, y)\n",
    "\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "print(\"Best CV macro-F1:\", round(rs.best_score_, 4))\n",
    "\n",
    "# tidy search results table for the appendix\n",
    "r = pd.DataFrame(rs.cv_results_)\n",
    "cols = [\n",
    "    \"param_clf__C\", \"param_clf__l1_ratio\",\n",
    "    \"mean_test_acc\", \"std_test_acc\",\n",
    "    \"mean_test_f1m\", \"std_test_f1m\",\n",
    "    \"mean_test_auc\", \"std_test_auc\",\n",
    "    \"rank_test_f1m\"\n",
    "]\n",
    "r = r[cols].sort_values(\"rank_test_f1m\")\n",
    "r.to_csv(\"artifacts/hybrid_logreg_randomsearch_results.csv\", index=False)\n",
    "print(\"Saved: artifacts/hybrid_logreg_randomsearch_results.csv\")\n",
    "\n",
    "best_hybrid = rs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76917c3d-0721-44f8-917d-cad23f2449ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"clf__C\": np.logspace(-1, 0.5, 15),        # narrower, 0.1 … ~3.16\n",
    "    \"clf__l1_ratio\": np.linspace(0.2, 0.8, 13)\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=pipe_hybrid,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    refit=True,\n",
    "    n_jobs=4,                  # reduce oversubscription\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ").fit(Xh, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafe5ef-7b67-4587-9398-cc9657f2a19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2968cd0-231a-4f56-9b8c-ac018ceb3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This focuses the space around your previously good params (C≈0.3, l1_ratio≈0.2), raises max_iter, relaxes tol, and keeps things stable/fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c5af5-5bd7-4986-846d-afcd2600e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes Xtr, Xte, ytr, yte, pre_h are already in memory (from earlier cells)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "logit = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    penalty=\"elasticnet\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=4000,        # more room to converge\n",
    "    tol=1e-3,             # slightly looser for speed\n",
    "    n_jobs=-1             # harmless on binary; leave set\n",
    ")\n",
    "pipe_hybrid = Pipeline([(\"pre\", pre_h), (\"clf\", logit)])\n",
    "\n",
    "param_dist_trim = {\n",
    "    \"clf__C\": np.logspace(-1.3, 0.2, 12),       # ~0.05 … 1.58, focuses near 0.3\n",
    "    \"clf__l1_ratio\": np.linspace(0.15, 0.35, 9) # focuses near 0.2\n",
    "}\n",
    "\n",
    "rs_trim = RandomizedSearchCV(\n",
    "    estimator=pipe_hybrid,\n",
    "    param_distributions=param_dist_trim,\n",
    "    n_iter=15,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    refit=True,           # refit best on Xtr\n",
    "    n_jobs=4,\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "rs_trim.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best params:\", rs_trim.best_params_)\n",
    "print(\"Best CV macro-F1:\", rs_trim.best_score_)\n",
    "best_hybrid = rs_trim.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83c477-fe7a-49c0-a91f-2e461eacddec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e912d-b9c4-4ba9-8888-85acd17fec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633aff40-08e9-422a-9114-172ce11c7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from joblib import dump\n",
    "import json, pandas as pd\n",
    "\n",
    "print(\"Best params (CV):\", rs_trim.best_params_)\n",
    "print(\"Best CV macro-F1:\", rs_trim.best_score_)\n",
    "\n",
    "# 1) Finalize the tuned model and evaluate on hold-out\n",
    "best_hybrid = rs_trim.best_estimator_\n",
    "\n",
    "proba_te = best_hybrid.predict_proba(Xte)[:, 1]\n",
    "pred05   = (proba_te >= 0.50).astype(int)\n",
    "\n",
    "acc05 = accuracy_score(yte, pred05)\n",
    "f1m05 = f1_score(yte, pred05, average=\"macro\")\n",
    "auc   = roc_auc_score(yte, proba_te)\n",
    "cm05  = confusion_matrix(yte, pred05)\n",
    "\n",
    "print(f\"\\nHYBRID(LogReg-enet) — hold-out @0.50  acc={acc05:.3f}  macro-F1={f1m05:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @0.50:\\n\", cm05)\n",
    "print(\"\\nReport @0.50:\\n\", classification_report(yte, pred05, digits=3))\n",
    "\n",
    "# 2) (Optional) pick threshold that maximizes macro-F1 and re-report\n",
    "ths = np.linspace(0.1, 0.9, 81)\n",
    "f1s = [f1_score(yte, (proba_te >= t).astype(int), average=\"macro\") for t in ths]\n",
    "t_star = float(ths[int(np.argmax(f1s))])\n",
    "\n",
    "pred_star = (proba_te >= t_star).astype(int)\n",
    "acc_star  = accuracy_score(yte, pred_star)\n",
    "f1m_star  = f1_score(yte, pred_star, average=\"macro\")\n",
    "cm_star   = confusion_matrix(yte, pred_star)\n",
    "\n",
    "print(f\"\\nBest threshold for macro-F1: {t_star:.3f}\")\n",
    "print(f\"Hold-out @{t_star:.3f}  acc={acc_star:.3f}  macro-F1={f1m_star:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @t*:\\n\", cm_star)\n",
    "\n",
    "# 3) Save artifacts for the report/repro\n",
    "dump(best_hybrid, \"hybrid_logreg_enet_best.joblib\")\n",
    "\n",
    "summary = {\n",
    "    \"search\": {\"type\": \"RandomizedSearchCV\", \"n_iter\": 15, \"cv\": 3},\n",
    "    \"best_params\": rs_trim.best_params_,\n",
    "    \"cv_best_macro_f1\": float(rs_trim.best_score_),\n",
    "    \"holdout_thr_0.50\": {\n",
    "        \"accuracy\": float(acc05), \"macro_f1\": float(f1m05),\n",
    "        \"roc_auc\": float(auc), \"confusion\": cm05.tolist()\n",
    "    },\n",
    "    \"holdout_thr_star\": {\n",
    "        \"threshold\": t_star, \"accuracy\": float(acc_star),\n",
    "        \"macro_f1\": float(f1m_star), \"roc_auc\": float(auc),\n",
    "        \"confusion\": cm_star.tolist()\n",
    "    }\n",
    "}\n",
    "json.dump(summary, open(\"hybrid_logreg_enet_summary.json\",\"w\"), indent=2)\n",
    "\n",
    "cv_df = pd.DataFrame(rs_trim.cv_results_)\n",
    "cv_df.to_csv(\"hybrid_logreg_enet_cv_results.csv\", index=False)\n",
    "\n",
    "# 4) Emit a one-row table for your doc\n",
    "row = {\n",
    "    \"Model\": \"Hybrid(LogReg-enet)\",\n",
    "    \"Search\": \"RandomizedSearch\",\n",
    "    \"n_iter\": 15,\n",
    "    \"cv\": 3,\n",
    "    \"C\": rs_trim.best_params_[\"clf__C\"],\n",
    "    \"l1_ratio\": rs_trim.best_params_[\"clf__l1_ratio\"],\n",
    "    \"Accuracy@0.50\": acc05,\n",
    "    \"MacroF1@0.50\": f1m05,\n",
    "    \"ROC-AUC\": auc,\n",
    "    \"BestThr\": t_star,\n",
    "    \"Accuracy@BestThr\": acc_star,\n",
    "    \"MacroF1@BestThr\": f1m_star,\n",
    "    \"CM@0.50\": cm05.tolist(),\n",
    "    \"CM@BestThr\": cm_star.tolist(),\n",
    "}\n",
    "pd.DataFrame([row]).to_csv(\"hybrid_logreg_enet_table_row.csv\", index=False)\n",
    "print(\"\\nSaved: hybrid_logreg_enet_best.joblib, hybrid_logreg_enet_summary.json, hybrid_logreg_enet_cv_results.csv, hybrid_logreg_enet_table_row.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb407f-260b-4309-b4ff-65e874ec7847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b2860-fc7f-4da9-836f-b9c012cd3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save hybrid visuals & table row (no refit required) ===\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# ---- 0) Where to save ----\n",
    "OUT_DIR = Path(\"report_artifacts_hybrid\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- 1) Helpers ----\n",
    "def compute_at_threshold(y_true, proba, t):\n",
    "    pred = (proba >= t).astype(int)\n",
    "    acc  = float((pred == y_true).mean())\n",
    "    f1m  = float(f1_score(y_true, pred, average=\"macro\"))\n",
    "    auc  = float(roc_auc_score(y_true, proba))\n",
    "    cm   = confusion_matrix(y_true, pred)\n",
    "    return pred, acc, f1m, auc, cm\n",
    "\n",
    "def best_threshold_f1_macro(y_true, proba, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 181)\n",
    "    f1s = [f1_score(y_true, (proba >= t).astype(int), average=\"macro\") for t in grid]\n",
    "    i   = int(np.argmax(f1s))\n",
    "    return float(grid[i]), float(f1s[i])\n",
    "\n",
    "def plot_confusion(cm, title, path):\n",
    "    fig, ax = plt.subplots(figsize=(4, 3.6), dpi=150)\n",
    "    im = ax.imshow(cm, aspect=\"auto\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f\"{int(cm[i,j])}\", ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_bars(values, labels, title, path):\n",
    "    fig, ax = plt.subplots(figsize=(5.5, 3.6), dpi=150)\n",
    "    x = np.arange(len(values))\n",
    "    ax.bar(x, values)\n",
    "    ax.set_xticks(x); ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title)\n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(i, v + (0.02 if v < 0.95 else -0.05), f\"{v:.3f}\", ha=\"center\",\n",
    "                va=\"bottom\" if v < 0.95 else \"top\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---- 2) Inputs expected in memory: yte (Series/array), proba (np.array of positive-class probs)\n",
    "y_true = np.asarray(yte)\n",
    "p_pos  = np.asarray(proba)\n",
    "\n",
    "# Baseline @0.50\n",
    "pred50, acc50, f1m50, auc50, cm50 = compute_at_threshold(y_true, p_pos, 0.50)\n",
    "# Best macro-F1 threshold\n",
    "t_star, f1m_star_grid = best_threshold_f1_macro(y_true, p_pos)\n",
    "preds, accs, f1ms, aucs, cms = compute_at_threshold(y_true, p_pos, t_star)\n",
    "\n",
    "# ---- 3) Save figures ----\n",
    "plot_confusion(cm50, \"Hybrid — Confusion Matrix (hold-out @0.50)\",\n",
    "               OUT_DIR / \"hybrid_confusion_050.png\")\n",
    "plot_confusion(cms,  f\"Hybrid — Confusion Matrix (hold-out @{t_star:.3f})\",\n",
    "               OUT_DIR / \"hybrid_confusion_bestthr.png\")\n",
    "\n",
    "plot_bars([acc50, f1m50, auc50],\n",
    "          [\"Acc(0.50)\", \"F1m(0.50)\", \"AUC\"],\n",
    "          \"Hold-out metrics @0.50\",\n",
    "          OUT_DIR / \"hybrid_metrics_050.png\")\n",
    "\n",
    "plot_bars([accs, f1ms, aucs],\n",
    "          [f\"Acc({t_star:.3f})\", f\"F1m({t_star:.3f})\", \"AUC\"],\n",
    "          \"Hold-out metrics @t* (best F1m)\",\n",
    "          OUT_DIR / \"hybrid_metrics_tstar.png\")\n",
    "\n",
    "# ---- 4) Save a one-line table row for the report ----\n",
    "try:\n",
    "    C  = float(pipe_hybrid.named_steps[\"clf\"].C)\n",
    "    L1 = float(pipe_hybrid.named_steps[\"clf\"].l1_ratio)\n",
    "except Exception:\n",
    "    C  = np.nan\n",
    "    L1 = np.nan\n",
    "\n",
    "cv_f1m = float(rs.best_score_) if \"rs\" in locals() else np.nan\n",
    "\n",
    "row = pd.DataFrame([{\n",
    "    \"Model\": \"Hybrid(LogReg-enet)\",\n",
    "    \"C\": C, \"l1_ratio\": L1,\n",
    "    \"CV_macroF1\": cv_f1m,\n",
    "    \"thr_050_acc\": acc50, \"thr_050_macroF1\": f1m50, \"thr_050_auc\": auc50,\n",
    "    \"thr_star\": t_star, \"thr_star_acc\": accs, \"thr_star_macroF1\": f1ms, \"thr_star_auc\": aucs\n",
    "}])\n",
    "row.to_csv(OUT_DIR / \"hybrid_report_table_row.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_DIR.resolve())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0048de-9b77-4bdb-904b-2a709206fd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72cd5c-773b-4b2a-9485-badfd9360105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inline visuals for Hybrid(LogReg-enet) ===\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score, roc_auc_score\n",
    "\n",
    "# Expect these to exist from your previous steps:\n",
    "#   yte  -> hold-out labels (array-like, 0/1)\n",
    "#   proba -> predicted proba for positive class (np.array)\n",
    "model_name = \"Hybrid(LogReg-enet)\"\n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "def best_threshold_f1_macro(y, p, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 181)\n",
    "    f1s = [f1_score(y, (p >= t).astype(int), average=\"macro\") for t in grid]\n",
    "    i = int(np.argmax(f1s))\n",
    "    return float(grid[i]), float(f1s[i])\n",
    "\n",
    "def metrics_at_t(y, p, t):\n",
    "    pred = (p >= t).astype(int)\n",
    "    acc  = float((pred == y).mean())\n",
    "    f1m  = float(f1_score(y, pred, average=\"macro\"))\n",
    "    aucv = float(roc_auc_score(y, p))\n",
    "    cm   = confusion_matrix(y, pred)\n",
    "    return pred, acc, f1m, aucv, cm\n",
    "\n",
    "def show_confusion(cm, title):\n",
    "    fig, ax = plt.subplots(figsize=(5.0, 4.2), dpi=150)\n",
    "    im = ax.imshow(cm, aspect=\"auto\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f\"{int(cm[i,j])}\", ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_metric_bars(values, labels, subtitle):\n",
    "    fig, ax = plt.subplots(figsize=(5.6, 3.6), dpi=150)\n",
    "    x = np.arange(len(values))\n",
    "    ax.bar(x, values)\n",
    "    ax.set_xticks(x); ax.set_xticklabels(labels)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(f\"{model_name} — {subtitle}\")\n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(i, v + (0.02 if v < 0.95 else -0.05), f\"{v:.3f}\",\n",
    "                ha=\"center\", va=(\"bottom\" if v < 0.95 else \"top\"))\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------- compute + show -----------------\n",
    "y_true = np.asarray(yte)\n",
    "p_pos  = np.asarray(proba)\n",
    "\n",
    "# Confusions @ 0.50 and @ t*\n",
    "t_star, _ = best_threshold_f1_macro(y_true, p_pos)\n",
    "_, acc50, f1m50, auc50, cm50 = metrics_at_t(y_true, p_pos, 0.50)\n",
    "_, accs,  f1ms,  aucs,  cms  = metrics_at_t(y_true, p_pos, t_star)\n",
    "\n",
    "show_confusion(cm50, f\"{model_name} — Confusion Matrix @0.50\")\n",
    "show_confusion(cms,  f\"{model_name} — Confusion Matrix @{t_star:.3f} (best F1m)\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, p_pos)\n",
    "rocA = auc(fpr, tpr)\n",
    "fig, ax = plt.subplots(figsize=(5.0, 4.2), dpi=150)\n",
    "ax.plot(fpr, tpr, label=f\"AUC = {rocA:.3f}\")\n",
    "ax.plot([0,1], [0,1], linestyle=\"--\")\n",
    "ax.set_title(f\"{model_name} — ROC Curve\")\n",
    "ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Metric bars (two separate figures so each is easy to screenshot)\n",
    "show_metric_bars([acc50, f1m50, auc50], [\"Accuracy\",\"Macro-F1\",\"ROC-AUC\"], \"Hold-out @0.50\")\n",
    "show_metric_bars([accs,  f1ms,  aucs],  [\"Accuracy\",\"Macro-F1\",\"ROC-AUC\"], f\"Hold-out @{t_star:.3f}\")\n",
    "\n",
    "# Small summary table (renders inline)\n",
    "summary = pd.DataFrame({\n",
    "    \"Threshold\": [\"0.50\", f\"{t_star:.3f} (best F1m)\"],\n",
    "    \"Accuracy\":  [acc50, accs],\n",
    "    \"Macro-F1\":  [f1m50, f1ms],\n",
    "    \"ROC-AUC\":   [auc50, aucs]\n",
    "})\n",
    "summary\n",
    "\n",
    "# (Optional) also save the figures to your folder for consistency with earlier step\n",
    "OUT_DIR = Path(\"report_artifacts_hybrid\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "# Re-plot quickly for saving:\n",
    "for title, cm, fname in [\n",
    "    (f\"{model_name} — Confusion Matrix @0.50\", cm50, \"hybrid_confusion_050.png\"),\n",
    "    (f\"{model_name} — Confusion Matrix @{t_star:.3f}\", cms, \"hybrid_confusion_bestthr.png\"),\n",
    "]:\n",
    "    fig, ax = plt.subplots(figsize=(5.0, 4.2), dpi=150)\n",
    "    im = ax.imshow(cm, aspect=\"auto\")\n",
    "    ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f\"{int(cm[i,j])}\", ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout(); fig.savefig(OUT_DIR/fname, dpi=220, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "# Save a one-line CSV row you can drop into a table later\n",
    "try:\n",
    "    C  = float(pipe_hybrid.named_steps[\"clf\"].C)\n",
    "    L1 = float(pipe_hybrid.named_steps[\"clf\"].l1_ratio)\n",
    "except Exception:\n",
    "    C, L1 = np.nan, np.nan\n",
    "\n",
    "cv_f1m = float(rs.best_score_) if \"rs\" in globals() else np.nan\n",
    "pd.DataFrame([{\n",
    "    \"Model\": model_name, \"C\": C, \"l1_ratio\": L1, \"CV_macroF1\": cv_f1m,\n",
    "    \"thr_050_acc\": acc50, \"thr_050_macroF1\": f1m50, \"thr_050_auc\": auc50,\n",
    "    \"thr_star\": t_star, \"thr_star_acc\": accs, \"thr_star_macroF1\": f1ms, \"thr_star_auc\": aucs\n",
    "}]).to_csv(OUT_DIR / \"hybrid_report_table_row.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c47c2-3f79-4d20-be43-b271b5e36f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8b7ec-7a7c-4fd8-a7db-af65dd50e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === UNSUPERVISED VISUALS: spherical K-Means (k=7) & K-Modes (k=3) ===\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score, roc_curve, auc\n",
    "\n",
    "# ---------- Resolve target ----------\n",
    "if 'y' in globals():\n",
    "    y_true = pd.Series(y).astype(int)\n",
    "elif 'df' in globals() and 'avg_stars_2019' in df.columns:\n",
    "    y_true = df['avg_stars_2019'].astype(int)\n",
    "else:\n",
    "    raise RuntimeError(\"Couldn't find y or df['avg_stars_2019']. Please define the binary target first.\")\n",
    "\n",
    "# ---------- Helper: evaluate clusters via majority vote + prob from pos-rate ----------\n",
    "def eval_clusters(cluster_like, y_true, name=\"clusters\"):\n",
    "    s = pd.Series(cluster_like, name=\"cluster\")\n",
    "    # try to align on index; if impossible, fall back to positional\n",
    "    if not s.index.equals(y_true.index):\n",
    "        s = s.reindex(y_true.index)\n",
    "        if s.isna().any():\n",
    "            s = s.reset_index(drop=True)\n",
    "            y_aligned = y_true.reset_index(drop=True)\n",
    "        else:\n",
    "            y_aligned = y_true\n",
    "    else:\n",
    "        y_aligned = y_true\n",
    "\n",
    "    s = s.astype(int)\n",
    "    ct = pd.crosstab(y_aligned, s)  # rows: true {0,1}, cols: clusters\n",
    "    # cluster-wise positive rate (used as probability for ROC; NaN->0)\n",
    "    pos_rate = (ct.loc[1] / ct.sum(axis=0)).fillna(0.0)\n",
    "    pred = s.map(lambda g: 1 if pos_rate.get(g, 0.0) >= 0.5 else 0).astype(int)\n",
    "    proba = s.map(pos_rate).fillna(0.0).to_numpy()\n",
    "\n",
    "    cm = confusion_matrix(y_aligned, pred)\n",
    "    acc = float((pred == y_aligned).mean())\n",
    "    f1m = float(f1_score(y_aligned, pred, average=\"macro\"))\n",
    "    aucv = float(roc_auc_score(y_aligned, proba))\n",
    "\n",
    "    return dict(name=name, clusters=s, table=ct, pos_rate=pos_rate,\n",
    "                pred=pred, proba=proba, cm=cm, acc=acc, f1m=f1m, auc=aucv)\n",
    "\n",
    "# ---------- Plot helpers ----------\n",
    "def plot_confusion(cm, title, path=None):\n",
    "    fig, ax = plt.subplots(figsize=(5.2, 4.6), dpi=120)\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted label\"); ax.set_ylabel(\"True label\")\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([\"0\",\"1\"])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"0\",\"1\"])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f\"{int(cm[i,j])}\", ha=\"center\", va=\"center\")\n",
    "    fig.tight_layout()\n",
    "    if path: fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_cluster_sizes(ct, title, path=None):\n",
    "    sizes = ct.sum(axis=0).sort_index()\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 3.8), dpi=120)\n",
    "    ax.bar(sizes.index.astype(str), sizes.values)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Cluster ID\"); ax.set_ylabel(\"Count\")\n",
    "    fig.tight_layout()\n",
    "    if path: fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_pos_rate(pos_rate, title, path=None):\n",
    "    pr = pos_rate.sort_index()\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 3.8), dpi=120)\n",
    "    ax.bar(pr.index.astype(str), pr.values)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Cluster ID\"); ax.set_ylabel(\"Positive rate P(y=1|cluster)\")\n",
    "    fig.tight_layout()\n",
    "    if path: fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, proba, title, path=None):\n",
    "    fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig, ax = plt.subplots(figsize=(5.2, 4.6), dpi=120)\n",
    "    ax.plot(fpr, tpr, lw=2, label=f\"AUC={roc_auc:.3f}\")\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=1)\n",
    "    ax.set_title(title); ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    fig.tight_layout()\n",
    "    if path: fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_scatter_2d(embed2, clusters, title, path=None, sample=12000, s=6):\n",
    "    # subsample for speed/visibility\n",
    "    n = len(clusters)\n",
    "    idx = np.random.RandomState(42).choice(n, size=min(sample, n), replace=False)\n",
    "    x, y = embed2[idx, 0], embed2[idx, 1]\n",
    "    lab = pd.Series(clusters).to_numpy()[idx]\n",
    "    fig, ax = plt.subplots(figsize=(6.6, 5.6), dpi=120)\n",
    "    sc = ax.scatter(x, y, c=lab, s=s)\n",
    "    ax.set_title(title); ax.set_xticks([]); ax.set_yticks([])\n",
    "    fig.tight_layout()\n",
    "    if path: fig.savefig(path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------- Make output folder ----------\n",
    "outdir = Path(\"outputs_unsup\"); outdir.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- Evaluate & plot: SPHERICAL K-MEANS ----------\n",
    "if 'df' in globals() and 'cluster_sph' in df.columns:\n",
    "    res_sph = eval_clusters(df['cluster_sph'], y_true, name=\"spherical-kmeans\")\n",
    "    print(f\"[Spherical K-Means] acc={res_sph['acc']:.3f}  macro-F1={res_sph['f1m']:.3f}  ROC-AUC={res_sph['auc']:.3f}\")\n",
    "    plot_confusion(res_sph['cm'],\n",
    "                   \"Spherical K-Means — Confusion (majority mapping)\",\n",
    "                   outdir / \"sph_confusion.png\")\n",
    "    plot_cluster_sizes(res_sph['table'],\n",
    "                       \"Spherical K-Means — Cluster sizes\",\n",
    "                       outdir / \"sph_sizes.png\")\n",
    "    plot_pos_rate(res_sph['pos_rate'],\n",
    "                  \"Spherical K-Means — Positive rate by cluster\",\n",
    "                  outdir / \"sph_posrate.png\")\n",
    "    plot_roc_curve(y_true, res_sph['proba'],\n",
    "                   \"Spherical K-Means — ROC (prob=cluster positive rate)\",\n",
    "                   outdir / \"sph_roc.png\")\n",
    "\n",
    "    # Optional 2-D scatter if an embedding is available\n",
    "    embed2 = None\n",
    "    try:\n",
    "        if 'Zs' in globals():\n",
    "            from sklearn.decomposition import TruncatedSVD\n",
    "            embed2 = TruncatedSVD(n_components=2, random_state=42).fit_transform(Zs)\n",
    "        elif 'Xs' in globals():\n",
    "            from sklearn.decomposition import TruncatedSVD\n",
    "            embed2 = TruncatedSVD(n_components=2, random_state=42).fit_transform(Xs)\n",
    "    except Exception as e:\n",
    "        embed2 = None\n",
    "        print(\"2-D scatter skipped (no embedding available).\")\n",
    "\n",
    "    if embed2 is not None:\n",
    "        plot_scatter_2d(embed2, df['cluster_sph'],\n",
    "                        \"Spherical K-Means — 2-D embedding (sampled)\",\n",
    "                        outdir / \"sph_scatter2d.png\")\n",
    "else:\n",
    "    print(\"⚠️ 'cluster_sph' not found in df; skipping spherical K-Means visuals.\")\n",
    "\n",
    "# ---------- Evaluate & plot: K-MODES ----------\n",
    "if 'df' in globals() and 'cluster_kmodes' in df.columns:\n",
    "    res_km = eval_clusters(df['cluster_kmodes'], y_true, name=\"k-modes\")\n",
    "    print(f\"[K-Modes] acc={res_km['acc']:.3f}  macro-F1={res_km['f1m']:.3f}  ROC-AUC={res_km['auc']:.3f}\")\n",
    "    plot_confusion(res_km['cm'],\n",
    "                   \"K-Modes — Confusion (majority mapping)\",\n",
    "                   outdir / \"kmodes_confusion.png\")\n",
    "    plot_cluster_sizes(res_km['table'],\n",
    "                       \"K-Modes — Cluster sizes\",\n",
    "                       outdir / \"kmodes_sizes.png\")\n",
    "    plot_pos_rate(res_km['pos_rate'],\n",
    "                  \"K-Modes — Positive rate by cluster\",\n",
    "                  outdir / \"kmodes_posrate.png\")\n",
    "    plot_roc_curve(y_true, res_km['proba'],\n",
    "                   \"K-Modes — ROC (prob=cluster positive rate)\",\n",
    "                   outdir / \"kmodes_roc.png\")\n",
    "else:\n",
    "    print(\"⚠️ 'cluster_kmodes' not found in df; skipping K-Modes visuals.\")\n",
    "\n",
    "# ---------- Optional: silhouette/inertia over k (will plot if a grid is present) ----------\n",
    "grid_like = None\n",
    "for cand in (\"sph_grid\", \"mbkm_grid_df\", \"grid\"):\n",
    "    if cand in globals():\n",
    "        grid_like = globals()[cand]\n",
    "        break\n",
    "\n",
    "if isinstance(grid_like, pd.DataFrame) and {\"k\",\"silhouette\",\"inertia\"}.issubset(grid_like.columns):\n",
    "    g = grid_like.sort_values(\"k\")\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 3.6), dpi=120)\n",
    "    ax.plot(g[\"k\"], g[\"silhouette\"], marker=\"o\")\n",
    "    ax.set_title(\"Spherical K-Means — Silhouette vs k\")\n",
    "    ax.set_xlabel(\"k\"); ax.set_ylabel(\"silhouette\")\n",
    "    fig.tight_layout(); fig.savefig(outdir / \"sph_silhouette_vs_k.png\", dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 3.6), dpi=120)\n",
    "    ax.plot(g[\"k\"], g[\"inertia\"], marker=\"o\")\n",
    "    ax.set_title(\"Spherical K-Means — Inertia vs k\")\n",
    "    ax.set_xlabel(\"k\"); ax.set_ylabel(\"inertia\")\n",
    "    fig.tight_layout(); fig.savefig(outdir / \"sph_inertia_vs_k.png\", dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ℹ️ Silhouette/Inertia grid not found; skipping the k-sweep plots.\")\n",
    "\n",
    "# ---------- Summary table you can paste into the report ----------\n",
    "rows = []\n",
    "if 'res_sph' in locals():\n",
    "    rows.append([\"Spherical K-Means (k=7)\", res_sph[\"acc\"], res_sph[\"f1m\"], res_sph[\"auc\"], \"outputs_unsup/sph_confusion.png\"])\n",
    "if 'res_km' in locals():\n",
    "    rows.append([\"K-Modes (k=3)\", res_km[\"acc\"], res_km[\"f1m\"], res_km[\"auc\"], \"outputs_unsup/kmodes_confusion.png\"])\n",
    "if rows:\n",
    "    summary_df = pd.DataFrame(rows, columns=[\"Method\", \"Accuracy\", \"Macro-F1\", \"ROC-AUC\", \"Confusion image\"])\n",
    "    print(\"\\nUnsupervised summary:\\n\", summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153c5ba-8d6d-4d64-af76-6d1fb3822815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build spherical K-Means k-sweep table -> sph_grid\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 1) Ensure we have a normalized embedding Zs\n",
    "if 'Zs' not in globals():\n",
    "    if 'Xs' not in globals():\n",
    "        raise RuntimeError(\"Need Xs (sparse features) or Zs (embedding). Define one before running.\")\n",
    "    svd = TruncatedSVD(n_components=80, random_state=42)\n",
    "    Zs = svd.fit_transform(Xs)\n",
    "    Zs = normalize(Zs, norm='l2')\n",
    "\n",
    "# 2) Sweep k and compute silhouette (cosine) + inertia\n",
    "k_list = [3,4,5,6,7,8,9,10]\n",
    "rows = []\n",
    "rng = np.random.RandomState(42)\n",
    "n_sil = min(12000, Zs.shape[0])                      # subsample for speed\n",
    "sil_idx = rng.choice(Zs.shape[0], size=n_sil, replace=False)\n",
    "\n",
    "for k in k_list:\n",
    "    mbkm = MiniBatchKMeans(\n",
    "        n_clusters=k, random_state=42, batch_size=2048,\n",
    "        n_init=10, max_iter=100, reassignment_ratio=0.01\n",
    "    )\n",
    "    labels = mbkm.fit_predict(Zs)\n",
    "    inertia = float(mbkm.inertia_)\n",
    "    sil = float(silhouette_score(Zs[sil_idx], labels[sil_idx], metric=\"cosine\"))\n",
    "    rows.append((k, sil, inertia))\n",
    "\n",
    "sph_grid = pd.DataFrame(rows, columns=[\"k\",\"silhouette\",\"inertia\"]).sort_values(\"k\")\n",
    "print(\"Spherical K-Means grid:\\n\", sph_grid.to_string(index=False))\n",
    "\n",
    "# 3) (Optional) Persist/update best-k clustering to df['cluster_sph']\n",
    "best_k = int(sph_grid.sort_values(\"silhouette\", ascending=False).iloc[0].k)\n",
    "print(f\"\\nBest k by silhouette: {best_k}\")\n",
    "if 'df' in globals():\n",
    "    mbkm_best = MiniBatchKMeans(\n",
    "        n_clusters=best_k, random_state=42, batch_size=2048,\n",
    "        n_init=10, max_iter=100, reassignment_ratio=0.01\n",
    "    ).fit(Zs)\n",
    "    df['cluster_sph'] = mbkm_best.labels_\n",
    "    print(\"Updated df['cluster_sph'] with best-k labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2b8c0-4dd6-4f1b-bedc-eef2299c7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for spherical K-Means k-sweep (silhouette & inertia)\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "assert 'sph_grid' in globals(), \"Run the k-sweep cell first to create `sph_grid`.\"\n",
    "\n",
    "g = sph_grid.sort_values('k').reset_index(drop=True)\n",
    "outdir = Path(\"figs\"); outdir.mkdir(exist_ok=True)\n",
    "\n",
    "# Best k by silhouette\n",
    "best_k = int(g.loc[g['silhouette'].idxmax(), 'k'])\n",
    "best_sil = float(g['silhouette'].max())\n",
    "\n",
    "# 1) Silhouette vs k\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(g['k'], g['silhouette'], marker='o')\n",
    "ax.axvline(best_k, linestyle='--')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Silhouette (cosine)')\n",
    "ax.set_title('Spherical K-Means: Silhouette vs k')\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.savefig(outdir / 'sph_silhouette_vs_k.png', dpi=220, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {outdir / 'sph_silhouette_vs_k.png'}  |  best k={best_k} (silhouette={best_sil:.3f})\")\n",
    "\n",
    "# 2) Inertia vs k\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(g['k'], g['inertia'], marker='o')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Inertia')\n",
    "ax.set_title('Spherical K-Means: Inertia vs k')\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.savefig(outdir / 'sph_inertia_vs_k.png', dpi=220, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {outdir / 'sph_inertia_vs_k.png'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50998792-6c57-40a7-9c5d-0f0f8eb0bdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed6dab-20b6-40ef-9ca2-bff01abd9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Quick ensemble check: HGB on dense Zs + clusters ====\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- Build a compact, dense feature set ---\n",
    "assert 'cluster_sph' in df.columns, \"cluster_sph not found in df\"\n",
    "if 'cluster_kmodes' not in df.columns:\n",
    "    df['cluster_kmodes'] = -1  # fallback if not present\n",
    "\n",
    "# Zs must be a numpy array (n_samples, d). If you used 60 or 80 dims earlier, reuse it.\n",
    "assert 'Zs' in globals(), \"Zs (SVD embedding) is not in memory\"\n",
    "\n",
    "Z = pd.DataFrame(Zs, index=df.index, columns=[f\"z{i:02d}\" for i in range(Zs.shape[1])])\n",
    "C = pd.get_dummies(df[['cluster_sph','cluster_kmodes']].astype('category'),\n",
    "                   drop_first=False, prefix=['sph','km'])\n",
    "Xb = pd.concat([Z, C], axis=1)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(Xb, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.07,\n",
    "    max_leaf_nodes=31,\n",
    "    min_samples_leaf=20,\n",
    "    max_iter=500,\n",
    "    l2_regularization=1e-4,\n",
    "    class_weight='balanced',\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hgb.fit(Xtr, ytr)\n",
    "proba = hgb.predict_proba(Xte)[:, 1]\n",
    "pred  = (proba >= 0.50).astype(int)\n",
    "\n",
    "acc = accuracy_score(yte, pred)\n",
    "f1m = f1_score(yte, pred, average=\"macro\")\n",
    "auc = roc_auc_score(yte, proba)\n",
    "cm  = confusion_matrix(yte, pred)\n",
    "\n",
    "print(f\"HGB(Zs+clusters) — hold-out @0.50  acc={acc:.3f}  macro-F1={f1m:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @0.50:\\n\", cm)\n",
    "print(\"\\nReport:\\n\", classification_report(yte, pred, digits=3))\n",
    "\n",
    "# quick 3×CV for sanity (uses all rows)\n",
    "cv = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "scores = cross_validate(\n",
    "    hgb, Xb, y,\n",
    "    scoring={\"acc\":\"accuracy\",\"f1m\":\"f1_macro\",\"auc\":\"roc_auc\"},\n",
    "    cv=cv, n_jobs=-1, return_train_score=False\n",
    ")\n",
    "print(\"CV means: acc={:.3f}  f1m={:.3f}  auc={:.3f}\".format(\n",
    "    scores[\"test_acc\"].mean(), scores[\"test_f1m\"].mean(), scores[\"test_auc\"].mean()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ec3cb-b770-4018-a723-37cd24875767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccc8c5-3f19-45ed-8805-ceffb8c95a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HGB: threshold sweep + ROC/PR + confusion visuals ===\n",
    "import os, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    f1_score, confusion_matrix, classification_report, accuracy_score\n",
    ")\n",
    "\n",
    "# --- Safety checks & probability vector ---------------------------------------\n",
    "if 'yte' not in globals():\n",
    "    raise RuntimeError(\"`yte` not found. Run the HGB train/test split cell first.\")\n",
    "\n",
    "try:\n",
    "    _ = proba  # reuse if it exists\n",
    "except NameError:\n",
    "    if 'hgb' not in globals() or 'Xte' not in globals():\n",
    "        raise RuntimeError(\"Missing `hgb` and/or `Xte`. Run the HGB training cell first.\")\n",
    "    proba = hgb.predict_proba(Xte)[:, 1]\n",
    "\n",
    "# --- Metrics @ fixed threshold (0.50) -----------------------------------------\n",
    "pred_050 = (proba >= 0.50).astype(int)\n",
    "acc_050 = accuracy_score(yte, pred_050)\n",
    "f1m_050 = f1_score(yte, pred_050, average=\"macro\")\n",
    "auc_val = roc_auc_score(yte, proba)   # same for any threshold\n",
    "cm_050  = confusion_matrix(yte, pred_050)\n",
    "\n",
    "print(f\"HGB — hold-out @0.50  acc={acc_050:.3f}  macro-F1={f1m_050:.3f}  ROC-AUC={auc_val:.3f}\")\n",
    "print(\"Confusion @0.50:\\n\", cm_050)\n",
    "print(\"\\nReport @0.50:\\n\", classification_report(yte, pred_050, digits=3))\n",
    "\n",
    "# --- Threshold sweep for macro-F1 ---------------------------------------------\n",
    "ths = np.linspace(0.01, 0.99, 99)\n",
    "f1s = [f1_score(yte, (proba >= t).astype(int), average=\"macro\") for t in ths]\n",
    "best_idx = int(np.argmax(f1s))\n",
    "t_star   = float(ths[best_idx])\n",
    "f1m_star = float(f1s[best_idx])\n",
    "pred_star = (proba >= t_star).astype(int)\n",
    "acc_star  = accuracy_score(yte, pred_star)\n",
    "cm_star   = confusion_matrix(yte, pred_star)\n",
    "\n",
    "print(f\"\\nBest threshold for macro-F1: {t_star:.3f}\")\n",
    "print(f\"Hold-out @{t_star:.3f}  acc={acc_star:.3f}  macro-F1={f1m_star:.3f}  ROC-AUC={auc_val:.3f}\")\n",
    "print(\"Confusion @t*:\\n\", cm_star)\n",
    "\n",
    "# --- Prepare output dir --------------------------------------------------------\n",
    "out_dir = \"figs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# --- Helper: plot confusion matrix (counts) -----------------------------------\n",
    "def plot_confusion(cm, title, out_path):\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    im = ax.imshow(cm)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0, 1]); ax.set_yticks([0, 1])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f\"{int(cm[i, j])}\", ha=\"center\", va=\"center\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 1) ROC curve --------------------------------------------------------------\n",
    "fpr, tpr, _ = roc_curve(yte, proba)\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"HGB (Zs+clusters) — ROC\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{out_dir}/hgb_roc.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# --- 2) Precision–Recall curve -------------------------------------------------\n",
    "prec, rec, _ = precision_recall_curve(yte, proba)\n",
    "ap = average_precision_score(yte, proba)\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"HGB (Zs+clusters) — Precision–Recall\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{out_dir}/hgb_pr.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# --- 3) Threshold sweep plot ---------------------------------------------------\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "plt.plot(ths, f1s)\n",
    "plt.axvline(0.50, linestyle=\"--\")\n",
    "plt.axvline(t_star, linestyle=\":\")\n",
    "plt.xlabel(\"Threshold\"); plt.ylabel(\"Macro-F1\")\n",
    "plt.title(\"HGB — Macro-F1 vs Threshold\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{out_dir}/hgb_threshold_sweep.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# --- 4) Confusion matrices (@0.50 and @t*) ------------------------------------\n",
    "plot_confusion(cm_050, \"HGB — Confusion (hold-out @0.50)\", f\"{out_dir}/hgb_confusion_050.png\")\n",
    "plot_confusion(cm_star, f\"HGB — Confusion (hold-out @{t_star:.3f})\", f\"{out_dir}/hgb_confusion_best.png\")\n",
    "\n",
    "print(\"\\nSaved figure files:\")\n",
    "for f in [\"hgb_roc.png\", \"hgb_pr.png\", \"hgb_threshold_sweep.png\", \"hgb_confusion_050.png\", \"hgb_confusion_best.png\"]:\n",
    "    p = os.path.join(out_dir, f)\n",
    "    print(\" -\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0823a5-a0ff-4c51-8cba-6a9c7763c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045517a3-e20b-4d72-89da-ad9edc929384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, joblib\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "os.makedirs(\"artifacts/hgb\", exist_ok=True)\n",
    "\n",
    "# assume yte and proba from your last cell\n",
    "metrics = {\n",
    "    \"model\": \"HGB (hybrid features)\",\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"threshold_default\": 0.50,\n",
    "    \"threshold_star\": float(0.530),   # from your output\n",
    "    \"acc@0.50\": float(accuracy_score(yte, (proba>=0.50).astype(int))),\n",
    "    \"f1_macro@0.50\": float(f1_score(yte, (proba>=0.50).astype(int), average=\"macro\")),\n",
    "    \"acc@t*\": float(accuracy_score(yte, (proba>=0.530).astype(int))),\n",
    "    \"f1_macro@t*\": float(f1_score(yte, (proba>=0.530).astype(int), average=\"macro\")),\n",
    "    \"roc_auc\": float(roc_auc_score(yte, proba))\n",
    "}\n",
    "\n",
    "with open(\"artifacts/hgb/hgb_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# Save the estimator object (pipeline or bare model), whichever you used\n",
    "to_save = None\n",
    "if 'pipe_hgb' in globals():\n",
    "    to_save = pipe_hgb\n",
    "elif 'hgb' in globals():\n",
    "    to_save = hgb\n",
    "else:\n",
    "    raise RuntimeError(\"No HGB estimator found (hgb/pipe_hgb).\")\n",
    "\n",
    "joblib.dump(to_save, \"artifacts/hgb/hgb_model.joblib\")\n",
    "\n",
    "# Also keep a one-row CSV for your report table\n",
    "import pandas as pd\n",
    "row = pd.DataFrame([{\n",
    "    \"Model\":\"HGB (hybrid)\",\n",
    "    \"Tuned?\":\"No (baseline)\",\n",
    "    \"Threshold\":\"0.530\",\n",
    "    \"Accuracy\":metrics[\"acc@t*\"],\n",
    "    \"Macro-F1\":metrics[\"f1_macro@t*\"],\n",
    "    \"ROC-AUC\":metrics[\"roc_auc\"]\n",
    "}])\n",
    "row.to_csv(\"artifacts/hgb/hgb_table_row.csv\", index=False)\n",
    "\n",
    "print(\"Saved: artifacts/hgb/hgb_model.joblib, hgb_metrics.json, hgb_table_row.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2cfeb-28f0-4e12-8dde-e5664022893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db559a1-b03b-4459-b6e3-3d735344978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HGB with SVD compression (recommended) ---\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,\n",
    "                             confusion_matrix)\n",
    "\n",
    "# pre_h = your existing ColumnTransformer (impute + OHE that yields sparse)\n",
    "# Xh, y, and your holdout split (Xte, yte) already exist from earlier cells.\n",
    "\n",
    "pipe_hgb_svd = Pipeline([\n",
    "    (\"pre\", pre_h),                                    # sparse out\n",
    "    (\"svd\", TruncatedSVD(n_components=120, random_state=42)),\n",
    "    (\"sc\",  StandardScaler()),                         # dense scaling\n",
    "    (\"clf\", HistGradientBoostingClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"svd__n_components\": [80, 120, 160],\n",
    "    \"clf__learning_rate\": list(np.logspace(-2.2, -0.5, 6)),  # ~0.006–0.316\n",
    "    \"clf__max_iter\": [200, 300, 400],\n",
    "    \"clf__max_depth\": [None, 3, 4],\n",
    "    \"clf__max_leaf_nodes\": [31, 63],\n",
    "    \"clf__min_samples_leaf\": [20, 50],\n",
    "    \"clf__l2_regularization\": [0.0, 0.1, 1.0],\n",
    "    \"clf__max_bins\": [255],\n",
    "}\n",
    "\n",
    "rs_hgb = RandomizedSearchCV(\n",
    "    pipe_hgb_svd,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=12, cv=3, scoring=\"f1_macro\",\n",
    "    n_jobs=-1, verbose=2, random_state=42, refit=True\n",
    ")\n",
    "rs_hgb.fit(Xh, y)\n",
    "\n",
    "print(\"Best params:\", rs_hgb.best_params_)\n",
    "print(\"Best CV macro-F1:\", rs_hgb.best_score_)\n",
    "\n",
    "# ---- Hold-out evaluation (same style as before) ----\n",
    "proba = rs_hgb.predict_proba(Xte)[:, 1]\n",
    "pred50 = (proba >= 0.50).astype(int)\n",
    "\n",
    "ths = np.linspace(0.01, 0.99, 99)\n",
    "f1s = [f1_score(yte, (proba >= t).astype(int), average=\"macro\") for t in ths]\n",
    "t_star = float(ths[int(np.argmax(f1s))])\n",
    "pred_star = (proba >= t_star).astype(int)\n",
    "\n",
    "print(f\"\\nTUNED HGB(SVD) — @0.50  acc={accuracy_score(yte,pred50):.3f}  \"\n",
    "      f\"f1m={f1_score(yte,pred50,average='macro'):.3f}  auc={roc_auc_score(yte,proba):.3f}\")\n",
    "print(f\"TUNED HGB(SVD) — @{t_star:.3f}  acc={accuracy_score(yte,pred_star):.3f}  \"\n",
    "      f\"f1m={f1_score(yte,pred_star,average='macro'):.3f}\")\n",
    "print(\"Confusion @t*:\\n\", confusion_matrix(yte, pred_star))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f3b1f-a112-4d17-8f97-27fb564e525a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0de771-7640-4fef-aadf-e5ade9e975a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate tuned HGB(SVD) on a consistent hold-out -----------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 1) Make a FRESH split from the SAME Xh,y you used for RandomizedSearchCV\n",
    "Xtr2, Xte2, ytr2, yte2 = train_test_split(\n",
    "    Xh, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2) Grab the tuned pipeline and refit on TRAIN ONLY\n",
    "best_hgb = rs_hgb.best_estimator_      # this is your Pipeline(pre -> svd -> sc -> HGB)\n",
    "best_hgb.fit(Xtr2, ytr2)\n",
    "\n",
    "# 3) Predict on the aligned test slice\n",
    "proba = best_hgb.predict_proba(Xte2)[:, 1]\n",
    "pred50 = (proba >= 0.50).astype(int)\n",
    "\n",
    "# threshold sweep for best macro-F1\n",
    "ths = np.linspace(0.01, 0.99, 99)\n",
    "f1s = [f1_score(yte2, (proba >= t).astype(int), average=\"macro\") for t in ths]\n",
    "t_star = float(ths[int(np.argmax(f1s))])\n",
    "pred_star = (proba >= t_star).astype(int)\n",
    "\n",
    "# 4) Metrics\n",
    "acc50 = accuracy_score(yte2, pred50)\n",
    "f1m50 = f1_score(yte2, pred50, average=\"macro\")\n",
    "auc   = roc_auc_score(yte2, proba)\n",
    "\n",
    "accs  = accuracy_score(yte2, pred_star)\n",
    "f1ms  = f1_score(yte2, pred_star, average=\"macro\")\n",
    "\n",
    "print(\"Best params (CV):\", rs_hgb.best_params_)\n",
    "print(f\"Best CV macro-F1: {rs_hgb.best_score_:.3f}\")\n",
    "\n",
    "print(f\"\\nTUNED HGB(SVD) — hold-out @0.50  acc={acc50:.3f}  macro-F1={f1m50:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @0.50:\\n\", confusion_matrix(yte2, pred50))\n",
    "\n",
    "print(f\"\\nBest threshold for macro-F1: {t_star:.3f}\")\n",
    "print(f\"Hold-out @{t_star:.3f}  acc={accs:.3f}  macro-F1={f1ms:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @t*:\\n\", confusion_matrix(yte2, pred_star))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd23579-9dc6-4a1e-b814-09e4d83d2f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e268e7-0610-4cc6-a747-5dd1206e93fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1719d-b5fc-4925-b9fb-c6eabdd4d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Bulletproof eval for tuned HGB(SVD): hard NA sanitization + eval =====\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "best = rs_hgb.best_estimator_         # Pipeline(pre -> svd -> hgb)\n",
    "pre  = best.named_steps[\"pre\"]         # ColumnTransformer\n",
    "\n",
    "# --- 1) Recover exact training columns and split (num/cat) ---\n",
    "try:\n",
    "    expected_cols = list(pre.feature_names_in_)\n",
    "except AttributeError:\n",
    "    expected_cols = []\n",
    "    for name, trans, cols in pre.transformers_:\n",
    "        expected_cols.extend(list(cols))\n",
    "\n",
    "num_cols, cat_cols = [], []\n",
    "for name, trans, cols in pre.transformers_:\n",
    "    if name == \"num\":\n",
    "        num_cols = list(cols)\n",
    "    elif name == \"cat\":\n",
    "        cat_cols = list(cols)\n",
    "\n",
    "# --- 2) Build DataFrame with EXACT columns; HARD sanitize all pd.NA -> np.nan ---\n",
    "Xall = df.reindex(columns=expected_cols)\n",
    "\n",
    "# 2a) Nuke all extension dtypes by going to object first (so replacements stick)\n",
    "Xall = Xall.astype(\"object\")\n",
    "\n",
    "# 2b) Replace ANY missing-like value (incl. pd.NA) with real np.nan in one shot\n",
    "Xall = Xall.where(pd.notna(Xall), np.nan)\n",
    "\n",
    "# 2c) Restore numeric branch to float64; coerce stray strings to NaN\n",
    "if num_cols:\n",
    "    Xall.loc[:, num_cols] = (\n",
    "        Xall[num_cols]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .astype(\"float64\")\n",
    "    )\n",
    "\n",
    "# 2d) Categorical branch stays as plain 'object'\n",
    "\n",
    "# --- 3) Safety net: if any pd.NA still survives, force-replace per-cell ---\n",
    "stubborn_cols = []\n",
    "for c in Xall.columns:\n",
    "    s = Xall[c]\n",
    "    if s.dtype == \"object\":\n",
    "        if any((v is pd.NA) for v in s.values):\n",
    "            stubborn_cols.append(c)\n",
    "if stubborn_cols:\n",
    "    # Slow but surgical: guaranteed pd.NA -> np.nan conversion\n",
    "    Xall.loc[:, stubborn_cols] = Xall[stubborn_cols].applymap(\n",
    "        lambda v: np.nan if v is pd.NA else v\n",
    "    )\n",
    "\n",
    "# --- 4) Use your existing hold-out indices if available, else recreate ---\n",
    "try:\n",
    "    te_idx  = yte.index\n",
    "    Xte     = Xall.loc[te_idx]\n",
    "    y_eval  = yte\n",
    "except NameError:\n",
    "    _, Xte, _, y_eval = train_test_split(\n",
    "        Xall, y, test_size=0.20, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "# --- 5) Predict + threshold sweep (macro-F1) ---\n",
    "proba  = best.predict_proba(Xte)[:, 1]\n",
    "pred50 = (proba >= 0.50).astype(int)\n",
    "\n",
    "ths = np.linspace(0.01, 0.99, 99)\n",
    "f1s = [f1_score(y_eval, (proba >= t).astype(int), average=\"macro\") for t in ths]\n",
    "t_star = float(ths[int(np.argmax(f1s))])\n",
    "predst = (proba >= t_star).astype(int)\n",
    "\n",
    "auc   = float(roc_auc_score(y_eval, proba))\n",
    "acc50 = float((pred50 == y_eval).mean())\n",
    "f1m50 = float(f1_score(y_eval, pred50, average=\"macro\"))\n",
    "accst = float((predst == y_eval).mean())\n",
    "f1mst = float(f1_score(y_eval, predst, average=\"macro\"))\n",
    "\n",
    "print(f\"TUNED HGB(SVD) — hold-out @0.50  acc={acc50:.3f}  macro-F1={f1m50:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @0.50:\\n\", confusion_matrix(y_eval, pred50))\n",
    "print(f\"\\nBest threshold for macro-F1: {t_star:.3f}\")\n",
    "print(f\"Hold-out @{t_star:.3f}  acc={accst:.3f}  macro-F1={f1mst:.3f}  ROC-AUC={auc:.3f}\")\n",
    "print(\"Confusion @t*:\\n\", confusion_matrix(y_eval, predst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb4737-17f5-4434-9186-95ccda2874b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31482190-5154-4455-b9fe-74ab350b2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== HGB(SVD) visuals + export (safe to rerun) ====\n",
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, f1_score\n",
    "\n",
    "# Expect: best (pipeline), Xte, y_eval exist. If not, adjust to your var names.\n",
    "# Recompute proba to be safe.\n",
    "proba  = best.predict_proba(Xte)[:, 1]\n",
    "pred50 = (proba >= 0.50).astype(int)\n",
    "\n",
    "# Threshold sweep (macro-F1)\n",
    "ths = np.linspace(0.01, 0.99, 99)\n",
    "f1s = [f1_score(y_eval, (proba >= t).astype(int), average=\"macro\") for t in ths]\n",
    "t_star = float(ths[int(np.argmax(f1s))])\n",
    "predst = (proba >= t_star).astype(int)\n",
    "\n",
    "# Metrics\n",
    "cm50  = confusion_matrix(y_eval, pred50)\n",
    "cmst  = confusion_matrix(y_eval, predst)\n",
    "fpr, tpr, _ = roc_curve(y_eval, proba)\n",
    "roc_auc     = auc(fpr, tpr)\n",
    "prec, rec, _= precision_recall_curve(y_eval, proba)\n",
    "\n",
    "acc50 = float((pred50 == y_eval).mean())\n",
    "f1m50 = float(f1_score(y_eval, pred50, average=\"macro\"))\n",
    "accst = float((predst == y_eval).mean())\n",
    "f1mst = float(f1_score(y_eval, predst, average=\"macro\"))\n",
    "\n",
    "print(f\"HGB(SVD) @0.50  acc={acc50:.3f}  f1m={f1m50:.3f}  AUC={roc_auc:.3f}\")\n",
    "print(f\"HGB(SVD) @{t_star:.3f}  acc={accst:.3f}  f1m={f1mst:.3f}  AUC={roc_auc:.3f}\")\n",
    "\n",
    "# --- plotting helpers ---\n",
    "def plot_confusion(cm, title):\n",
    "    fig, ax = plt.subplots(figsize=(4.8, 4.2))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i,j]), ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 1) Confusion @0.50 and @t*\n",
    "plot_confusion(cm50, \"HGB(SVD) — Confusion @0.50\")\n",
    "plot_confusion(cmst, f\"HGB(SVD) — Confusion @{t_star:.3f}\")\n",
    "\n",
    "# 2) ROC curve\n",
    "fig, ax = plt.subplots(figsize=(5.2, 4.4))\n",
    "ax.plot(fpr, tpr, lw=2, label=f\"AUC={roc_auc:.3f}\")\n",
    "ax.plot([0,1], [0,1], lw=1, linestyle=\"--\")\n",
    "ax.set_title(\"HGB(SVD) — ROC curve\")\n",
    "ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) Precision–Recall curve\n",
    "fig, ax = plt.subplots(figsize=(5.2, 4.4))\n",
    "ax.plot(rec, prec, lw=2)\n",
    "ax.set_title(\"HGB(SVD) — Precision–Recall\")\n",
    "ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 4) Threshold sweep (macro-F1)\n",
    "fig, ax = plt.subplots(figsize=(5.2, 4.4))\n",
    "ax.plot(ths, f1s, lw=2)\n",
    "ax.axvline(t_star, linestyle=\"--\")\n",
    "ax.set_title(\"HGB(SVD) — Macro-F1 vs Threshold\")\n",
    "ax.set_xlabel(\"Decision threshold\"); ax.set_ylabel(\"Macro-F1\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 5) Export a tidy table row with params + metrics\n",
    "outdir = Path(\"reports\"); outdir.mkdir(exist_ok=True)\n",
    "row = {\n",
    "    \"model\": \"HGB(SVD)\",\n",
    "    \"threshold_50\": 0.50,\n",
    "    \"acc_50\": acc50, \"macro_f1_50\": f1m50, \"roc_auc\": roc_auc,\n",
    "    \"threshold_star\": t_star,\n",
    "    \"acc_star\": accst, \"macro_f1_star\": f1mst,\n",
    "}\n",
    "# add best params if available\n",
    "try:\n",
    "    for k, v in rs_hgb.best_params_.items():\n",
    "        row[k] = v\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "pd.DataFrame([row]).to_csv(outdir / \"hgb_svd_table_row.csv\", index=False)\n",
    "print(f\"Saved table row -> {outdir/'hgb_svd_table_row.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecc20c-dad1-465f-af64-5314722897d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d60b1c-db5f-49d7-b171-cb31df17ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CHECKPOINT NOW: persist models, metadata, splits, and results ====\n",
    "from pathlib import Path\n",
    "import json, joblib, numpy as np, pandas as pd\n",
    "import sklearn, sys, platform, datetime as dt\n",
    "\n",
    "ART = Path(\"artifacts\"); ART.mkdir(exist_ok=True)\n",
    "print(f\"Saving to: {ART.resolve()}\")\n",
    "\n",
    "# 1) Core data (lightweight + reproducible)\n",
    "if 'y' in globals():\n",
    "    pd.Series(y).to_csv(ART/\"y.csv\", index=True)\n",
    "if 'df' in globals():\n",
    "    # Save only columns we actually used in hybrid features if available\n",
    "    cols_to_save = None\n",
    "    if 'hyb_cols' in globals():\n",
    "        cols_to_save = list(dict.fromkeys(hyb_cols))\n",
    "    elif 'use_cols' in globals():\n",
    "        # fall back to base features; clusters/cosdist might be missing on reload\n",
    "        cols_to_save = list(dict.fromkeys(use_cols))\n",
    "    if cols_to_save is not None:\n",
    "        df[cols_to_save].to_parquet(ART/\"df_features.parquet\")\n",
    "        json.dump(cols_to_save, open(ART/\"hyb_cols.json\",\"w\"))\n",
    "        print(f\"Saved df_features.parquet with {len(cols_to_save)} columns.\")\n",
    "    else:\n",
    "        # as a last resort (larger file), save the whole frame\n",
    "        df.to_parquet(ART/\"df_full.parquet\")\n",
    "        print(\"Saved df_full.parquet (fallback).\")\n",
    "\n",
    "# 2) Train/hold-out split indices (so you can reproduce evaluation fast)\n",
    "def _save_index(name, X):\n",
    "    idx = getattr(X, \"index\", None)\n",
    "    if idx is not None:\n",
    "        pd.Index(idx).to_series(name=\"index\").to_csv(ART/f\"{name}_index.csv\", index=False)\n",
    "\n",
    "for nm in (\"Xtr\",\"Xte\",\"ytr\",\"y_eval\"):\n",
    "    if nm in globals():\n",
    "        _save_index(nm, globals()[nm])\n",
    "\n",
    "# 3) Pipelines / models\n",
    "# Hybrid Logistic (elastic net) – try to save the tuned one first\n",
    "if 'rs' in globals() and getattr(rs, 'best_estimator_', None) is not None:\n",
    "    joblib.dump(rs.best_estimator_, ART/\"hybrid_logreg_enet_best.joblib\")\n",
    "elif 'pipe_hybrid' in globals():\n",
    "    joblib.dump(pipe_hybrid, ART/\"hybrid_logreg_enet_pipe.joblib\")\n",
    "\n",
    "# Tuned HGB(SVD)\n",
    "if 'rs_hgb' in globals() and getattr(rs_hgb, 'best_estimator_', None) is not None:\n",
    "    joblib.dump(rs_hgb.best_estimator_, ART/\"hgb_svd_best.joblib\")\n",
    "elif 'best' in globals():\n",
    "    joblib.dump(best, ART/\"hgb_svd_best.joblib\")\n",
    "\n",
    "# 4) CV results and single-row summaries if you’ve created them\n",
    "if 'rs' in globals() and hasattr(rs, \"cv_results_\"):\n",
    "    pd.DataFrame(rs.cv_results_).to_csv(ART/\"cv_hybrid_logreg_enet.csv\", index=False)\n",
    "if 'rs_hgb' in globals() and hasattr(rs_hgb, \"cv_results_\"):\n",
    "    pd.DataFrame(rs_hgb.cv_results_).to_csv(ART/\"cv_hgb_svd.csv\", index=False)\n",
    "\n",
    "for fname in (\"hybrid_logreg_enet_table_row.csv\", \"hgb_svd_table_row.csv\",\n",
    "              \"hybrid_logreg_enet_summary.json\"):\n",
    "    p = Path(fname)\n",
    "    if p.exists():\n",
    "        p.replace(ART/p.name)\n",
    "\n",
    "# 5) Minimal manifest (helps future-you)\n",
    "manifest = {\n",
    "    \"timestamp_utc\": dt.datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"python\": sys.version.split()[0],\n",
    "    \"sklearn\": sklearn.__version__,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"artifacts\": sorted([p.name for p in ART.iterdir() if p.is_file()]),\n",
    "}\n",
    "json.dump(manifest, open(ART/\"manifest.json\",\"w\"), indent=2)\n",
    "print(\"Wrote manifest.json\")\n",
    "print(\"Done ✅ — you can safely stop the kernel after this cell finishes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be647d3d-f720-4a1c-b8ce-8b2275a294b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== RESUME LATER: reload models, data, and splits (pandas>=2 friendly) ====\n",
    "from pathlib import Path\n",
    "import joblib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ART = Path(\"artifacts\")\n",
    "assert ART.exists(), \"No artifacts/ folder found. Did you run the checkpoint cell?\"\n",
    "\n",
    "# Load y as a Series (works whether the CSV had a header or not)\n",
    "ydf = pd.read_csv(ART / \"y.csv\", index_col=0)\n",
    "y = ydf.iloc[:, 0]\n",
    "if y.name is None or y.name == \"\":\n",
    "    y.name = \"target\"\n",
    "\n",
    "# Load features DF (prefer slim feature parquet, else full)\n",
    "if (ART / \"df_features.parquet\").exists():\n",
    "    df = pd.read_parquet(ART / \"df_features.parquet\")\n",
    "    hyb_cols = json.load(open(ART / \"hyb_cols.json\"))\n",
    "elif (ART / \"df_full.parquet\").exists():\n",
    "    df = pd.read_parquet(ART / \"df_full.parquet\")\n",
    "    hyb_cols = list(df.columns)\n",
    "else:\n",
    "    raise FileNotFoundError(\"No data parquet found in artifacts/\")\n",
    "\n",
    "# Rebuild Xh exactly as saved\n",
    "Xh = df[hyb_cols].copy()\n",
    "\n",
    "# Load split indices if present\n",
    "def _maybe_idx(name):\n",
    "    p = ART / f\"{name}_index.csv\"\n",
    "    if p.exists():\n",
    "        return pd.read_csv(p)[\"index\"]\n",
    "    return None\n",
    "\n",
    "idx_Xte = _maybe_idx(\"Xte\")\n",
    "idx_yte = _maybe_idx(\"y_eval\")\n",
    "\n",
    "if idx_Xte is not None and idx_yte is not None:\n",
    "    Xte = Xh.loc[idx_Xte]\n",
    "    y_eval = y.loc[idx_yte]\n",
    "    print(f\"Restored hold-out: Xte={Xte.shape}, y_eval={y_eval.shape}\")\n",
    "else:\n",
    "    print(\"Split indices not found — you can re-run train_test_split if needed.\")\n",
    "\n",
    "# Load models\n",
    "best_hgb = None\n",
    "best_log = None\n",
    "if (ART / \"hgb_svd_best.joblib\").exists():\n",
    "    best_hgb = joblib.load(ART / \"hgb_svd_best.joblib\")\n",
    "    print(\"Loaded: hgb_svd_best.joblib\")\n",
    "if (ART / \"hybrid_logreg_enet_best.joblib\").exists():\n",
    "    best_log = joblib.load(ART / \"hybrid_logreg_enet_best.joblib\")\n",
    "    print(\"Loaded: hybrid_logreg_enet_best.joblib\")\n",
    "elif (ART / \"hybrid_logreg_enet_pipe.joblib\").exists():\n",
    "    best_log = joblib.load(ART / \"hybrid_logreg_enet_pipe.joblib\")\n",
    "    print(\"Loaded: hybrid_logreg_enet_pipe.joblib\")\n",
    "\n",
    "print(\"Ready ✅ — models and data are reloaded. You can call predict_proba on Xte immediately.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd0c0c-4dc8-49c5-9649-27d68f117ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0e4fd-5f00-4d6c-988a-8d7425b1057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "def make_sklearn_friendly(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Normalize null sentinel first\n",
    "    df = df.replace({pd.NA: np.nan})\n",
    "\n",
    "    # 2) Extension numerics -> plain float64 so np.nan works everywhere\n",
    "    for col in df.columns:\n",
    "        dt = df[col].dtype\n",
    "        if str(dt) in (\"Int64\", \"UInt64\", \"Float64\"):\n",
    "            df[col] = df[col].astype(\"float64\")\n",
    "\n",
    "    # 3) Extension booleans / pandas string -> object (avoid pd.NA semantics)\n",
    "    bool_ext = df.select_dtypes(include=[\"boolean\"]).columns\n",
    "    if len(bool_ext):\n",
    "        df[bool_ext] = df[bool_ext].astype(\"object\")\n",
    "\n",
    "    str_ext = df.select_dtypes(include=[\"string\"]).columns\n",
    "    if len(str_ext):\n",
    "        df[str_ext] = df[str_ext].astype(\"object\")\n",
    "\n",
    "    # 4) Force object/category cols to be writable NumPy arrays, then fix nulls\n",
    "    obj_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for c in obj_cols:\n",
    "        arr = df[c].to_numpy(dtype=object, copy=True)  # ensures WRITABLE\n",
    "        m = pd.isna(arr)\n",
    "        if m.any():\n",
    "            arr[m] = np.nan\n",
    "        df[c] = arr  # assign back as a fresh, writeable column\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to the frames you use for evaluation/plots\n",
    "Xte = make_sklearn_friendly(Xte)\n",
    "Xh  = make_sklearn_friendly(Xh)\n",
    "\n",
    "# quick sanity checks\n",
    "assert not any(dt.name == \"boolean\" for dt in Xte.dtypes)\n",
    "assert not any(s in str(dt) for dt in Xte.dtypes for s in (\"Int64\",\"UInt64\",\"Float64\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfdbd77-0b06-4fdf-b119-0cc52bbe9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Permutation importance + plots (robust) -------------------------------\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# ---------- 0) Helper: sanitize a DataFrame for sklearn ----------\n",
    "def make_sklearn_friendly(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # unify nulls\n",
    "    df = df.replace({pd.NA: np.nan})\n",
    "    # extension numerics -> float64 (so np.nan is valid)\n",
    "    for c in df.columns:\n",
    "        dt = df[c].dtype\n",
    "        if str(dt) in (\"Int64\", \"UInt64\", \"Float64\"):\n",
    "            df[c] = df[c].astype(\"float64\")\n",
    "    # extension booleans / pandas strings -> object\n",
    "    bool_ext = df.select_dtypes(include=[\"boolean\"]).columns\n",
    "    if len(bool_ext):\n",
    "        df[bool_ext] = df[bool_ext].astype(\"object\")\n",
    "    str_ext = df.select_dtypes(include=[\"string\"]).columns\n",
    "    if len(str_ext):\n",
    "        df[str_ext] = df[str_ext].astype(\"object\")\n",
    "    # ensure object/category columns are writable & use real np.nan\n",
    "    obj_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for c in obj_cols:\n",
    "        arr = df[c].to_numpy(dtype=object, copy=True)   # writeable\n",
    "        m = pd.isna(arr)\n",
    "        if m.any():\n",
    "            arr[m] = np.nan\n",
    "        df[c] = arr\n",
    "    return df\n",
    "\n",
    "# Apply to your frames (no-op if already clean)\n",
    "Xte = make_sklearn_friendly(Xte)\n",
    "Xh  = make_sklearn_friendly(Xh)\n",
    "\n",
    "# Small safety checks\n",
    "assert isinstance(Xte, pd.DataFrame), \"Xte must be a DataFrame\"\n",
    "assert isinstance(Xh, pd.DataFrame), \"Xh must be a DataFrame\"\n",
    "assert \"y_eval\" in globals(), \"y_eval (hold-out y) not found\"\n",
    "\n",
    "print(f\"Sanitized: Xte shape={Xte.shape}, y_eval={y_eval.shape}\")\n",
    "\n",
    "# ---------- 1) Helper to compute PI and make a tidy dataframe ----------\n",
    "def perm_importance_df(estimator, X: pd.DataFrame, y, *,\n",
    "                       scoring=\"f1_macro\", n_repeats=8, n_jobs=4, random_state=42):\n",
    "    pi = permutation_importance(\n",
    "        estimator, X, y,\n",
    "        scoring=scoring, n_repeats=n_repeats,\n",
    "        n_jobs=n_jobs, random_state=random_state\n",
    "    )\n",
    "    out = (pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"importance_mean\": pi.importances_mean,\n",
    "        \"importance_std\":  pi.importances_std,\n",
    "    })\n",
    "    .sort_values(\"importance_mean\", ascending=False)\n",
    "    .reset_index(drop=True))\n",
    "    return out\n",
    "\n",
    "# ---------- 2) Plot helper ----------\n",
    "def plot_topk_bars(df_imp: pd.DataFrame, title: str, k: int = 20):\n",
    "    k = min(k, len(df_imp))\n",
    "    top = df_imp.head(k).iloc[::-1]  # reverse so the biggest is at the top of the barh\n",
    "    fig, ax = plt.subplots(figsize=(8, 0.35*k + 1.5))\n",
    "    ax.barh(top[\"feature\"], top[\"importance_mean\"])\n",
    "    ax.set_xlabel(\"Permutation importance (mean Δ score)\")\n",
    "    ax.set_title(title)\n",
    "    # error bars\n",
    "    for i, (m, s) in enumerate(zip(top[\"importance_mean\"], top[\"importance_std\"])):\n",
    "        ax.errorbar(m, i, xerr=s, fmt='none', capsize=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---------- 3) Run for each available champion model ----------\n",
    "models = []\n",
    "if \"best_hgb\" in globals():\n",
    "    models.append((\"HGB(SVD) champion\", best_hgb))\n",
    "if \"best_logit\" in globals():\n",
    "    models.append((\"Hybrid LogReg champion\", best_logit))\n",
    "\n",
    "if not models:\n",
    "    raise RuntimeError(\"No champion models found. Expected variables: best_hgb and/or best_logit.\")\n",
    "\n",
    "for name, est in models:\n",
    "    print(f\"\\n▶ Permutation importance for {name}\")\n",
    "    imp_df = perm_importance_df(est, Xte, y_eval, scoring=\"f1_macro\", n_repeats=8, n_jobs=4)\n",
    "    display(imp_df.head(25))\n",
    "    plot_topk_bars(imp_df, f\"{name} — Top features (permutation)\", k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5823380-398f-42e6-b5ac-100eb95f5215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4301fd1-3406-45ff-872c-d3c60d51962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOAL\n",
    "#Estimate mean ± std importance per feature across several seeds, plus how often each feature appears in the top-K (stability score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38117e16-2dd1-445b-85c9-8fad9d84f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 0) FIND & LOAD THE ESTIMATOR ARTIFACT ====\n",
    "import os, sys, glob\n",
    "from joblib import load\n",
    "\n",
    "def find_model_candidates():\n",
    "    # likely names/locations\n",
    "    explicit = [\n",
    "        \"hgb_svd_best.joblib\",\n",
    "        \"models/hgb_svd_best.joblib\",\n",
    "        \"artifacts/hgb_svd_best.joblib\",\n",
    "        \"outputs/hgb_svd_best.joblib\",\n",
    "        \"models/hgb_svd.joblib\",\n",
    "    ]\n",
    "    cands = [p for p in explicit if os.path.exists(p)]\n",
    "\n",
    "    # generic search: any .joblib that looks like HGB or SVD or champion\n",
    "    patterns = [\n",
    "        \"**/*hgb*joblib\", \"**/*svd*joblib\", \"**/*gradient*joblib\",\n",
    "        \"**/*champion*joblib\", \"**/*.joblib\"\n",
    "    ]\n",
    "    roots = [os.getcwd()]\n",
    "    # add mlflow default folder if present\n",
    "    if os.path.exists(\"mlruns\"):\n",
    "        roots.append(\"mlruns\")\n",
    "    # search\n",
    "    for root in roots:\n",
    "        for pat in patterns:\n",
    "            cands.extend(glob.glob(os.path.join(root, pat), recursive=True))\n",
    "    # de-dup while preserving order\n",
    "    seen, uniq = set(), []\n",
    "    for p in cands:\n",
    "        if p not in seen:\n",
    "            seen.add(p); uniq.append(p)\n",
    "    return uniq\n",
    "\n",
    "model_path = None\n",
    "try:\n",
    "    model_path = \"hgb_svd_best.joblib\"\n",
    "    estimator = load(model_path)\n",
    "except Exception:\n",
    "    # search for alternatives\n",
    "    candidates = find_model_candidates()\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find any *.joblib model artifact. \"\n",
    "            \"Check your save path or re-save the trained model with:\\n\"\n",
    "            \"from joblib import dump; dump(hgb_svd_best, 'hgb_svd_best.joblib')\"\n",
    "        )\n",
    "    # prefer candidates with 'hgb' and 'svd' in name\n",
    "    def score(path):\n",
    "        name = os.path.basename(path).lower()\n",
    "        s = 0\n",
    "        for kw in (\"hgb\", \"hist\", \"gradient\", \"boost\"):\n",
    "            if kw in name: s += 2\n",
    "        for kw in (\"svd\", \"pipe\", \"pipeline\"):\n",
    "            if kw in name: s += 1\n",
    "        return s\n",
    "    candidates.sort(key=score, reverse=True)\n",
    "    model_path = candidates[0]\n",
    "    estimator = load(model_path)\n",
    "\n",
    "print(f\"Loaded estimator from: {model_path}\")\n",
    "# optional alias expected by earlier code\n",
    "hgb_svd_best = estimator\n",
    "\n",
    "# ==== 1) STABILITY: permutation importance across seeds ====\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "SEEDS = [0, 1, 2, 3, 4, 7, 13, 21, 42, 2025]\n",
    "N_REPEATS = 10\n",
    "TOP_K = 25\n",
    "\n",
    "def perm_imp_once(est, X, y, seed, n_repeats=10, scoring=None):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    pi = permutation_importance(\n",
    "        est, X, y,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=rng,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    idx = getattr(X, \"columns\", np.arange(X.shape[1]))\n",
    "    s_mean = pd.Series(pi.importances_mean, index=idx, name=f\"seed_{seed}\")\n",
    "    s_std  = pd.Series(pi.importances_std,  index=idx, name=f\"seed_{seed}_std\")\n",
    "    return s_mean, s_std\n",
    "\n",
    "means, stds = [], []\n",
    "for seed in SEEDS:\n",
    "    s_mean, s_std = perm_imp_once(estimator, Xte, y_eval, seed, n_repeats=N_REPEATS, scoring=None)\n",
    "    means.append(s_mean); stds.append(s_std)\n",
    "\n",
    "M = pd.concat(means, axis=1)   # feature x seeds (means)\n",
    "S = pd.concat(stds,  axis=1)   # feature x seeds (within-seed stds)\n",
    "\n",
    "agg = pd.DataFrame({\n",
    "    \"importance_mean\": M.mean(axis=1),\n",
    "    \"importance_std\":  M.std(axis=1, ddof=1),     # across-seed std\n",
    "    \"within_seed_std_mean\": S.mean(axis=1)\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "# Stability metric: how often a feature is in Top-K across seeds\n",
    "counts = pd.Series(0, index=M.index, dtype=float)\n",
    "for col in M.columns:\n",
    "    topk_idx = M[col].sort_values(ascending=False).index[:TOP_K]\n",
    "    counts.loc[topk_idx] += 1\n",
    "agg[\"topK_frequency\"] = counts / len(SEEDS)\n",
    "\n",
    "# Coefficient of variation across seeds (lower = more stable)\n",
    "agg[\"cv_across_seeds\"] = (agg[\"importance_std\"] / agg[\"importance_mean\"].replace(0, np.nan)).fillna(np.inf)\n",
    "\n",
    "# Peek the top-K stable features\n",
    "stable_top = agg.head(TOP_K)\n",
    "print(stable_top.head(10))\n",
    "\n",
    "# Save for your report\n",
    "agg.to_csv(\"perm_importance_stability.csv\", index=True)\n",
    "print(\"Saved: perm_importance_stability.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632f20f-233d-4ba9-84ac-d9339493fcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577c657-7a73-4386-8ab4-6539e4c8f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f41e24-8773-4e47-a09a-d5d51671e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Grouped Permutation Importance for HGB(SVD) champion =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Helper: robust AUC scorer\n",
    "def auc_score(est, X, y):\n",
    "    try:\n",
    "        p = est.predict_proba(X)[:, 1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        # Min-max to [0,1] as a fallback\n",
    "        s_min, s_max = s.min(), s.max()\n",
    "        p = (s - s_min) / (s_max - s_min + 1e-12)\n",
    "    return roc_auc_score(y, p)\n",
    "\n",
    "# 2) Build feature groups by prefix\n",
    "def make_groups(cols):\n",
    "    groups = {\n",
    "        \"Cuisine (cat__)\": [c for c in cols if c.startswith(\"cat__\")],\n",
    "        \"Amenities (attr_)\": [c for c in cols if c.startswith(\"attr_\")],\n",
    "        \"Review meta (rl_)\": [c for c in cols if c.startswith(\"rl_\")],\n",
    "        \"Spherical distances (sphcosdist_)\": [c for c in cols if c.startswith(\"sphcosdist_\")],\n",
    "        \"Clusters\": [c for c in cols if c.startswith(\"cluster_\")],\n",
    "        \"City dummies\": [c for c in cols if c.startswith(\"city_\")],\n",
    "        \"Geography (lat/lon)\": [c for c in cols if c in {\"latitude\", \"longitude\"}],\n",
    "        \"Counts & recency\": [c for c in cols if c in {\"review_count_log1p\", \"review_count\", \"days_open\"}],\n",
    "    }\n",
    "    # Optional catch-all for anything unmatched\n",
    "    used = set(sum(groups.values(), []))\n",
    "    remainder = [c for c in cols if c not in used]\n",
    "    if remainder:\n",
    "        groups[\"Other\"] = remainder\n",
    "    # Drop empty groups\n",
    "    return {g: v for g, v in groups.items() if len(v) > 0}\n",
    "\n",
    "groups = make_groups(Xte.columns)\n",
    "\n",
    "# 3) Baseline AUC\n",
    "BASELINE = auc_score(estimator, Xte, y_eval)\n",
    "print(f\"Baseline AUC: {BASELINE:.3f}\")\n",
    "\n",
    "# 4) Grouped permutation importance\n",
    "def grouped_perm_importance(est, X, y, groups, n_repeats=30, random_state=2025):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    results = []\n",
    "    for gname, cols in groups.items():\n",
    "        drops = []\n",
    "        for _ in range(n_repeats):\n",
    "            Xp = X.copy()\n",
    "            # Shuffle the group with a shared permutation index (preserve within-row structure)\n",
    "            idx = rng.permutation(len(Xp))\n",
    "            for c in cols:\n",
    "                Xp[c] = Xp[c].values[idx]\n",
    "            score = auc_score(est, Xp, y)\n",
    "            drops.append(BASELINE - score)\n",
    "        results.append((gname, float(np.mean(drops)), float(np.std(drops, ddof=1)), len(cols)))\n",
    "    df = pd.DataFrame(results, columns=[\"group\", \"importance_mean\", \"importance_std\", \"n_cols\"])\n",
    "    return df.sort_values(\"importance_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "group_imp = grouped_perm_importance(estimator, Xte, y_eval, groups, n_repeats=30, random_state=2025)\n",
    "print(group_imp)\n",
    "group_imp.to_csv(\"grouped_permutation_importance.csv\", index=False)\n",
    "print(\"Saved: grouped_permutation_importance.csv\")\n",
    "\n",
    "# 5) Quick plot\n",
    "plt.figure(figsize=(9, 6))\n",
    "gi = group_imp.iloc[::-1]  # reverse for barh\n",
    "plt.barh(gi[\"group\"], gi[\"importance_mean\"], xerr=gi[\"importance_std\"])\n",
    "plt.title(\"Grouped permutation importance (AUC drop)\")\n",
    "plt.xlabel(\"AUC drop when group is permuted\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de985d2-0bf4-4b01-a6e1-fd28d6fd7844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82967586-7d37-401c-95bc-53341dcf9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrain ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96351ea1-3ce0-47df-9ecb-c3bde6668a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#“what if we removed this family entirely?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20a55e-3d70-41b6-98e4-1dfec8b137e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Schema-preserving group ablation (dtype-robust) =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc_score(est, X, y):\n",
    "    try:\n",
    "        p = est.predict_proba(X)[:, 1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        p = (s - s.min()) / (s.max() - s.min() + 1e-12)\n",
    "    return roc_auc_score(y, p)\n",
    "\n",
    "def neutralize_columns_dtype_aware(Xtr, Xte, cols, strategy=\"smart\"):\n",
    "    \"\"\"\n",
    "    Keep columns present but remove signal.\n",
    "    strategy=\"smart\": numeric -> mean constant; non-numeric -> 0\n",
    "    strategy=\"zero\": set everything to 0.0\n",
    "    \"\"\"\n",
    "    Xtr_mut, Xte_mut = Xtr.copy(), Xte.copy()\n",
    "    used = []\n",
    "\n",
    "    for c in cols:\n",
    "        if c not in Xtr_mut.columns:\n",
    "            continue\n",
    "        used.append(c)\n",
    "        if strategy == \"zero\":\n",
    "            const_tr = const_te = 0.0\n",
    "        else:\n",
    "            # smart: per-column decision\n",
    "            ser = Xtr_mut[c]\n",
    "            if np.issubdtype(ser.dtype, np.number):\n",
    "                m = ser.mean()\n",
    "                const_tr = const_te = float(0.0 if pd.isna(m) else m)\n",
    "            else:\n",
    "                # Try to coerce to numeric; if still non-numeric, use 0\n",
    "                coerced = pd.to_numeric(ser, errors='coerce')\n",
    "                m = coerced.mean()\n",
    "                const = float(0.0 if pd.isna(m) else m)\n",
    "                const_tr = const_te = const\n",
    "        Xtr_mut[c] = const_tr\n",
    "        if c in Xte_mut.columns:\n",
    "            Xte_mut[c] = const_te\n",
    "    return Xtr_mut, Xte_mut, used\n",
    "\n",
    "def ablate_groups_keep_schema(est, Xtr, ytr, Xte, yte, groups, groups_to_neutralize, strategy=\"smart\"):\n",
    "    # Collect columns from the target groups that actually exist in Xtr\n",
    "    cols = []\n",
    "    for gname in groups_to_neutralize:\n",
    "        cols.extend(groups[gname])\n",
    "    cols = [c for c in cols if c in Xtr.columns]\n",
    "\n",
    "    # Neutralize per column with dtype-aware constants\n",
    "    Xtr_mut, Xte_mut, used = neutralize_columns_dtype_aware(Xtr, Xte, cols, strategy=strategy)\n",
    "\n",
    "    est2 = clone(est)\n",
    "    est2.fit(Xtr_mut, ytr)\n",
    "    auc2 = auc_score(est2, Xte_mut, yte)\n",
    "    return auc2, used, est2\n",
    "\n",
    "# --- Run ablations again ---\n",
    "BASELINE_AUC = auc_score(estimator, Xte, y_eval)\n",
    "print(f\"Baseline AUC: {BASELINE_AUC:.3f}\")\n",
    "\n",
    "to_test = [\"Cuisine (cat__)\", \"Amenities (attr_)\", \"Review meta (rl_)\", \"Counts & recency\"]\n",
    "rows = []\n",
    "for gname in to_test:\n",
    "    auc2, used_cols, _ = ablate_groups_keep_schema(\n",
    "        estimator, Xtr, y_train, Xte, y_eval, groups, [gname], strategy=\"smart\"  # or \"zero\"\n",
    "    )\n",
    "    rows.append({\n",
    "        \"group\": gname,\n",
    "        \"auc_after_neutralize\": auc2,\n",
    "        \"auc_delta\": BASELINE_AUC - auc2,\n",
    "        \"n_cols_neutralized\": len(used_cols),\n",
    "        \"strategy\": \"smart\"\n",
    "    })\n",
    "\n",
    "ablation_df = pd.DataFrame(rows).sort_values(\"auc_delta\", ascending=False).reset_index(drop=True)\n",
    "print(ablation_df)\n",
    "ablation_df.to_csv(\"group_ablation_refit_schema_preserving.csv\", index=False)\n",
    "print(\"Saved: group_ablation_refit_schema_preserving.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda31ec-d9e4-4514-a4de-5f54ddc8f676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e68395-7f04-4a38-9e78-742977e1d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc_score(est, X, y):\n",
    "    try:\n",
    "        p = est.predict_proba(X)[:,1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        p = (s - s.min()) / (s.max() - s.min() + 1e-12)\n",
    "    return roc_auc_score(y, p)\n",
    "\n",
    "def neutralize_columns_dtype_aware(Xtr, Xte, cols, strategy=\"zero\"):\n",
    "    Xtr_mut, Xte_mut = Xtr.copy(), Xte.copy()\n",
    "    used = []\n",
    "    for c in cols:\n",
    "        if c not in Xtr_mut.columns: \n",
    "            continue\n",
    "        used.append(c)\n",
    "        if strategy == \"zero\":\n",
    "            const_tr = const_te = 0.0\n",
    "        else:  # fallback\n",
    "            ser = Xtr_mut[c]\n",
    "            if np.issubdtype(ser.dtype, np.number):\n",
    "                m = ser.mean()\n",
    "                const_tr = const_te = float(0.0 if pd.isna(m) else m)\n",
    "            else:\n",
    "                coerced = pd.to_numeric(ser, errors=\"coerce\")\n",
    "                m = coerced.mean()\n",
    "                const_tr = const_te = float(0.0 if pd.isna(m) else m)\n",
    "        Xtr_mut[c] = const_tr\n",
    "        if c in Xte_mut.columns:\n",
    "            Xte_mut[c] = const_te\n",
    "    return Xtr_mut, Xte_mut, used\n",
    "\n",
    "def ablate_groups_keep_schema(est, Xtr, ytr, Xte, yte, groups, groups_to_neutralize, strategy_map):\n",
    "    # Collect columns and apply group-specific strategies\n",
    "    Xtr_mut, Xte_mut = Xtr.copy(), Xte.copy()\n",
    "    used_all = []\n",
    "    for gname in groups_to_neutralize:\n",
    "        cols = [c for c in groups[gname] if c in Xtr_mut.columns]\n",
    "        strat = strategy_map.get(gname, \"zero\")\n",
    "        Xtr_mut, Xte_mut, used = neutralize_columns_dtype_aware(Xtr_mut, Xte_mut, cols, strategy=strat)\n",
    "        used_all.extend(used)\n",
    "    est2 = clone(est)\n",
    "    est2.fit(Xtr_mut, ytr)\n",
    "    auc2 = auc_score(est2, Xte_mut, yte)\n",
    "    return auc2, used_all, est2\n",
    "\n",
    "# Baseline\n",
    "BASELINE_AUC = auc_score(estimator, Xte, y_eval)\n",
    "print(f\"Baseline AUC: {BASELINE_AUC:.3f}\")\n",
    "\n",
    "# Strategy per group: zero for one-hots; mean for continuous-ish\n",
    "strategy_map = {\n",
    "    \"Cuisine (cat__)\": \"zero\",\n",
    "    \"Amenities (attr_)\": \"zero\",\n",
    "    \"City dummies\": \"zero\",\n",
    "    \"Clusters\": \"mean\",\n",
    "    \"Counts & recency\": \"mean\",\n",
    "    \"Review meta (rl_)\": \"mean\",\n",
    "    \"Spherical distances (sphcosdist_)\": \"mean\",\n",
    "    \"Geography (lat/lon)\": \"mean\",\n",
    "    \"Other\": \"mean\",\n",
    "}\n",
    "\n",
    "# --- Single-group ablation (schema-preserving, sharper for dummies) ---\n",
    "single_groups = [\"Review meta (rl_)\",\"Amenities (attr_)\",\"Cuisine (cat__)\",\"Counts & recency\"]\n",
    "rows = []\n",
    "for gname in single_groups:\n",
    "    auc2, used_cols, _ = ablate_groups_keep_schema(\n",
    "        estimator, Xtr, y_train, Xte, y_eval, groups, [gname], strategy_map\n",
    "    )\n",
    "    rows.append({\n",
    "        \"group\": gname,\n",
    "        \"auc_after_neutralize\": auc2,\n",
    "        \"auc_delta\": BASELINE_AUC - auc2,\n",
    "        \"n_cols_neutralized\": len(used_cols),\n",
    "        \"signal_per_feature\": (BASELINE_AUC - auc2) / max(len(used_cols),1)\n",
    "    })\n",
    "single_df = pd.DataFrame(rows).sort_values(\"auc_delta\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\nSingle-group (zero/mean) neutralization:\")\n",
    "print(single_df)\n",
    "\n",
    "# --- Pairwise ablations to check overlap/additivity ---\n",
    "import itertools\n",
    "pairs = list(itertools.combinations(single_groups[:3], 2))  # test top 3 pairs\n",
    "pair_rows = []\n",
    "for gA, gB in pairs:\n",
    "    auc2, used_cols, _ = ablate_groups_keep_schema(\n",
    "        estimator, Xtr, y_train, Xte, y_eval, groups, [gA, gB], strategy_map\n",
    "    )\n",
    "    delta = BASELINE_AUC - auc2\n",
    "    pair_rows.append({\n",
    "        \"groups\": f\"{gA} + {gB}\",\n",
    "        \"auc_after_neutralize\": auc2,\n",
    "        \"auc_delta\": delta,\n",
    "        \"n_cols_neutralized\": len(used_cols),\n",
    "        \"signal_per_feature\": delta / max(len(used_cols),1)\n",
    "    })\n",
    "pair_df = pd.DataFrame(pair_rows).sort_values(\"auc_delta\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\nPairwise neutralization:\")\n",
    "print(pair_df)\n",
    "\n",
    "# Save\n",
    "single_df.to_csv(\"group_ablation_single_zero_mean.csv\", index=False)\n",
    "pair_df.to_csv(\"group_ablation_pairs_zero_mean.csv\", index=False)\n",
    "print(\"\\nSaved: group_ablation_single_zero_mean.csv, group_ablation_pairs_zero_mean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38023ae-4416-4ecb-acbb-454981773b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620ce95-3cbd-4422-bada-d350dacc36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP: Interpretability & insights → Effects (PDP/ICE) =====\n",
    "# Produces PDP + ICE for top features and a 2D PDP for interaction; saves PNGs.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Assumes these already exist in your session:\n",
    "# - estimator : your trained HGB(SVD) champion pipeline\n",
    "# - Xtr, Xte  : train/eval DataFrames (same columns)\n",
    "# - y_eval    : eval labels (not used here but kept available)\n",
    "\n",
    "# Choose data for plotting grids (training is more representative for PDP grids)\n",
    "X_plot = Xtr if 'Xtr' in globals() else Xte\n",
    "\n",
    "# Select actionable features (edit if needed; code will skip missing ones)\n",
    "single_features = [\n",
    "    \"rl_word_mean\",\n",
    "    \"review_count_log1p\",\n",
    "    \"attr_RestaurantsAttire\",\n",
    "    \"attr_HasTV\",\n",
    "    \"attr_WiFi\",\n",
    "    \"cat__Fast Food\"\n",
    "]\n",
    "\n",
    "# One 2D pair to show interaction/synergy\n",
    "pair_features = [(\"rl_word_mean\", \"attr_RestaurantsAttire\")]\n",
    "\n",
    "def present(feat, X):\n",
    "    return feat in X.columns\n",
    "\n",
    "outdir = \"plots_pdp_ice\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# Single-feature PDP + ICE\n",
    "for feat in single_features:\n",
    "    if not present(feat, X_plot):\n",
    "        print(f\"[skip] '{feat}' not found in columns.\")\n",
    "        continue\n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        estimator,\n",
    "        X_plot,\n",
    "        [feat],\n",
    "        kind=\"both\",           # plots both PDP (avg) and ICE (individual)\n",
    "        grid_resolution=20\n",
    "    )\n",
    "    plt.title(f\"PDP/ICE — {feat}\")\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(outdir, f\"pdp_ice__{feat.replace(' ', '_').replace('/', '_')}.png\")\n",
    "    plt.savefig(fname, dpi=160)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")\n",
    "\n",
    "# Two-way PDP (interaction surface)\n",
    "for f1, f2 in pair_features:\n",
    "    if not (present(f1, X_plot) and present(f2, X_plot)):\n",
    "        print(f\"[skip pair] '{f1}', '{f2}' — one or both missing.\")\n",
    "        continue\n",
    "    plt.figure(figsize=(6.5, 5.5))\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        estimator,\n",
    "        X_plot,\n",
    "        [(f1, f2)],\n",
    "        kind=\"average\",\n",
    "        grid_resolution=20\n",
    "    )\n",
    "    plt.suptitle(f\"2D PDP — {f1} × {f2}\")\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(outdir, f\"pdp2d__{f1}__x__{f2}.png\".replace(' ', '_').replace('/', '_'))\n",
    "    plt.savefig(fname, dpi=160)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")\n",
    "\n",
    "print(\"\\nDone. All figures saved in:\", outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257491a-8acf-49e2-9194-c4c17f8dfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 1c: PDP/ICE (dtype-safe) =====\n",
    "# Fixes TypeError by coercing selected columns to numeric in a copy used only for plotting.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Choose plotting frame (train preferred for PDP grids)\n",
    "X_plot = Xtr if 'Xtr' in globals() else Xte\n",
    "\n",
    "# Reuse previously selected features if available; otherwise auto-select from stability CSV\n",
    "if 'single_features' in globals() and isinstance(single_features, (list, tuple)) and len(single_features) > 0:\n",
    "    feats_single = list(single_features)\n",
    "else:\n",
    "    agg = pd.read_csv(\"perm_importance_stability.csv\", index_col=0)\n",
    "    cols_present = set(X_plot.columns)\n",
    "    agg_present = agg[agg.index.isin(cols_present)].sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "    def is_binary(col):\n",
    "        try:\n",
    "            vals = pd.unique(X_plot[col].dropna())\n",
    "            return len(vals) <= 2\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def is_numeric(col):\n",
    "        return np.issubdtype(X_plot[col].dtype, np.number)\n",
    "\n",
    "    top_numeric = [c for c in agg_present.index if is_numeric(c) and not is_binary(c)]\n",
    "    top_binary  = [c for c in agg_present.index if is_binary(c)]\n",
    "    feats_single = top_numeric[:4] + top_binary[:4]\n",
    "\n",
    "# Pick a 2D pair (rl_word_mean with best amenity) if present\n",
    "amenity_candidates = [c for c in feats_single if c.startswith(\"attr_\")] or \\\n",
    "                     [c for c in X_plot.columns if c.startswith(\"attr_\")]\n",
    "pair_features = []\n",
    "if \"rl_word_mean\" in X_plot.columns and len(amenity_candidates) > 0:\n",
    "    pair_features = [(\"rl_word_mean\", amenity_candidates[0])]\n",
    "\n",
    "print(\"Will plot single-feature PDP/ICE for:\", feats_single)\n",
    "print(\"2D PDP pair:\", pair_features if pair_features else \"None\")\n",
    "\n",
    "# --- Make a dtype-safe copy just for plotting ---\n",
    "X_safe = X_plot.copy()\n",
    "cols_to_sanitize = set(feats_single + [f for tup in pair_features for f in (tup if isinstance(tup, tuple) else [tup])])\n",
    "cols_to_sanitize = [c for c in cols_to_sanitize if c in X_safe.columns]\n",
    "\n",
    "for c in cols_to_sanitize:\n",
    "    # Try numeric conversion; fall back to 0 for non-convertible entries\n",
    "    newc = pd.to_numeric(X_safe[c], errors=\"coerce\")\n",
    "    if newc.isna().any():\n",
    "        # For binary-like columns use 0; otherwise median\n",
    "        unique_non_na = pd.unique(newc.dropna())\n",
    "        if len(unique_non_na) <= 2:\n",
    "            fill_val = 0.0\n",
    "        else:\n",
    "            fill_val = float(np.nanmedian(newc))\n",
    "        newc = newc.fillna(fill_val)\n",
    "    X_safe[c] = newc.astype(float)\n",
    "\n",
    "outdir = \"plots_pdp_ice_fixed\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# --- Plot single-feature PDP + ICE ---\n",
    "for feat in feats_single:\n",
    "    if feat not in X_safe.columns:\n",
    "        print(f\"[skip] '{feat}' not found after sanitation.\")\n",
    "        continue\n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        estimator,\n",
    "        X_safe,\n",
    "        [feat],\n",
    "        kind=\"both\",\n",
    "        grid_resolution=20\n",
    "    )\n",
    "    plt.title(f\"PDP/ICE — {feat}\")\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(outdir, f\"pdp_ice__{feat.replace(' ', '_').replace('/', '_')}.png\")\n",
    "    plt.savefig(fname, dpi=160)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")\n",
    "\n",
    "# --- 2D PDP (interaction surface) ---\n",
    "for (f1, f2) in pair_features:\n",
    "    if f1 in X_safe.columns and f2 in X_safe.columns:\n",
    "        plt.figure(figsize=(6.5, 5.5))\n",
    "        PartialDependenceDisplay.from_estimator(\n",
    "            estimator,\n",
    "            X_safe,\n",
    "            [(f1, f2)],\n",
    "            kind=\"average\",\n",
    "            grid_resolution=20\n",
    "        )\n",
    "        plt.suptitle(f\"2D PDP — {f1} × {f2}\")\n",
    "        plt.tight_layout()\n",
    "        fname = os.path.join(outdir, f\"pdp2d__{f1}__x__{f2}.png\".replace(' ', '_').replace('/', '_'))\n",
    "        plt.savefig(fname, dpi=160)\n",
    "        plt.show()\n",
    "        print(f\"[saved] {fname}\")\n",
    "    else:\n",
    "        print(f\"[skip pair] Missing sanitized columns for {f1} or {f2}\")\n",
    "\n",
    "print(\"\\nDone. All figures saved in:\", outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5d629-b84f-4b67-8e56-bf73b0102b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 2: Calibration & thresholding =====\n",
    "# Outputs:\n",
    "#   - plots_calibration/calibration_curve.png\n",
    "#   - plots_calibration/prob_hist.png\n",
    "#   - plots_calibration/threshold_vs_f1.png\n",
    "#   - threshold_sweep_eval.csv (metrics vs threshold)\n",
    "#   - printed best threshold by macro-F1 and metrics at 0.50, 0.53, best\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, brier_score_loss, roc_auc_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# --- 0) Get predicted probabilities on eval (robust to estimators without predict_proba)\n",
    "def get_prob(est, X):\n",
    "    try:\n",
    "        return est.predict_proba(X)[:, 1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        s_min, s_max = s.min(), s.max()\n",
    "        return (s - s_min) / (s_max - s_min + 1e-12)\n",
    "\n",
    "proba = get_prob(estimator, Xte)\n",
    "y_true = np.asarray(y_eval).astype(int)\n",
    "\n",
    "# --- 1) Calibration curve + Brier score\n",
    "frac_pos, mean_pred = calibration_curve(y_true, proba, n_bins=15, strategy=\"quantile\")\n",
    "brier = brier_score_loss(y_true, proba)\n",
    "auc = roc_auc_score(y_true, proba)\n",
    "\n",
    "outdir = \"plots_calibration\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(5.5,5))\n",
    "plt.plot([0,1],[0,1],'--',label=\"perfect\")\n",
    "plt.plot(mean_pred, frac_pos, marker='o', label=\"model\")\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(f\"Calibration curve (eval) — Brier={brier:.3f}, AUC={auc:.3f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir,\"calibration_curve.png\"), dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# Probability histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(proba, bins=30, edgecolor='black')\n",
    "plt.xlabel(\"Predicted probability (positive)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Predicted probability distribution (eval)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir,\"prob_hist.png\"), dpi=160)\n",
    "plt.show()\n",
    "\n",
    "# --- 2) Threshold sweep for macro-F1\n",
    "def metrics_at(y_true, proba, thr):\n",
    "    y_pred = (proba >= thr).astype(int)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    pre  = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    f1m  = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return acc, pre, rec, f1, f1m, tn, fp, fn, tp\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    acc, pre, rec, f1, f1m, tn, fp, fn, tp = metrics_at(y_true, proba, t)\n",
    "    rows.append({\"threshold\": t, \"accuracy\": acc, \"precision\": pre, \"recall\": rec,\n",
    "                 \"f1\": f1, \"macro_f1\": f1m, \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp})\n",
    "sweep = pd.DataFrame(rows)\n",
    "\n",
    "# Best by macro-F1\n",
    "best_idx = sweep[\"macro_f1\"].idxmax()\n",
    "best_row = sweep.loc[best_idx]\n",
    "best_thr = float(best_row[\"threshold\"])\n",
    "\n",
    "# Reference thresholds\n",
    "def row_for(t):\n",
    "    return sweep.iloc[(sweep['threshold']-t).abs().argmin()]\n",
    "\n",
    "row_050 = row_for(0.50)\n",
    "row_053 = row_for(0.53)\n",
    "\n",
    "print(\"\\n=== Threshold results (eval) ===\")\n",
    "print(f\"Best macro-F1 threshold: {best_thr:.3f} | macro-F1={best_row['macro_f1']:.3f} \"\n",
    "      f\"| acc={best_row['accuracy']:.3f} | prec={best_row['precision']:.3f} \"\n",
    "      f\"| rec={best_row['recall']:.3f} | F1={best_row['f1']:.3f} | \"\n",
    "      f\"cm=[tn={int(best_row['tn'])}, fp={int(best_row['fp'])}, fn={int(best_row['fn'])}, tp={int(best_row['tp'])}]\")\n",
    "\n",
    "print(f\"\\nAt t=0.50: macro-F1={row_050['macro_f1']:.3f} | acc={row_050['accuracy']:.3f} \"\n",
    "      f\"| prec={row_050['precision']:.3f} | rec={row_050['recall']:.3f} | F1={row_050['f1']:.3f}\")\n",
    "\n",
    "print(f\"At t=0.53: macro-F1={row_053['macro_f1']:.3f} | acc={row_053['accuracy']:.3f} \"\n",
    "      f\"| prec={row_053['precision']:.3f} | rec={row_053['recall']:.3f} | F1={row_053['f1']:.3f}\")\n",
    "\n",
    "# Save sweep\n",
    "sweep.to_csv(\"threshold_sweep_eval.csv\", index=False)\n",
    "print(\"\\nSaved: plots_calibration/calibration_curve.png, plots_calibration/prob_hist.png, threshold_sweep_eval.csv\")\n",
    "\n",
    "# Plot macro-F1 vs threshold\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(sweep[\"threshold\"], sweep[\"macro_f1\"], label=\"macro-F1\")\n",
    "plt.axvline(0.50, linestyle=\"--\", label=\"0.50\")\n",
    "plt.axvline(0.53, linestyle=\"--\", label=\"0.53\")\n",
    "plt.axvline(best_thr, linestyle=\":\", label=f\"best={best_thr:.2f}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Macro-F1\")\n",
    "plt.title(\"Threshold sweep (eval)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir,\"threshold_vs_f1.png\"), dpi=160)\n",
    "plt.show()\n",
    "print(\"Saved: plots_calibration/threshold_vs_f1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56536003-966f-42a2-9026-3f515a32dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 3: Slice performance & error analysis =====\n",
    "# Inputs assumed present: estimator, Xte, y_eval, and best threshold (0.53 from Step 2)\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "THRESH = 0.53  # from Step 2 best macro-F1\n",
    "\n",
    "def get_prob(est, X):\n",
    "    try:\n",
    "        return est.predict_proba(X)[:,1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        s_min, s_max = s.min(), s.max()\n",
    "        return (s - s_min) / (s_max - s_min + 1e-12)\n",
    "\n",
    "proba = get_prob(estimator, Xte)\n",
    "y_true = np.asarray(y_eval).astype(int)\n",
    "y_pred = (proba >= THRESH).astype(int)\n",
    "\n",
    "eval_df = pd.DataFrame({\n",
    "    \"y_true\": y_true,\n",
    "    \"proba\": proba,\n",
    "    \"y_pred\": y_pred\n",
    "}, index=Xte.index)\n",
    "\n",
    "# ---------- metrics helper ----------\n",
    "def metrics_at_mask(mask, name):\n",
    "    mask = mask.astype(bool)\n",
    "    n = int(mask.sum())\n",
    "    if n < 30:   # skip tiny slices to avoid noise; adjust if needed\n",
    "        return None\n",
    "    yt = y_true[mask]\n",
    "    pr = proba[mask]\n",
    "    yp = y_pred[mask]\n",
    "    acc  = accuracy_score(yt, yp)\n",
    "    prec = precision_score(yt, yp, zero_division=0)\n",
    "    rec  = recall_score(yt, yp, zero_division=0)\n",
    "    f1   = f1_score(yt, yp, zero_division=0)\n",
    "    f1m  = f1_score(yt, yp, average=\"macro\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(yt, pr)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    tn, fp, fn, tp = confusion_matrix(yt, yp).ravel()\n",
    "    pos_rate = float(yt.mean())\n",
    "    return {\n",
    "        \"slice\": name, \"support\": n, \"pos_rate\": pos_rate,\n",
    "        \"accuracy\": acc, \"precision\": prec, \"recall\": rec,\n",
    "        \"f1\": f1, \"macro_f1\": f1m, \"auc\": auc,\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp\n",
    "    }\n",
    "\n",
    "def eval_dummies(prefix, title, exclude_prefixes=(), topn_plot=12):\n",
    "    cols = [c for c in Xte.columns if c.startswith(prefix) and not any(c.startswith(ep) for ep in exclude_prefixes)]\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        res = metrics_at_mask(Xte[c] == 1, c.replace(prefix, f\"{title}: \"))\n",
    "        if res: rows.append(res)\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(rows).sort_values([\"macro_f1\",\"support\"], ascending=[False, False])\n",
    "    out = f\"slice_metrics_{title.lower().replace(' ','_')}.csv\"\n",
    "    df.to_csv(out, index=False); print(\"Saved:\", out)\n",
    "\n",
    "    # quick plot: top slices by macro-F1 (min support filter)\n",
    "    plot_df = df[df[\"support\"] >= 50].head(topn_plot)\n",
    "    if len(plot_df) > 0:\n",
    "        plt.figure(figsize=(9, 5))\n",
    "        plt.barh(plot_df[\"slice\"][::-1], plot_df[\"macro_f1\"][::-1])\n",
    "        plt.xlabel(\"Macro-F1\"); plt.title(f\"{title} — top slices (support ≥ 50)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"slice_{title.lower().replace(' ','_')}_top.png\", dpi=160)\n",
    "        plt.show()\n",
    "        print(\"Saved:\", f\"slice_{title.lower().replace(' ','_')}_top.png\")\n",
    "    return df\n",
    "\n",
    "# ---------- 3A. Slices by family ----------\n",
    "city_df     = eval_dummies(\"city_\", \"City\")\n",
    "cuisine_df  = eval_dummies(\"cat__\", \"Cuisine\")\n",
    "# Price range one-hots often look like attr_RestaurantsPriceRange1/2/3/4\n",
    "price_df    = eval_dummies(\"attr_RestaurantsPriceRange\", \"PriceRange\")\n",
    "# Amenities = attr_ (excluding price range columns already handled)\n",
    "amen_df     = eval_dummies(\"attr_\", \"Amenity\", exclude_prefixes=(\"attr_RestaurantsPriceRange\",))\n",
    "\n",
    "# ---------- 3B. Review-count quartiles ----------\n",
    "if \"review_count_log1p\" in Xte.columns:\n",
    "    q = pd.qcut(Xte[\"review_count_log1p\"], q=4, duplicates=\"drop\")\n",
    "    rows = []\n",
    "    for lvl in q.cat.categories:\n",
    "        mask = (q == lvl)\n",
    "        res = metrics_at_mask(mask.values, f\"Reviews quartile: {lvl}\")\n",
    "        if res: rows.append(res)\n",
    "    rc_df = pd.DataFrame(rows).sort_values(\"support\", ascending=False)\n",
    "    rc_df.to_csv(\"slice_metrics_review_count_quartiles.csv\", index=False)\n",
    "    print(\"Saved:\", \"slice_metrics_review_count_quartiles.csv\")\n",
    "else:\n",
    "    rc_df = pd.DataFrame()\n",
    "\n",
    "# ---------- 3C. Top false positives & false negatives ----------\n",
    "top_features = [f for f in [\n",
    "    \"rl_word_mean\",\"review_count_log1p\",\n",
    "    \"attr_RestaurantsAttire\",\"attr_HasTV\",\"attr_WiFi\",\n",
    "    \"cat__Fast Food\",\"cat__Pizza\",\"attr_RestaurantsPriceRange2\"\n",
    "] if f in Xte.columns]\n",
    "\n",
    "# Top 20 FP (pred=1, truth=0) with a few key feature values\n",
    "fp = eval_df.query(\"y_true==0 and y_pred==1\").copy()\n",
    "fp[\"margin\"] = fp[\"proba\"] - THRESH\n",
    "fp_top = fp.sort_values(\"proba\", ascending=False).head(20).join(Xte[top_features])\n",
    "fp_top.to_csv(\"top_false_positives.csv\"); print(\"Saved:\", \"top_false_positives.csv\")\n",
    "\n",
    "# Top 20 FN (pred=0, truth=1)\n",
    "fn = eval_df.query(\"y_true==1 and y_pred==0\").copy()\n",
    "fn[\"margin\"] = THRESH - fn[\"proba\"]\n",
    "fn_top = fn.sort_values(\"proba\", ascending=True).head(20).join(Xte[top_features])\n",
    "fn_top.to_csv(\"top_false_negatives.csv\"); print(\"Saved:\", \"top_false_negatives.csv\")\n",
    "\n",
    "# ---------- 3D. Summary printout ----------\n",
    "def brief(df, name):\n",
    "    if df is None or len(df)==0: \n",
    "        print(f\"{name}: no slices or too small.\"); return\n",
    "    best = df.sort_values(\"macro_f1\", ascending=False).head(5)[[\"slice\",\"support\",\"macro_f1\",\"pos_rate\"]]\n",
    "    print(f\"\\nTop {name} slices by macro-F1:\")\n",
    "    print(best.to_string(index=False))\n",
    "\n",
    "brief(city_df, \"City\")\n",
    "brief(cuisine_df, \"Cuisine\")\n",
    "brief(amen_df, \"Amenity\")\n",
    "brief(price_df, \"PriceRange\")\n",
    "brief(rc_df, \"ReviewCount Quartiles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d51177-59c8-42aa-8cfe-63ec74cae8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634573d-a97c-4608-afb4-603ae5ca9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 4: Refit & freeze (full-data) + inference with reason codes =====\n",
    "import os, json, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from joblib import dump, load\n",
    "\n",
    "# --- helpers\n",
    "def get_prob(est, X):\n",
    "    try:\n",
    "        return est.predict_proba(X)[:,1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        s_min, s_max = s.min(), s.max()\n",
    "        return (s - s_min) / (s_max - s_min + 1e-12)\n",
    "\n",
    "THRESH = 0.53  # from STEP 2\n",
    "\n",
    "# 1) Build full dataset (train ∪ eval) with aligned columns\n",
    "cols_union = Xtr.columns.union(Xte.columns)\n",
    "Xtr_aligned = Xtr.reindex(columns=cols_union, fill_value=0)\n",
    "Xte_aligned = Xte.reindex(columns=cols_union, fill_value=0)\n",
    "\n",
    "X_full = pd.concat([Xtr_aligned, Xte_aligned], axis=0, ignore_index=True)\n",
    "y_full = pd.concat([pd.Series(y_train).reset_index(drop=True),\n",
    "                    pd.Series(y_eval).reset_index(drop=True)], axis=0).astype(int).values\n",
    "\n",
    "# 2) Refit champion on full data\n",
    "est_full = clone(estimator)\n",
    "est_full.fit(X_full, y_full)\n",
    "\n",
    "# 3) Confirm eval metrics at chosen threshold (sanity check)\n",
    "proba_eval = get_prob(est_full, Xte_aligned)\n",
    "y_pred_eval = (proba_eval >= THRESH).astype(int)\n",
    "metrics_eval = {\n",
    "    \"accuracy\": float(accuracy_score(y_eval, y_pred_eval)),\n",
    "    \"precision\": float(precision_score(y_eval, y_pred_eval, zero_division=0)),\n",
    "    \"recall\": float(recall_score(y_eval, y_pred_eval, zero_division=0)),\n",
    "    \"f1\": float(f1_score(y_eval, y_pred_eval, zero_division=0)),\n",
    "    \"macro_f1\": float(f1_score(y_eval, y_pred_eval, average=\"macro\", zero_division=0)),\n",
    "    \"auc\": float(roc_auc_score(y_eval, proba_eval))\n",
    "}\n",
    "print(\"Eval metrics @0.53 after refit:\", metrics_eval)\n",
    "\n",
    "# 4) Save artifacts\n",
    "ARTDIR = \"artifacts_final\"\n",
    "os.makedirs(ARTDIR, exist_ok=True)\n",
    "dump(est_full, f\"{ARTDIR}/final_hgb_svd_v1.joblib\")\n",
    "json.dump(list(cols_union), open(f\"{ARTDIR}/columns_v1.json\",\"w\"))\n",
    "\n",
    "# Background means for reason-codes neutralization\n",
    "bg_means = {}\n",
    "for c in cols_union:\n",
    "    ser = X_full[c]\n",
    "    if np.issubdtype(ser.dtype, np.number):\n",
    "        m = float(np.nanmean(ser.values))\n",
    "        bg_means[c] = 0.0 if np.isnan(m) else m\n",
    "    else:\n",
    "        # try numeric coercion, else default 0\n",
    "        coerced = pd.to_numeric(ser, errors=\"coerce\")\n",
    "        m = float(np.nanmean(coerced.values)) if coerced.notna().any() else 0.0\n",
    "        bg_means[c] = 0.0 if np.isnan(m) else m\n",
    "json.dump(bg_means, open(f\"{ARTDIR}/background_means_v1.json\",\"w\"))\n",
    "\n",
    "# Simple metadata\n",
    "meta = {\n",
    "    \"model\": \"HGB(SVD) pipeline\",\n",
    "    \"version\": \"v1\",\n",
    "    \"timestamp\": dt.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"threshold\": THRESH,\n",
    "    \"eval_metrics_after_refit\": metrics_eval,\n",
    "    \"n_train_full\": int(len(X_full)),\n",
    "    \"n_features\": int(len(cols_union))\n",
    "}\n",
    "json.dump(meta, open(f\"{ARTDIR}/metadata_v1.json\",\"w\"), indent=2)\n",
    "print(\"Saved artifacts in:\", ARTDIR)\n",
    "\n",
    "# 5) Lightweight inference with reason codes (top-k features)\n",
    "def load_artifacts(path=\"artifacts_final\"):\n",
    "    est = load(f\"{path}/final_hgb_svd_v1.joblib\")\n",
    "    cols = json.load(open(f\"{path}/columns_v1.json\"))\n",
    "    bg = json.load(open(f\"{path}/background_means_v1.json\"))\n",
    "    return est, cols, bg\n",
    "\n",
    "def predict_with_reasons(sample_df, top_features=None, threshold=THRESH, artifacts_dir=\"artifacts_final\"):\n",
    "    \"\"\"\n",
    "    sample_df: DataFrame with a SINGLE row, same schema as training (missing cols OK).\n",
    "    Returns dict: {'prob','class','reasons':[(feature, delta_prob),...]}\n",
    "    \"\"\"\n",
    "    est, cols, bg = load_artifacts(artifacts_dir)\n",
    "    X = sample_df.reindex(columns=cols, fill_value=0)\n",
    "    base = float(get_prob(est, X)[0])\n",
    "\n",
    "    # choose features: use stability CSV top 10 if not provided\n",
    "    if top_features is None:\n",
    "        agg = pd.read_csv(\"perm_importance_stability.csv\", index_col=0)\n",
    "        top_features = [c for c in agg.sort_values(\"importance_mean\", ascending=False).index if c in X.columns][:10]\n",
    "\n",
    "    # one-at-a-time neutralization delta (positive delta => feature increases current prob)\n",
    "    deltas = []\n",
    "    for f in top_features:\n",
    "        Xtmp = X.copy()\n",
    "        neutral = 0.0 if f.startswith((\"cat__\",\"attr_\",\"city_\")) else bg.get(f, 0.0)\n",
    "        Xtmp.at[Xtmp.index[0], f] = neutral\n",
    "        p = float(get_prob(est, Xtmp)[0])\n",
    "        deltas.append((f, base - p))\n",
    "    deltas.sort(key=lambda t: abs(t[1]), reverse=True)\n",
    "\n",
    "    return {\n",
    "        \"prob\": base,\n",
    "        \"class\": int(base >= threshold),\n",
    "        \"threshold\": threshold,\n",
    "        \"reasons\": deltas\n",
    "    }\n",
    "\n",
    "# --- Example usage on one eval row (optional sanity check) ---\n",
    "example = Xte_aligned.sample(1, random_state=7)\n",
    "result = predict_with_reasons(example)\n",
    "print(\"Example prediction:\", {k:(round(v,4) if isinstance(v,float) else v) for k,v in result.items() if k!='reasons'})\n",
    "print(\"Top reasons (feature, delta_prob):\", [(f, round(d,4)) for f,d in result[\"reasons\"][:5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81edfba-2d76-45b7-a72a-e22305c204b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6476ad3-f543-458d-817e-08cf29be1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 5: Deliverables pack =====\n",
    "import os, glob, json, numpy as np, pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "THRESH = 0.53\n",
    "OUTDIR = \"deliverables\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "def get_prob(est, X):\n",
    "    try:\n",
    "        return est.predict_proba(X)[:,1]\n",
    "    except Exception:\n",
    "        s = est.decision_function(X)\n",
    "        s_min, s_max = s.min(), s.max()\n",
    "        return (s - s_min) / (s_max - s_min + 1e-12)\n",
    "\n",
    "def metrics_table_row(name, est, X, y, thr):\n",
    "    p = get_prob(est, X)\n",
    "    ypred = (p >= thr).astype(int)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"threshold\": thr,\n",
    "        \"accuracy\": accuracy_score(y, ypred),\n",
    "        \"precision\": precision_score(y, ypred, zero_division=0),\n",
    "        \"recall\": recall_score(y, ypred, zero_division=0),\n",
    "        \"f1\": f1_score(y, ypred, zero_division=0),\n",
    "        \"macro_f1\": f1_score(y, ypred, average=\"macro\", zero_division=0),\n",
    "        \"auc\": roc_auc_score(y, p)\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "# Champion on proper hold-out (the 'estimator' you used in Steps 1–3)\n",
    "rows.append(metrics_table_row(\"HGB(SVD) — holdout\", estimator, Xte, y_eval, THRESH))\n",
    "\n",
    "# Also include post-refit sanity (trained on full data; optimistic — label it clearly)\n",
    "try:\n",
    "    est_full = load(\"artifacts_final/final_hgb_svd_v1.joblib\")\n",
    "    rows.append(metrics_table_row(\"HGB(SVD) — post-refit (sanity only)\", est_full, Xte, y_eval, THRESH))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Optional: LogReg-enet if available\n",
    "for cand in [\"logreg_enet.joblib\",\"artifacts/logreg_enet.joblib\",\"models/logreg_enet.joblib\"]:\n",
    "    if os.path.exists(cand):\n",
    "        logreg = load(cand)\n",
    "        rows.append(metrics_table_row(\"LogReg-enet — holdout\", logreg, Xte, y_eval, THRESH))\n",
    "        break  # first one wins\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_path = os.path.join(OUTDIR, \"results_table.csv\")\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(\"Saved:\", results_path)\n",
    "print(results_df)\n",
    "\n",
    "# ---------- Actionable insights text ----------\n",
    "insights_lines = []\n",
    "\n",
    "# Pull top individual features (stability CSV)\n",
    "try:\n",
    "    stab = pd.read_csv(\"perm_importance_stability.csv\", index_col=0).sort_values(\"importance_mean\", ascending=False)\n",
    "    top_feats = stab.head(8).index.tolist()\n",
    "    insights_lines.append(f\"Top single features by stable permutation importance: {', '.join(top_feats)}.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Pull group importance\n",
    "try:\n",
    "    group_imp = pd.read_csv(\"grouped_permutation_importance.csv\").sort_values(\"importance_mean\", ascending=False)\n",
    "    top_groups = group_imp.head(3)[[\"group\",\"importance_mean\"]].values.tolist()\n",
    "    desc = \"; \".join([f\"{g} (ΔAUC≈{v:.3f})\" for g,v in top_groups])\n",
    "    insights_lines.append(f\"Most influential families (grouped permutation): {desc}.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Pull ablation (schema-preserving)\n",
    "try:\n",
    "    abl = pd.read_csv(\"group_ablation_refit_schema_preserving.csv\").sort_values(\"auc_delta\", ascending=False)\n",
    "    keepers = abl.head(3)[[\"group\",\"auc_delta\",\"n_cols_neutralized\"]].values.tolist()\n",
    "    bullets = \"; \".join([f\"{g} (ΔAUC≈{d:.3f} across {n} cols)\" for g,d,n in keepers])\n",
    "    insights_lines.append(f\"Ablation confirms uniqueness: {bullets}.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Calibration/threshold summary\n",
    "try:\n",
    "    sweep = pd.read_csv(\"threshold_sweep_eval.csv\")\n",
    "    best_row = sweep.loc[sweep[\"macro_f1\"].idxmax()]\n",
    "    insights_lines.append(\n",
    "        f\"Calibration: Brier≈{open('plots_calibration/calibration_curve.png') and 'see plot'}. \"\n",
    "        f\"Best macro-F1 at threshold≈{float(best_row['threshold']):.2f}.\"\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "insights_lines.append(\n",
    "    \"Practical levers: encourage richer reviews (rl_word_mean), maintain accurate amenity listings (WiFi, Attire), \"\n",
    "    \"and increase authentic review volume (review_count_log1p). Treat cuisine/category as segmentation for benchmarks.\"\n",
    ")\n",
    "\n",
    "insights_text = \"\\n\".join(f\"- {ln}\" for ln in insights_lines)\n",
    "insights_path = os.path.join(OUTDIR, \"actionable_insights.txt\")\n",
    "with open(insights_path, \"w\") as f:\n",
    "    f.write(\"Actionable insights for boosting star ratings\\n\")\n",
    "    f.write(\"=\"*48 + \"\\n\")\n",
    "    f.write(insights_text + \"\\n\")\n",
    "print(\"Saved:\", insights_path)\n",
    "\n",
    "# ---------- Model card ----------\n",
    "card_path = os.path.join(OUTDIR, \"model_card.md\")\n",
    "with open(card_path, \"w\") as f:\n",
    "    f.write(\"# Model Card — Yelp Ratings Predictor (HGB(SVD))\\n\\n\")\n",
    "    f.write(\"**Objective:** Predict high star ratings and surface actionable levers to improve them.\\n\\n\")\n",
    "    f.write(\"**Champion:** HGB(SVD) pipeline; threshold 0.53 (macro-F1-optimal on holdout).\\n\\n\")\n",
    "    f.write(\"**Validation:** Train/holdout split; reporting on holdout.\\n\\n\")\n",
    "    f.write(\"**Key signals:** review richness (rl_word_mean), review volume (review_count_log1p), \"\n",
    "            \"amenities (attr_*), cuisines (cat__), clusters.\\n\\n\")\n",
    "    f.write(\"**Limitations:** Associations, not causation; category effects are segmentation signals; \"\n",
    "            \"avoid manipulative review incentives; monitor for drift quarterly.\\n\\n\")\n",
    "    f.write(\"**Artifacts:** `artifacts_final/final_hgb_svd_v1.joblib`, columns JSON, background means JSON.\\n\")\n",
    "print(\"Saved:\", card_path)\n",
    "\n",
    "# ---------- Plot manifest ----------\n",
    "plots = []\n",
    "for pat in [\"plots_*/*.png\",\"plots_*/*/*.png\",\"slice_*_top.png\"]:\n",
    "    plots.extend(glob.glob(pat))\n",
    "manifest_path = os.path.join(OUTDIR, \"plot_manifest.txt\")\n",
    "with open(manifest_path,\"w\") as f:\n",
    "    f.write(\"\\n\".join(sorted(plots)))\n",
    "print(\"Saved:\", manifest_path)\n",
    "print(f\"\\nTotal plots found: {len(plots)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d3608-39f2-4d90-9a31-eadceff71af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7a30e-9526-4813-b45b-9ef51f190d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 6: Generate executive_summary.md =====\n",
    "import os, json, pandas as pd, textwrap, glob\n",
    "\n",
    "OUTDIR = \"deliverables\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# 1) Load artifacts we already produced\n",
    "results = pd.read_csv(f\"{OUTDIR}/results_table.csv\")\n",
    "holdout_row = results[results[\"model\"].str.contains(\"holdout\", case=False)].iloc[0]\n",
    "\n",
    "insights_txt = \"\"\n",
    "if os.path.exists(f\"{OUTDIR}/actionable_insights.txt\"):\n",
    "    with open(f\"{OUTDIR}/actionable_insights.txt\",\"r\") as f:\n",
    "        insights_txt = f.read().strip()\n",
    "\n",
    "# optional: pick a few plot paths if they exist\n",
    "plots = []\n",
    "plots += [p for p in [\n",
    "    \"plots_calibration/calibration_curve.png\",\n",
    "    \"plots_calibration/threshold_vs_f1.png\",\n",
    "] if os.path.exists(p)]\n",
    "plots += sorted(glob.glob(\"plots_pdp_ice_fixed/pdp_ice__*.png\"))[:4]  # first 4 PDP/ICE\n",
    "\n",
    "# 2) Short bullets from slice CSVs (top-3 each if present)\n",
    "def top_slices(path, col=\"slice\", k=3):\n",
    "    if not os.path.exists(path): return []\n",
    "    df = pd.read_csv(path).sort_values([\"macro_f1\",\"support\"], ascending=[False, False])\n",
    "    df = df[df[\"support\"]>=50].head(k)\n",
    "    return [f\"{r[col]} — macro-F1 {r['macro_f1']:.3f} (n={int(r['support'])})\" for _,r in df.iterrows()]\n",
    "\n",
    "city_bul = top_slices(\"slice_metrics_city.csv\")\n",
    "cui_bul  = top_slices(\"slice_metrics_cuisine.csv\")\n",
    "amen_bul = top_slices(\"slice_metrics_amenity.csv\")\n",
    "price_bul= top_slices(\"slice_metrics_pricerange.csv\")\n",
    "revq_bul = top_slices(\"slice_metrics_review_count_quartiles.csv\")\n",
    "\n",
    "# 3) Build markdown\n",
    "md = []\n",
    "md.append(\"# Executive Summary — Yelp Ratings Predictor\\n\")\n",
    "md.append(\"**Objective:** Predict high star ratings and surface practical levers stakeholders can act on to improve them.\\n\")\n",
    "md.append(\"## Champion model\\n\")\n",
    "md.append(f\"- **Model:** HGB(SVD) pipeline\\n- **Holdout threshold:** 0.53 (macro-F1-optimal)\\n\")\n",
    "md.append(f\"- **Holdout metrics:** accuracy **{holdout_row['accuracy']:.3f}**, macro-F1 **{holdout_row['macro_f1']:.3f}**, AUC **{holdout_row['auc']:.3f}**\\n\")\n",
    "md.append(\"*(A separate post-refit metric was computed for sanity only and is not for external reporting.)*\\n\")\n",
    "\n",
    "md.append(\"## Key insights (actionable)\\n\")\n",
    "if insights_txt:\n",
    "    md.append(insights_txt + \"\\n\")\n",
    "else:\n",
    "    md.append(\"- See grouped importance and ablation CSVs for evidence.\\n\")\n",
    "\n",
    "def section_list(title, items):\n",
    "    if not items: return \"\"\n",
    "    s = [f\"## {title}\\n\"]\n",
    "    s += [f\"- {it}\" for it in items]\n",
    "    s.append(\"\") \n",
    "    return \"\\n\".join(s)\n",
    "\n",
    "md.append(section_list(\"Strong slices (City)\", city_bul))\n",
    "md.append(section_list(\"Strong slices (Cuisine)\", cui_bul))\n",
    "md.append(section_list(\"Strong slices (Amenity)\", amen_bul))\n",
    "md.append(section_list(\"Strong slices (PriceRange)\", price_bul))\n",
    "md.append(section_list(\"Performance by review volume\", revq_bul))\n",
    "\n",
    "md.append(\"## Plots\\n\")\n",
    "if plots:\n",
    "    md += [f\"- {p}\" for p in plots]\n",
    "else:\n",
    "    md.append(\"- Plots were generated in earlier steps; see `plots_*` folders.\")\n",
    "\n",
    "md.append(\"\\n## Limitations & guardrails\\n- Correlational signals; use for hypotheses and A/B tests, not causal claims.\\n- Category effects guide **benchmarking** rather than direct changes.\\n- Avoid manipulative review tactics; emphasize genuine, detailed feedback.\\n\")\n",
    "\n",
    "path = f\"{OUTDIR}/executive_summary.md\"\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(md))\n",
    "print(\"Saved:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1368d-ace3-4d9a-a594-c4e7a9ed87fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56fb6b-19d7-45a8-804c-22a34ffa0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip & handoff (bundle artifacts) \n",
    "import os, glob, json, time, zipfile, textwrap, pandas as pd\n",
    "\n",
    "OUTZIP = \"yelp_ratings_project_v1.zip\"\n",
    "BUNDLE_DIRS = [\n",
    "    \"artifacts_final\",\n",
    "    \"deliverables\",\n",
    "    \"plots_calibration\",\n",
    "    \"plots_pdp_ice\",\n",
    "    \"plots_pdp_ice_fixed\",\n",
    "]\n",
    "BUNDLE_FILES = [\n",
    "    \"perm_importance_stability.csv\",\n",
    "    \"grouped_permutation_importance.csv\",\n",
    "    \"group_ablation_refit_schema_preserving.csv\",\n",
    "    \"group_ablation_pairs_zero_mean.csv\",\n",
    "    \"group_ablation_single_zero_mean.csv\",\n",
    "    \"threshold_sweep_eval.csv\",\n",
    "    \"slice_metrics_city.csv\",\n",
    "    \"slice_metrics_cuisine.csv\",\n",
    "    \"slice_metrics_amenity.csv\",\n",
    "    \"slice_metrics_pricerange.csv\",\n",
    "    \"slice_metrics_review_count_quartiles.csv\",\n",
    "    \"top_false_positives.csv\",\n",
    "    \"top_false_negatives.csv\",\n",
    "    \"slice_city_top.png\",\n",
    "    \"slice_cuisine_top.png\",\n",
    "    \"slice_amenity_top.png\",\n",
    "    \"slice_pricerange_top.png\",\n",
    "]\n",
    "\n",
    "# 1) (Re)create inference script\n",
    "INFER_PY = \"inference_demo.py\"\n",
    "infer_lines = [\n",
    "    \"import json, pandas as pd\",\n",
    "    \"from joblib import load\",\n",
    "    \"\",\n",
    "    \"THRESH = 0.53\",\n",
    "    \"\",\n",
    "    \"def _prob(est, X):\",\n",
    "    \"    try:\",\n",
    "    \"        return est.predict_proba(X)[:,1]\",\n",
    "    \"    except Exception:\",\n",
    "    \"        s = est.decision_function(X)\",\n",
    "    \"        s = (s - s.min()) / (s.max() - s.min() + 1e-12)\",\n",
    "    \"        return s\",\n",
    "    \"\",\n",
    "    \"def load_artifacts(path='artifacts_final'):\",\n",
    "    \"    est = load(f\\\"{path}/final_hgb_svd_v1.joblib\\\")\",\n",
    "    \"    cols = json.load(open(f\\\"{path}/columns_v1.json\\\"))\",\n",
    "    \"    bg = json.load(open(f\\\"{path}/background_means_v1.json\\\"))\",\n",
    "    \"    return est, cols, bg\",\n",
    "    \"\",\n",
    "    \"def predict_with_reasons(sample_df, top_features=None, threshold=THRESH):\",\n",
    "    \"    est, cols, bg = load_artifacts()\",\n",
    "    \"    X = sample_df.reindex(columns=cols, fill_value=0)\",\n",
    "    \"    base = float(_prob(est, X)[0])\",\n",
    "    \"    if top_features is None:\",\n",
    "    \"        try:\",\n",
    "    \"            stab = pd.read_csv('perm_importance_stability.csv', index_col=0)\",\n",
    "    \"            top_features = [c for c in stab.sort_values('importance_mean', ascending=False).index if c in X.columns][:10]\",\n",
    "    \"        except Exception:\",\n",
    "    \"            top_features = list(X.columns[:10])\",\n",
    "    \"    deltas = []\",\n",
    "    \"    for f in top_features:\",\n",
    "    \"        Xtmp = X.copy()\",\n",
    "    \"        neutral = 0.0 if f.startswith(('cat__','attr_','city_')) else bg.get(f, 0.0)\",\n",
    "    \"        try:\",\n",
    "    \"            Xtmp.at[Xtmp.index[0], f] = neutral\",\n",
    "    \"        except Exception:\",\n",
    "    \"            Xtmp[f] = neutral\",\n",
    "    \"        p = float(_prob(est, Xtmp)[0])\",\n",
    "    \"        deltas.append((f, base - p))\",\n",
    "    \"    deltas.sort(key=lambda t: abs(t[1]), reverse=True)\",\n",
    "    \"    return {'prob': base, 'class': int(base >= threshold), 'threshold': threshold, 'reasons': deltas}\",\n",
    "    \"\",\n",
    "    \"if __name__ == '__main__':\",\n",
    "    \"    import sys\",\n",
    "    \"    if len(sys.argv) < 2:\",\n",
    "    \"        print('Usage: python inference_demo.py <single_row.csv>'); raise SystemExit(1)\",\n",
    "    \"    df = pd.read_csv(sys.argv[1])\",\n",
    "    \"    res = predict_with_reasons(df)\",\n",
    "    \"    print(res)\",\n",
    "]\n",
    "with open(INFER_PY, \"w\") as f:\n",
    "    f.write(\"\\n\".join(infer_lines))\n",
    "\n",
    "# 2) (Re)create README without triple-quoted strings\n",
    "README = \"README_SUBMISSION.md\"\n",
    "readme_lines = [\n",
    "    \"# Yelp Ratings Project — Submission (v1)\",\n",
    "    \"\",\n",
    "    \"**What’s inside**\",\n",
    "    \"- `deliverables/executive_summary.md` — one-pager to share with stakeholders\",\n",
    "    \"- `deliverables/results_table.csv` — holdout metrics (HGB(SVD) @ t=0.53)\",\n",
    "    \"- `plots_*/*.png` — calibration, threshold sweep, PDP/ICE, top-slice charts\",\n",
    "    \"- Analysis CSVs — permutation stability, grouped importance, ablations, slices\",\n",
    "    \"- `artifacts_final/` — final model + columns + background means + metadata\",\n",
    "    \"- `inference_demo.py` — quick script to score a single row with reason codes\",\n",
    "    \"\",\n",
    "    \"**How to run the demo**\",\n",
    "    \"```bash\",\n",
    "    \"pip install scikit-learn joblib pandas numpy\",\n",
    "    \"python inference_demo.py example_row.csv\",\n",
    "    \"```\",\n",
    "    \"\",\n",
    "    \"**Notes**\",\n",
    "    \"- Report **holdout** metrics only (post-refit metrics are sanity checks).\",\n",
    "    \"- Insights are correlational; use for hypotheses and small A/B tests.\",\n",
    "    \"- Threshold used: **0.53** (best macro-F1 on holdout).\",\n",
    "]\n",
    "with open(README, \"w\") as f:\n",
    "    f.write(\"\\n\".join(readme_lines))\n",
    "\n",
    "# 3) Build manifest list\n",
    "all_paths = []\n",
    "for d in BUNDLE_DIRS:\n",
    "    if os.path.isdir(d):\n",
    "        for root, _, files in os.walk(d):\n",
    "            for fn in files:\n",
    "                all_paths.append(os.path.join(root, fn))\n",
    "for f in BUNDLE_FILES:\n",
    "    if os.path.exists(f):\n",
    "        all_paths.append(f)\n",
    "# include PDP plots if present, both folders\n",
    "all_paths += glob.glob(\"plots_pdp_ice_fixed/*.png\")\n",
    "all_paths += glob.glob(\"plots_pdp_ice/*.png\")\n",
    "# always include README + inference script\n",
    "all_paths += [README, INFER_PY]\n",
    "\n",
    "# 4) Manifest CSV\n",
    "manifest = []\n",
    "for p in sorted(set(all_paths)):\n",
    "    try:\n",
    "        sz = os.path.getsize(p)\n",
    "        mt = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(os.path.getmtime(p)))\n",
    "    except Exception:\n",
    "        sz, mt = 0, \"\"\n",
    "    manifest.append({\"path\": p, \"size_bytes\": sz, \"modified\": mt})\n",
    "mf = pd.DataFrame(manifest)\n",
    "mf_path = \"submission_manifest.csv\"\n",
    "mf.to_csv(mf_path, index=False)\n",
    "print(\"Saved:\", mf_path)\n",
    "\n",
    "# 5) Zip everything\n",
    "with zipfile.ZipFile(OUTZIP, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for p in sorted(set(all_paths + [mf_path])):\n",
    "        if os.path.exists(p):\n",
    "            z.write(p)\n",
    "print(\"Saved:\", OUTZIP)\n",
    "\n",
    "# 6) Preview contents\n",
    "with zipfile.ZipFile(OUTZIP, \"r\") as z:\n",
    "    names = z.namelist()\n",
    "print(\"Zip contains\", len(names), \"files. First 15 entries:\")\n",
    "for n in names[:15]:\n",
    "    print(\" -\", n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171acac-52dc-4b83-827a-917983797e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2af0d0-a72d-44c9-a941-3d14bb77119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 8A: LogReg-enet coefficient plots (NaN-safe, numeric-only) =====\n",
    "import os, re, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import load\n",
    "\n",
    "os.makedirs(\"plots_logreg\", exist_ok=True)\n",
    "\n",
    "# --- Resolve train vars defensively\n",
    "X_train = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "y_train_vec = globals().get(\"y_train\", globals().get(\"ytr\"))\n",
    "assert X_train is not None and y_train_vec is not None, \"Training variables not found.\"\n",
    "\n",
    "# --- Try to load an existing LogReg; else fit one\n",
    "logreg_path = None\n",
    "for cand in [\"logreg_enet.joblib\", \"artifacts/logreg_enet.joblib\", \"models/logreg_enet.joblib\"]:\n",
    "    if os.path.exists(cand):\n",
    "        logreg_path = cand; break\n",
    "\n",
    "if logreg_path:\n",
    "    logreg_pipe = load(logreg_path)\n",
    "else:\n",
    "    # Numeric-only split into continuous vs binary-like\n",
    "    num_cols = [c for c in X_train.columns if np.issubdtype(X_train[c].dtype, np.number)]\n",
    "    cont_cols = [c for c in num_cols if X_train[c].nunique(dropna=True) > 2]\n",
    "    bin_cols  = [c for c in num_cols if X_train[c].nunique(dropna=True) <= 2]\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cont\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"sc\", StandardScaler())\n",
    "            ]), cont_cols),\n",
    "            (\"bin\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "            ]), bin_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    logreg = LogisticRegression(\n",
    "        solver=\"saga\", penalty=\"elasticnet\", l1_ratio=0.5, C=1.0,\n",
    "        max_iter=5000, n_jobs=-1, random_state=42\n",
    "    )\n",
    "    logreg_pipe = Pipeline([(\"pre\", pre), (\"clf\", logreg)])\n",
    "    logreg_pipe.fit(X_train, y_train_vec)\n",
    "\n",
    "# --- Get feature names and coefs\n",
    "try:\n",
    "    feat_names = logreg_pipe.named_steps[\"pre\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    # Fallback if get_feature_names_out unavailable\n",
    "    # Rebuild names from the ColumnTransformer lists\n",
    "    ct = logreg_pipe.named_steps[\"pre\"]\n",
    "    cont_cols = ct.transformers_[0][2]\n",
    "    bin_cols  = ct.transformers_[1][2]\n",
    "    feat_names = np.array(list(cont_cols) + list(bin_cols))\n",
    "\n",
    "coefs = logreg_pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coefs}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "# --- Group OHE back to readable fields\n",
    "def group_key(feat):\n",
    "    if feat.startswith(\"cat__\"):\n",
    "        return (\"Cuisine\", feat.replace(\"cat__\", \"\"))\n",
    "    if feat.startswith(\"city_\"):\n",
    "        return (\"City\", feat.replace(\"city_\", \"\"))\n",
    "    if feat.startswith(\"attr_\"):\n",
    "        # Strip trailing digits like PriceRange2 -> PriceRange\n",
    "        base = re.sub(r\"\\d+$\", \"\", feat.replace(\"attr_\", \"\"))\n",
    "        return (\"Amenity\", base)\n",
    "    return (\"Feature\", feat)\n",
    "\n",
    "coef_df[[\"group_type\",\"group_name\"]] = coef_df[\"feature\"].apply(lambda f: pd.Series(group_key(f)))\n",
    "group_sum = coef_df.groupby([\"group_type\",\"group_name\"], as_index=False)[\"coef\"].sum()\n",
    "\n",
    "top_pos = group_sum.sort_values(\"coef\", ascending=False).head(15)\n",
    "top_neg = group_sum.sort_values(\"coef\", ascending=True).head(15)\n",
    "\n",
    "print(\"\\nTop positive groups (sum of coeffs):\")\n",
    "print(top_pos[[\"group_type\",\"group_name\",\"coef\"]].to_string(index=False))\n",
    "print(\"\\nTop negative groups (sum of coeffs):\")\n",
    "print(top_neg[[\"group_type\",\"group_name\",\"coef\"]].to_string(index=False))\n",
    "\n",
    "# --- Plot grouped bars\n",
    "stack = pd.concat([top_neg.assign(side=\"neg\"), top_pos.assign(side=\"pos\")], axis=0)\n",
    "labels = stack.apply(lambda r: f\"{r['group_type']}: {r['group_name']}\", axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "ax.barh(labels, stack[\"coef\"])\n",
    "ax.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "ax.set_title(\"LogReg-enet — grouped coefficients (OHE aggregated)\")\n",
    "ax.set_xlabel(\"Coefficient (sum across dummies)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots_logreg/coef_groups_bar.png\", dpi=160)\n",
    "plt.show()\n",
    "print(\"Saved: plots_logreg/coef_groups_bar.png\")\n",
    "\n",
    "# --- Plot top individual features\n",
    "sing_pos = coef_df.head(15)\n",
    "sing_neg = coef_df.tail(15).sort_values(\"coef\")\n",
    "sing_stack = pd.concat([sing_neg.assign(side=\"neg\"), sing_pos.assign(side=\"pos\")], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "ax.barh(sing_stack[\"feature\"], sing_stack[\"coef\"])\n",
    "ax.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "ax.set_title(\"LogReg-enet — top individual coefficients\")\n",
    "ax.set_xlabel(\"Coefficient\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots_logreg/coef_top_singles.png\", dpi=160)\n",
    "plt.show()\n",
    "print(\"Saved: plots_logreg/coef_top_singles.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f8d73-2710-49a1-9c25-50fff61b90af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e31f4-8ca1-477a-b7c4-5863612fdd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare unsupervised representation & choose K (elbow + silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b5e59-941e-4b09-ba1f-85fe01f29686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U1 (fixed): Unsupervised prep + K selection =====\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from joblib import dump\n",
    "\n",
    "# -------- resolve full feature frame --------\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "assert isinstance(X_full, pd.DataFrame) and X_full.shape[1] > 0\n",
    "\n",
    "# -------- directories --------\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "os.makedirs(\"unsup_artifacts\", exist_ok=True)\n",
    "\n",
    "# -------- split columns by dtype --------\n",
    "num_cols = [c for c in X_full.columns if np.issubdtype(X_full[c].dtype, np.number)]\n",
    "cat_cols = [c for c in X_full.columns if c not in num_cols]  # strings, categories, bool-as-object, etc.\n",
    "\n",
    "# Numeric: median-impute + scale (with_mean=False to be sparse-safe)\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\", StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "# Categorical: most-frequent impute + OHE (ignore unknowns at transform time)\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Fit transform -> combined feature matrix (dense or sparse depending on mix)\n",
    "X_feat = ct.fit_transform(X_full)\n",
    "\n",
    "# -------- SVD on combined matrix --------\n",
    "SVD_COMPONENTS = min(30, (X_feat.shape[1] - 1)) if X_feat.shape[1] > 1 else 1\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=42)\n",
    "Z = svd.fit_transform(X_feat)   # latent representation (n x SVD_COMPONENTS)\n",
    "\n",
    "# Save artifacts\n",
    "dump(ct,  \"unsup_artifacts/ct_preproc.joblib\")\n",
    "dump(svd, \"unsup_artifacts/svd.joblib\")\n",
    "pd.DataFrame(Z, columns=[f\"z{i+1}\" for i in range(Z.shape[1])]).to_csv(\"unsup_artifacts/latent_z.csv\", index=False)\n",
    "\n",
    "# -------- K selection (MiniBatchKMeans) --------\n",
    "K_RANGE = list(range(2, 11))\n",
    "inertias, sil_scores = [], []\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "idx_sample = rng.choice(len(Z), size=min(5000, len(Z)), replace=False)\n",
    "\n",
    "for k in K_RANGE:\n",
    "    km = MiniBatchKMeans(\n",
    "        n_clusters=k, random_state=42, n_init=10,\n",
    "        batch_size=2048, max_iter=200\n",
    "    )\n",
    "    km.fit(Z)\n",
    "    inertias.append(km.inertia_)\n",
    "    sil_scores.append(silhouette_score(Z[idx_sample], km.predict(Z[idx_sample])))\n",
    "\n",
    "# -------- plots --------\n",
    "plt.figure(figsize=(6.5,4.2))\n",
    "plt.plot(K_RANGE, inertias, marker=\"o\")\n",
    "plt.title(\"Elbow (MiniBatchKMeans on SVD space)\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Inertia\"); plt.xticks(K_RANGE)\n",
    "plt.tight_layout(); plt.savefig(\"plots_unsup/elbow_kmeans.png\", dpi=160); plt.show()\n",
    "\n",
    "best_k = int(K_RANGE[int(np.argmax(sil_scores))])\n",
    "best_sil = float(max(sil_scores))\n",
    "\n",
    "plt.figure(figsize=(6.5,4.2))\n",
    "plt.plot(K_RANGE, sil_scores, marker=\"o\")\n",
    "plt.axvline(best_k, linestyle=\"--\", alpha=0.6)\n",
    "plt.title(f\"Silhouette by k (best k={best_k}, score={best_sil:.3f})\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Silhouette\"); plt.xticks(K_RANGE); plt.ylim(0,1)\n",
    "plt.tight_layout(); plt.savefig(\"plots_unsup/silhouette_kmeans.png\", dpi=160); plt.show()\n",
    "\n",
    "# -------- summary table --------\n",
    "tbl = pd.DataFrame({\"k\":K_RANGE, \"inertia\":inertias, \"silhouette\":sil_scores})\n",
    "print(\"\\n[STEP U1] K selection summary\")\n",
    "print(tbl.to_string(index=False))\n",
    "print(f\"\\nSuggested k (max silhouette): {best_k}  |  silhouette={best_sil:.3f}\")\n",
    "print(\"Saved: plots_unsup/elbow_kmeans.png, plots_unsup/silhouette_kmeans.png, unsup_artifacts/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c41cd1d-3a79-4122-a746-33fd8e38a2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edd736-2432-41d2-95d6-d6731d29bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U2: Fit clusters, assign labels, and profile =====\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from joblib import load, dump\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "os.makedirs(\"unsup_artifacts\", exist_ok=True)\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# --- 1) Reload preprocessing and latent space\n",
    "ct = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "svd = load(\"unsup_artifacts/svd.joblib\")\n",
    "\n",
    "# Build X_full again the same way we did in U1 (train∪eval union if needed)\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "# Transform to feature matrix -> latent Z\n",
    "X_feat = ct.transform(X_full)\n",
    "Z = svd.transform(X_feat)\n",
    "\n",
    "# Optional post-hoc labels for interpretation (NOT used in clustering)\n",
    "y_full = globals().get(\"y_full\")\n",
    "if y_full is None:\n",
    "    y_tr = globals().get(\"y_train\", globals().get(\"ytr\"))\n",
    "    y_te = globals().get(\"y_eval\")\n",
    "    if y_tr is not None and y_te is not None:\n",
    "        y_full = np.concatenate([np.asarray(y_tr).ravel(), np.asarray(y_te).ravel()])\n",
    "    else:\n",
    "        y_full = None\n",
    "\n",
    "# --- 2) Fit MiniBatchKMeans\n",
    "K = 2  # from U1 suggestion (silhouette max). Change here if you prefer another k.\n",
    "km = MiniBatchKMeans(\n",
    "    n_clusters=K, random_state=42, n_init=10,\n",
    "    batch_size=2048, max_iter=300\n",
    ")\n",
    "km.fit(Z)\n",
    "labels = km.labels_\n",
    "dump(km, f\"unsup_artifacts/kmeans_k{K}.joblib\")\n",
    "pd.DataFrame({\"row_id\": np.arange(len(labels)), \"cluster\": labels}).to_csv(\n",
    "    f\"unsup_artifacts/cluster_labels_k{K}.csv\", index=False\n",
    ")\n",
    "\n",
    "# Silhouette (overall + per-sample for quick glance)\n",
    "try:\n",
    "    sil = silhouette_score(Z, labels)\n",
    "except Exception:\n",
    "    sil = np.nan\n",
    "\n",
    "# --- 3) Feature names of the preprocessed matrix\n",
    "try:\n",
    "    feat_names = ct.get_feature_names_out()\n",
    "except Exception:\n",
    "    # Fallback: try to infer from transformers\n",
    "    feat_names = np.array([f\"f{i}\" for i in range(X_feat.shape[1])])\n",
    "\n",
    "# Compute global mean (preprocessed space) and per-cluster means\n",
    "# For sparse matrix, .mean(axis=0) returns 1 x d sparse; convert to dense\n",
    "if hasattr(X_feat, \"toarray\"):\n",
    "    global_mean = np.asarray(X_feat.mean(axis=0)).ravel()\n",
    "else:\n",
    "    global_mean = X_feat.mean(axis=0)\n",
    "\n",
    "cluster_means = []\n",
    "for c in range(K):\n",
    "    idx = (labels == c)\n",
    "    Xc = X_feat[idx]\n",
    "    mc = np.asarray(Xc.mean(axis=0)).ravel() if hasattr(Xc, \"toarray\") else Xc.mean(axis=0)\n",
    "    cluster_means.append(mc)\n",
    "cluster_means = np.vstack(cluster_means)  # K x d\n",
    "\n",
    "# Build a tidy profile of means\n",
    "profile_rows = []\n",
    "for c in range(K):\n",
    "    prof = pd.DataFrame({\n",
    "        \"cluster\": c,\n",
    "        \"feature\": feat_names,\n",
    "        \"mean_in_cluster\": cluster_means[c],\n",
    "        \"mean_global\": global_mean\n",
    "    })\n",
    "    prof[\"diff_from_global\"] = prof[\"mean_in_cluster\"] - prof[\"mean_global\"]\n",
    "    profile_rows.append(prof)\n",
    "profile_df = pd.concat(profile_rows, ignore_index=True)\n",
    "\n",
    "# Save full profile means (may be large)\n",
    "profile_df.to_csv(\"unsup_outputs/cluster_profile_means.csv\", index=False)\n",
    "\n",
    "# --- 4) Top signals per cluster (most over/under-represented)\n",
    "top_signal_rows = []\n",
    "TOPN = 10\n",
    "for c in range(K):\n",
    "    sub = profile_df[profile_df[\"cluster\"] == c].copy()\n",
    "    sub[\"abs_diff\"] = sub[\"diff_from_global\"].abs()\n",
    "    top_pos = sub.sort_values(\"diff_from_global\", ascending=False).head(TOPN)\n",
    "    top_neg = sub.sort_values(\"diff_from_global\", ascending=True).head(TOPN)\n",
    "    top_pos[\"direction\"] = \"over\"\n",
    "    top_neg[\"direction\"] = \"under\"\n",
    "    sig = pd.concat([top_pos, top_neg], ignore_index=True)\n",
    "    sig[\"rank_within_direction\"] = sig.groupby(\"direction\")[\"abs_diff\"].rank(ascending=False, method=\"first\")\n",
    "    sig[\"cluster\"] = c\n",
    "    top_signal_rows.append(sig)\n",
    "signals_df = pd.concat(top_signal_rows, ignore_index=True)\n",
    "signals_df.to_csv(\"unsup_outputs/cluster_top_signals.csv\", index=False)\n",
    "\n",
    "# --- 5) Post-hoc rating (or success) by cluster\n",
    "summary_rows = []\n",
    "for c in range(K):\n",
    "    idx = (labels == c)\n",
    "    n = int(idx.sum())\n",
    "    frac = n / len(labels)\n",
    "    row = {\"cluster\": c, \"size\": n, \"share\": frac}\n",
    "    if y_full is not None:\n",
    "        row[\"avg_label\"] = float(np.mean(np.asarray(y_full)[idx]))\n",
    "    summary_rows.append(row)\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"cluster\")\n",
    "summary_df.to_csv(\"unsup_outputs/cluster_summary.csv\", index=False)\n",
    "\n",
    "# --- 6) Quick visuals\n",
    "# 2D scatter in SVD space (z1 vs z2)\n",
    "plt.figure(figsize=(7.2, 5.8))\n",
    "# sample to keep plotting light\n",
    "rng = np.random.default_rng(42)\n",
    "sample_idx = rng.choice(len(Z), size=min(6000, len(Z)), replace=False)\n",
    "for c in range(K):\n",
    "    m = sample_idx[labels[sample_idx] == c]\n",
    "    plt.scatter(Z[m, 0], Z[m, 1], s=8, alpha=0.6, label=f\"Cluster {c}\")\n",
    "plt.title(f\"Clusters in SVD space (k={K}) — z1 vs z2\")\n",
    "plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.legend(markerscale=2)\n",
    "plt.tight_layout(); plt.savefig(f\"plots_unsup/cluster_scatter_z12_k{K}.png\", dpi=160); plt.show()\n",
    "print(\"Saved:\", f\"plots_unsup/cluster_scatter_z12_k{K}.png\")\n",
    "\n",
    "# Bar of post-hoc average label\n",
    "if y_full is not None and \"avg_label\" in summary_df.columns:\n",
    "    plt.figure(figsize=(6.5, 4.2))\n",
    "    plt.bar(summary_df[\"cluster\"].astype(str), summary_df[\"avg_label\"])\n",
    "    plt.xlabel(\"Cluster\"); plt.ylabel(\"Avg. label (post-hoc)\")\n",
    "    plt.title(\"Average label by cluster (post-hoc; not used in training)\")\n",
    "    plt.tight_layout(); plt.savefig(f\"plots_unsup/cluster_avg_rating_k{K}.png\", dpi=160); plt.show()\n",
    "    print(\"Saved:\", f\"plots_unsup/cluster_avg_rating_k{K}.png\")\n",
    "\n",
    "# --- 7) Console summaries\n",
    "print(\"\\n[STEP U2] Clustering summary\")\n",
    "print(\"Silhouette (overall):\", round(float(sil), 3))\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nTop over/under signals per cluster (head):\")\n",
    "for c in range(K):\n",
    "    sub = signals_df[signals_df[\"cluster\"] == c]\n",
    "    # show human-friendly top 5 per direction\n",
    "    pos5 = sub[sub[\"direction\"]==\"over\"].sort_values(\"diff_from_global\", ascending=False).head(5)\n",
    "    neg5 = sub[sub[\"direction\"]==\"under\"].sort_values(\"diff_from_global\", ascending=True).head(5)\n",
    "    print(f\"\\nCluster {c} — over-represented:\")\n",
    "    print(pos5[[\"feature\",\"diff_from_global\"]].to_string(index=False))\n",
    "    print(f\"Cluster {c} — under-represented:\")\n",
    "    print(neg5[[\"feature\",\"diff_from_global\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e3287-f3ad-4a7c-a4a8-41052a449849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd950aa-1540-4803-ab1b-8064ef78d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U3: Readable cluster profiles + stakeholder insights =====\n",
    "import os, re, numpy as np, pandas as pd\n",
    "from joblib import load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "\n",
    "# --- Load artifacts from U1/U2\n",
    "ct  = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "svd = load(\"unsup_artifacts/svd.joblib\")\n",
    "km  = load(\"unsup_artifacts/kmeans_k2.joblib\")\n",
    "labels_df = pd.read_csv(\"unsup_artifacts/cluster_labels_k2.csv\")\n",
    "labels = labels_df[\"cluster\"].to_numpy()\n",
    "K = km.n_clusters\n",
    "\n",
    "# Rebuild X_full as before\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "# Transform to preprocessed feature matrix\n",
    "X_feat = ct.transform(X_full)\n",
    "\n",
    "# --- Reconstruct readable feature names\n",
    "# Numeric block names (first transformer)\n",
    "num_cols = ct.transformers_[0][2]\n",
    "# Categorical block names (second transformer) using OHE\n",
    "cat_cols = ct.transformers_[1][2]\n",
    "ohe      = ct.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "feat_names = np.array(list(num_cols) + list(cat_names))\n",
    "\n",
    "# --- Compute global & per-cluster means in preprocessed space\n",
    "if hasattr(X_feat, \"toarray\"):\n",
    "    global_mean = np.asarray(X_feat.mean(axis=0)).ravel()\n",
    "else:\n",
    "    global_mean = X_feat.mean(axis=0)\n",
    "\n",
    "cluster_means = []\n",
    "for c in range(K):\n",
    "    idx = (labels == c)\n",
    "    Xc = X_feat[idx]\n",
    "    mc = np.asarray(Xc.mean(axis=0)).ravel() if hasattr(Xc, \"toarray\") else Xc.mean(axis=0)\n",
    "    cluster_means.append(mc)\n",
    "cluster_means = np.vstack(cluster_means)\n",
    "\n",
    "profile_rows = []\n",
    "for c in range(K):\n",
    "    prof = pd.DataFrame({\n",
    "        \"cluster\": c,\n",
    "        \"feature\": feat_names,\n",
    "        \"mean_in_cluster\": cluster_means[c],\n",
    "        \"mean_global\": global_mean\n",
    "    })\n",
    "    prof[\"diff_from_global\"] = prof[\"mean_in_cluster\"] - prof[\"mean_global\"]\n",
    "    profile_rows.append(prof)\n",
    "profile_readable = pd.concat(profile_rows, ignore_index=True)\n",
    "\n",
    "# Save full profile with readable names\n",
    "profile_path = \"unsup_outputs/cluster_profile_means_readable.csv\"\n",
    "profile_readable.to_csv(profile_path, index=False)\n",
    "print(\"Saved:\", profile_path)\n",
    "\n",
    "# --- Top signals per cluster (readable)\n",
    "def base_feature_name(f):\n",
    "    \"\"\"\n",
    "    Try to collapse OHE names like 'attr_HasTV_False' -> 'attr_HasTV'\n",
    "    Leave continuous & already-atomic names untouched.\n",
    "    \"\"\"\n",
    "    # If it's an OHE name, it looks like \"<origcol>_<category>\"\n",
    "    # Heuristic: if the base column exists in original X_full columns, keep it;\n",
    "    # otherwise strip off the last underscore chunk for readability.\n",
    "    if f in X_full.columns:\n",
    "        return f\n",
    "    # Try stripping last '_category' chunk\n",
    "    parts = f.split(\"_\")\n",
    "    if len(parts) > 1:\n",
    "        return \"_\".join(parts[:-1])\n",
    "    return f\n",
    "\n",
    "TOPN = 10\n",
    "signals_rows = []\n",
    "for c in range(K):\n",
    "    sub = profile_readable[profile_readable[\"cluster\"] == c].copy()\n",
    "    sub[\"abs_diff\"] = sub[\"diff_from_global\"].abs()\n",
    "    top_pos = sub.sort_values(\"diff_from_global\", ascending=False).head(TOPN)\n",
    "    top_neg = sub.sort_values(\"diff_from_global\", ascending=True).head(TOPN)\n",
    "    top_pos[\"direction\"] = \"over\"\n",
    "    top_neg[\"direction\"] = \"under\"\n",
    "    sig = pd.concat([top_pos, top_neg], ignore_index=True)\n",
    "    # Add a 'family' tag for readability (attr_, cat__, rl_, city_, etc.)\n",
    "    def family(f):\n",
    "        if f.startswith(\"attr_\"): return \"Amenity\"\n",
    "        if f.startswith(\"cat__\"): return \"Cuisine\"\n",
    "        if f.startswith(\"rl_\"): return \"Review meta\"\n",
    "        if f.startswith(\"city_\"): return \"City\"\n",
    "        if f.startswith(\"sph\") or f in {\"latitude\",\"longitude\"}: return \"Geo/Distance\"\n",
    "        if f.startswith(\"cluster_\"): return \"Cluster label\"\n",
    "        return \"Numeric/Other\"\n",
    "    sig[\"base_feature\"] = sig[\"feature\"].apply(base_feature_name)\n",
    "    sig[\"family\"] = sig[\"base_feature\"].apply(family)\n",
    "    sig[\"cluster\"] = c\n",
    "    signals_rows.append(sig)\n",
    "signals_readable = pd.concat(signals_rows, ignore_index=True)\n",
    "\n",
    "signals_path = \"unsup_outputs/cluster_top_signals_readable.csv\"\n",
    "signals_readable.to_csv(signals_path, index=False)\n",
    "print(\"Saved:\", signals_path)\n",
    "\n",
    "# --- Post-hoc label (share of high rating) by cluster for the report\n",
    "y_full = globals().get(\"y_full\")\n",
    "if y_full is None:\n",
    "    y_tr = globals().get(\"y_train\", globals().get(\"ytr\"))\n",
    "    y_te = globals().get(\"y_eval\")\n",
    "    if y_tr is not None and y_te is not None:\n",
    "        y_full = np.concatenate([np.asarray(y_tr).ravel(), np.asarray(y_te).ravel()])\n",
    "    else:\n",
    "        y_full = None\n",
    "\n",
    "summary_rows = []\n",
    "for c in range(K):\n",
    "    idx = (labels == c)\n",
    "    n = int(idx.sum())\n",
    "    frac = n / len(labels)\n",
    "    row = {\"cluster\": c, \"size\": n, \"share\": frac}\n",
    "    if y_full is not None:\n",
    "        row[\"share_high_rating\"] = float(np.mean(np.asarray(y_full)[idx]))\n",
    "    summary_rows.append(row)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# --- Write stakeholder-facing insights (Markdown)\n",
    "md_lines = []\n",
    "md_lines.append(\"# Unsupervised Segments — Summary (k=2)\\n\")\n",
    "md_lines.append(\"**Method:** TruncatedSVD → MiniBatchKMeans (k=2). Features include amenities, cuisines, review meta, geo, counts. Ratings used **post-hoc** only for interpretation.\\n\")\n",
    "md_lines.append(\"## Segment sizes\\n\")\n",
    "for _, r in summary_df.iterrows():\n",
    "    size = int(r[\"size\"]); share = r[\"share\"]\n",
    "    if \"share_high_rating\" in r:\n",
    "        md_lines.append(f\"- **Cluster {int(r['cluster'])}** — n={size} ({share:.1%}) · share high-rating={r['share_high_rating']:.1%}\")\n",
    "    else:\n",
    "        md_lines.append(f\"- **Cluster {int(r['cluster'])}** — n={size} ({share:.1%})\")\n",
    "\n",
    "md_lines.append(\"\\n## Characteristic signals (top ±5)\\n\")\n",
    "for c in range(K):\n",
    "    sub = signals_readable[signals_readable[\"cluster\"]==c]\n",
    "    pos5 = sub[sub[\"direction\"]==\"over\"].sort_values(\"diff_from_global\", ascending=False).head(5)\n",
    "    neg5 = sub[sub[\"direction\"]==\"under\"].sort_values(\"diff_from_global\", ascending=True).head(5)\n",
    "    md_lines.append(f\"### Cluster {c}\")\n",
    "    md_lines.append(\"**Over-represented:** \" + \"; \".join([f\"`{row['feature']}`\" for _, row in pos5.iterrows()]) )\n",
    "    md_lines.append(\"**Under-represented:** \" + \"; \".join([f\"`{row['feature']}`\" for _, row in neg5.iterrows()]) )\n",
    "    # Optional: quick heuristic action line\n",
    "    fams = pos5[\"family\"].value_counts().to_dict()\n",
    "    if fams:\n",
    "        topfam = max(fams, key=fams.get)\n",
    "        md_lines.append(f\"_Action hint_: This segment leans on **{topfam}** features; tailor ops/marketing accordingly.\\n\")\n",
    "\n",
    "insights_md = \"unsup_outputs/unsup_insights.md\"\n",
    "with open(insights_md, \"w\") as f:\n",
    "    f.write(\"\\n\".join(md_lines))\n",
    "print(\"Saved:\", insights_md)\n",
    "\n",
    "# --- Small console preview\n",
    "print(\"\\n[STEP U3] Preview — cluster sizes\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\nTop readable signals — head():\")\n",
    "print(signals_readable.head(12).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46f74c-bb06-4704-8f69-2cf2fa6eed95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8517ac-32cf-4afd-b437-70dd5eb123ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U4A: IsolationForest anomalies on SVD space =====\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from joblib import load, dump\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# Reload artifacts\n",
    "ct  = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "svd = load(\"unsup_artifacts/svd.joblib\")\n",
    "km  = load(\"unsup_artifacts/kmeans_k2.joblib\")\n",
    "labels = pd.read_csv(\"unsup_artifacts/cluster_labels_k2.csv\")[\"cluster\"].to_numpy()\n",
    "\n",
    "# Build X_full same way\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "# Latent space\n",
    "X_feat = ct.transform(X_full)\n",
    "Z = svd.transform(X_feat)\n",
    "\n",
    "# Isolation Forest on latent Z\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300, max_samples='auto', contamination=0.01,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "iso.fit(Z)\n",
    "raw_score = iso.score_samples(Z)              # higher = less anomalous\n",
    "anom_score = -raw_score                       # higher = more anomalous\n",
    "pred = iso.predict(Z)                         # -1 anomalous, 1 normal\n",
    "\n",
    "# Assemble dataframe with ranks\n",
    "df = pd.DataFrame({\n",
    "    \"row_id\": np.arange(len(Z)),\n",
    "    \"cluster\": labels,\n",
    "    \"anom_score\": anom_score,\n",
    "    \"iso_pred\": pred\n",
    "})\n",
    "df[\"rank_global\"] = df[\"anom_score\"].rank(ascending=False, method=\"first\")\n",
    "# within-cluster rank\n",
    "df[\"rank_in_cluster\"] = df.groupby(\"cluster\")[\"anom_score\"].rank(ascending=False, method=\"first\")\n",
    "# top 1% flags\n",
    "top_n = max(1, int(0.01 * len(df)))\n",
    "df[\"top1pct_global\"] = df[\"rank_global\"] <= top_n\n",
    "df[\"top1pct_in_cluster\"] = df.groupby(\"cluster\")[\"rank_in_cluster\"].transform(\n",
    "    lambda r: r <= max(1, int(0.01 * len(r)))\n",
    ").astype(bool)\n",
    "\n",
    "out_csv = \"unsup_outputs/anomalies.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(6.5,4.2))\n",
    "plt.hist(df[\"anom_score\"], bins=50)\n",
    "plt.title(\"Anomaly score distribution (higher = more anomalous)\")\n",
    "plt.xlabel(\"anom_score\"); plt.ylabel(\"count\")\n",
    "plt.tight_layout(); plt.savefig(\"plots_unsup/anomaly_score_hist.png\", dpi=160); plt.show()\n",
    "print(\"Saved: plots_unsup/anomaly_score_hist.png\")\n",
    "\n",
    "plt.figure(figsize=(6.5,4.2))\n",
    "data = [df.loc[df[\"cluster\"]==c, \"anom_score\"] for c in sorted(df[\"cluster\"].unique())]\n",
    "plt.boxplot(data, labels=[str(c) for c in sorted(df[\"cluster\"].unique())])\n",
    "plt.title(\"Anomaly scores by cluster\")\n",
    "plt.xlabel(\"cluster\"); plt.ylabel(\"anom_score\")\n",
    "plt.tight_layout(); plt.savefig(\"plots_unsup/anomaly_by_cluster_box.png\", dpi=160); plt.show()\n",
    "print(\"Saved: plots_unsup/anomaly_by_cluster_box.png\")\n",
    "\n",
    "# Console summary\n",
    "summary = df.groupby(\"cluster\").agg(\n",
    "    n=(\"row_id\",\"count\"),\n",
    "    n_top1pct_global=(\"top1pct_global\",\"sum\"),\n",
    "    n_top1pct_in_cluster=(\"top1pct_in_cluster\",\"sum\")\n",
    ").reset_index()\n",
    "print(\"\\n[STEP U4A] Anomaly summary\")\n",
    "print(summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8901c4-29b8-413a-b991-0670cf3429c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee03856-a33c-430c-bf6f-422b8eae7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP U4B — Generate an \"Unsupervised Segment Playbook\" PDF (retry, simplified)\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Image, ListFlowable, ListItem, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import inch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "PLAYBOOK_PDF = \"/mnt/data/unsupervised_segment_playbook.pdf\"\n",
    "signals_csv = \"unsup_outputs/cluster_top_signals_readable.csv\"\n",
    "summary_csv = \"unsup_outputs/cluster_summary.csv\"\n",
    "anoms_csv   = \"unsup_outputs/anomalies.csv\"\n",
    "scatter_png = \"plots_unsup/cluster_scatter_z12_k2.png\"\n",
    "avg_png     = \"plots_unsup/cluster_avg_rating_k2.png\"\n",
    "anom_hist   = \"plots_unsup/anomaly_score_hist.png\"\n",
    "anom_box    = \"plots_unsup/anomaly_by_cluster_box.png\"\n",
    "\n",
    "# Load data (assume created in previous steps)\n",
    "signals = pd.read_csv(signals_csv) if os.path.exists(signals_csv) else pd.DataFrame()\n",
    "summary = pd.read_csv(summary_csv) if os.path.exists(summary_csv) else pd.DataFrame()\n",
    "anoms   = pd.read_csv(anoms_csv) if os.path.exists(anoms_csv) else pd.DataFrame()\n",
    "\n",
    "# Styles\n",
    "styles = getSampleStyleSheet()\n",
    "title = styles[\"Title\"]\n",
    "h1 = styles[\"Heading1\"]\n",
    "h2 = styles[\"Heading2\"]\n",
    "h3 = styles[\"Heading3\"]\n",
    "body = styles[\"BodyText\"]\n",
    "body.spaceAfter = 6\n",
    "\n",
    "bullet = ParagraphStyle(\n",
    "    'Bullet',\n",
    "    parent=styles['BodyText'],\n",
    "    leftIndent=14,\n",
    "    bulletIndent=0,\n",
    "    spaceBefore=2,\n",
    "    spaceAfter=2\n",
    ")\n",
    "\n",
    "doc = SimpleDocTemplate(\n",
    "    PLAYBOOK_PDF, pagesize=letter,\n",
    "    leftMargin=0.7*inch, rightMargin=0.7*inch, topMargin=0.7*inch, bottomMargin=0.7*inch\n",
    ")\n",
    "\n",
    "story = []\n",
    "\n",
    "# Cover\n",
    "story.append(Paragraph(\"Unsupervised Segment Playbook — Yelp Ratings Predictor\", title))\n",
    "story.append(Spacer(1, 0.1*inch))\n",
    "intro = \"Method: TruncatedSVD → MiniBatchKMeans (k=2). Features include amenities, cuisines, review meta, geography, and counts. Ratings are used <b>post-hoc</b> only for interpretation.\"\n",
    "story.append(Paragraph(intro, body))\n",
    "story.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "# Figures (scatter + avg rating)\n",
    "img_w = 6.2*inch\n",
    "for pth, caption in [(scatter_png, \"Clusters in SVD space (z1 vs z2)\"),\n",
    "                     (avg_png, \"Post-hoc average high-rating share by cluster\")]:\n",
    "    if os.path.exists(pth):\n",
    "        im = Image(pth, width=img_w, height=img_w*0.66)\n",
    "        story.append(im)\n",
    "        story.append(Paragraph(caption, styles[\"Italic\"]))\n",
    "        story.append(Spacer(1, 0.12*inch))\n",
    "\n",
    "# Segment sizes table\n",
    "if not summary.empty:\n",
    "    story.append(Paragraph(\"Segment sizes\", h2))\n",
    "    tbl_df = summary.copy()\n",
    "    for col in [\"share\", \"share_high_rating\"]:\n",
    "        if col in tbl_df.columns:\n",
    "            tbl_df[col] = (tbl_df[col]*100.0).map(lambda x: f\"{x:.1f}%\")\n",
    "    if \"cluster\" in tbl_df.columns:\n",
    "        tbl_df[\"cluster\"] = tbl_df[\"cluster\"].astype(int)\n",
    "    data = [tbl_df.columns.tolist()] + tbl_df.values.tolist()\n",
    "    table = Table(data, hAlign=\"LEFT\")\n",
    "    table.setStyle(TableStyle([\n",
    "        (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
    "        (\"GRID\", (0,0), (-1,-1), 0.3, colors.grey),\n",
    "        (\"FONTNAME\", (0,0), (-1,0), \"Helvetica-Bold\"),\n",
    "        (\"ALIGN\", (1,1), (-1,-1), \"CENTER\")\n",
    "    ]))\n",
    "    story.append(table)\n",
    "    story.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "# Cluster profiles\n",
    "if not signals.empty:\n",
    "    story.append(Paragraph(\"Cluster profiles\", h2))\n",
    "    clusters = sorted(signals[\"cluster\"].unique())\n",
    "    for c in clusters:\n",
    "        story.append(Paragraph(f\"Cluster {int(c)}\", h3))\n",
    "        sub = signals[signals[\"cluster\"]==c].copy()\n",
    "        pos = sub[sub[\"direction\"]==\"over\"].sort_values(\"diff_from_global\", ascending=False).head(8)\n",
    "        neg = sub[sub[\"direction\"]==\"under\"].sort_values(\"diff_from_global\", ascending=True).head(8)\n",
    "        if not pos.empty:\n",
    "            story.append(Paragraph(\"Over-represented signals:\", body))\n",
    "            items = [ListItem(Paragraph(f\"{row['feature']}  <font size=9 color=grey>(Δ={row['diff_from_global']:.3f}; {row['family']})</font>\", bullet)) for _, row in pos.iterrows()]\n",
    "            story.append(ListFlowable(items, bulletType='bullet', start='•'))\n",
    "        if not neg.empty:\n",
    "            story.append(Paragraph(\"Under-represented signals:\", body))\n",
    "            items = [ListItem(Paragraph(f\"{row['feature']}  <font size=9 color=grey>(Δ={row['diff_from_global']:.3f}; {row['family']})</font>\", bullet)) for _, row in neg.iterrows()]\n",
    "            story.append(ListFlowable(items, bulletType='bullet', start='•'))\n",
    "        story.append(Spacer(1, 0.1*inch))\n",
    "    story.append(PageBreak())\n",
    "\n",
    "# Anomaly section\n",
    "if not anoms.empty:\n",
    "    story.append(Paragraph(\"Anomalies (IsolationForest on SVD space)\", h2))\n",
    "    summary_anom = anoms.groupby(\"cluster\").agg(\n",
    "        n=(\"row_id\",\"count\"),\n",
    "        n_top1pct_global=(\"top1pct_global\",\"sum\"),\n",
    "        n_top1pct_in_cluster=(\"top1pct_in_cluster\",\"sum\")\n",
    "    ).reset_index()\n",
    "    data = [summary_anom.columns.tolist()] + summary_anom.values.tolist()\n",
    "    table = Table(data, hAlign=\"LEFT\")\n",
    "    table.setStyle(TableStyle([\n",
    "        (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
    "        (\"GRID\", (0,0), (-1,-1), 0.3, colors.grey),\n",
    "        (\"FONTNAME\", (0,0), (-1,0), \"Helvetica-Bold\"),\n",
    "        (\"ALIGN\", (1,1), (-1,-1), \"CENTER\")\n",
    "    ]))\n",
    "    story.append(table)\n",
    "    story.append(Spacer(1, 0.12*inch))\n",
    "    for pth, caption in [(anom_hist, \"Anomaly score distribution (higher = more anomalous)\"),\n",
    "                         (anom_box,  \"Anomaly scores by cluster\")]:\n",
    "        if os.path.exists(pth):\n",
    "            im = Image(pth, width=img_w, height=img_w*0.62)\n",
    "            story.append(im)\n",
    "            story.append(Paragraph(caption, styles[\"Italic\"]))\n",
    "            story.append(Spacer(1, 0.12*inch))\n",
    "\n",
    "# Actionable guidance\n",
    "story.append(Paragraph(\"Actionable guidance (associational)\", h2))\n",
    "bullets = [\n",
    "    \"Use segment membership to tailor <b>listing hygiene</b>: highlight amenities over-represented in the segment; close gaps for under-represented but desirable amenities.\",\n",
    "    \"Lean into <b>review operations</b>: prompt specific, balanced feedback; steady volume matters.\",\n",
    "    \"Benchmark expectations by <b>cuisine/price band</b>; avoid over-interpreting geo effects.\",\n",
    "    \"Treat outliers from the anomaly list as <b>case studies</b>—either risk (data errors) or opportunity (true standouts). Validate changes with small A/B tests.\"\n",
    "]\n",
    "story.append(ListFlowable([ListItem(Paragraph(b, bullet)) for b in bullets], bulletType='bullet', start='•'))\n",
    "\n",
    "# Build PDF\n",
    "doc.build(story)\n",
    "\n",
    "PLAYBOOK_PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfe169-04f9-485f-929b-1ae442d182d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bacd2-1069-4728-854a-5b389b5ab802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U5: Try alternative ks (k=3 and k=7) =====\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from joblib import load, dump\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "os.makedirs(\"unsup_artifacts\", exist_ok=True)\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# --- Load preprocessing + SVD from U1\n",
    "ct  = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "svd = load(\"unsup_artifacts/svd.joblib\")\n",
    "\n",
    "# --- Build X_full exactly like U1/U2\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "# Transform to feature matrix -> latent space\n",
    "X_feat = ct.transform(X_full)\n",
    "Z = svd.transform(X_feat)\n",
    "\n",
    "# Optional post-hoc labels for interpretation only\n",
    "y_full = globals().get(\"y_full\")\n",
    "if y_full is None:\n",
    "    y_tr = globals().get(\"y_train\", globals().get(\"ytr\"))\n",
    "    y_te = globals().get(\"y_eval\")\n",
    "    if y_tr is not None and y_te is not None:\n",
    "        y_full = np.concatenate([np.asarray(y_tr).ravel(), np.asarray(y_te).ravel()])\n",
    "    else:\n",
    "        y_full = None\n",
    "\n",
    "# Reconstruct readable feature names (same approach as U3)\n",
    "num_cols = ct.transformers_[0][2]\n",
    "cat_cols = ct.transformers_[1][2]\n",
    "ohe      = ct.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = ohe.get_feature_names_out(cat_cols)\n",
    "feat_names = np.array(list(num_cols) + list(cat_names))\n",
    "\n",
    "def base_feature_name(f):\n",
    "    # Collapse OHE: \"attr_HasTV_False\" -> \"attr_HasTV\"\n",
    "    if f in X_full.columns:\n",
    "        return f\n",
    "    parts = f.split(\"_\")\n",
    "    return \"_\".join(parts[:-1]) if len(parts) > 1 else f\n",
    "\n",
    "def family(f):\n",
    "    if f.startswith(\"attr_\"): return \"Amenity\"\n",
    "    if f.startswith(\"cat__\"): return \"Cuisine\"\n",
    "    if f.startswith(\"rl_\"): return \"Review meta\"\n",
    "    if f.startswith(\"city_\"): return \"City\"\n",
    "    if f.startswith(\"sph\") or f in {\"latitude\",\"longitude\"}: return \"Geo/Distance\"\n",
    "    if f.startswith(\"cluster_\"): return \"Cluster label\"\n",
    "    return \"Numeric/Other\"\n",
    "\n",
    "def summarize_for_k(K):\n",
    "    km = MiniBatchKMeans(n_clusters=K, random_state=42, n_init=10, batch_size=2048, max_iter=300)\n",
    "    km.fit(Z)\n",
    "    labels = km.labels_\n",
    "    dump(km, f\"unsup_artifacts/kmeans_k{K}.joblib\")\n",
    "    pd.DataFrame({\"row_id\": np.arange(len(labels)), \"cluster\": labels}).to_csv(\n",
    "        f\"unsup_artifacts/cluster_labels_k{K}.csv\", index=False\n",
    "    )\n",
    "    # Silhouette on a sample for speed\n",
    "    rng = np.random.default_rng(42)\n",
    "    idx_sample = rng.choice(len(Z), size=min(6000, len(Z)), replace=False)\n",
    "    sil = float(silhouette_score(Z[idx_sample], km.predict(Z[idx_sample])))\n",
    "\n",
    "    # Global & per-cluster means in preprocessed space\n",
    "    if hasattr(X_feat, \"toarray\"):\n",
    "        global_mean = np.asarray(X_feat.mean(axis=0)).ravel()\n",
    "    else:\n",
    "        global_mean = X_feat.mean(axis=0)\n",
    "\n",
    "    cluster_means = []\n",
    "    for c in range(K):\n",
    "        Xc = X_feat[labels == c]\n",
    "        mc = np.asarray(Xc.mean(axis=0)).ravel() if hasattr(Xc, \"toarray\") else Xc.mean(axis=0)\n",
    "        cluster_means.append(mc)\n",
    "    cluster_means = np.vstack(cluster_means)\n",
    "\n",
    "    # Tidy profile\n",
    "    rows = []\n",
    "    for c in range(K):\n",
    "        prof = pd.DataFrame({\n",
    "            \"cluster\": c,\n",
    "            \"feature\": feat_names,\n",
    "            \"mean_in_cluster\": cluster_means[c],\n",
    "            \"mean_global\": global_mean\n",
    "        })\n",
    "        prof[\"diff_from_global\"] = prof[\"mean_in_cluster\"] - prof[\"mean_global\"]\n",
    "        prof[\"base_feature\"] = prof[\"feature\"].apply(base_feature_name)\n",
    "        prof[\"family\"] = prof[\"base_feature\"].apply(family)\n",
    "        rows.append(prof)\n",
    "    profile = pd.concat(rows, ignore_index=True)\n",
    "    profile.to_csv(f\"unsup_outputs/cluster_profile_means_readable_k{K}.csv\", index=False)\n",
    "\n",
    "    # Top signals per cluster\n",
    "    sig_rows = []\n",
    "    TOPN = 10\n",
    "    for c in range(K):\n",
    "        sub = profile[profile[\"cluster\"]==c].copy()\n",
    "        top_pos = sub.sort_values(\"diff_from_global\", ascending=False).head(TOPN)\n",
    "        top_neg = sub.sort_values(\"diff_from_global\", ascending=True).head(TOPN)\n",
    "        top_pos[\"direction\"] = \"over\"; top_neg[\"direction\"] = \"under\"\n",
    "        sig_rows.append(pd.concat([top_pos, top_neg], ignore_index=True))\n",
    "    signals = pd.concat(sig_rows, ignore_index=True)\n",
    "    signals.to_csv(f\"unsup_outputs/cluster_top_signals_readable_k{K}.csv\", index=False)\n",
    "\n",
    "    # Summary (size/share/+ post-hoc rating share)\n",
    "    summ_rows = []\n",
    "    for c in range(K):\n",
    "        idx = (labels == c)\n",
    "        row = {\"cluster\": c, \"size\": int(idx.sum()), \"share\": float(idx.mean())}\n",
    "        if y_full is not None:\n",
    "            row[\"share_high_rating\"] = float(np.mean(np.asarray(y_full)[idx]))\n",
    "        summ_rows.append(row)\n",
    "    summary_df = pd.DataFrame(summ_rows).sort_values(\"cluster\")\n",
    "    summary_df.to_csv(f\"unsup_outputs/cluster_summary_k{K}.csv\", index=False)\n",
    "\n",
    "    # Plots\n",
    "    plt.figure(figsize=(7.2,5.8))\n",
    "    # light scatter of z1 vs z2\n",
    "    for c in range(K):\n",
    "        m = idx_sample[labels[idx_sample] == c]\n",
    "        plt.scatter(Z[m,0], Z[m,1], s=8, alpha=0.6, label=f\"Cluster {c}\")\n",
    "    plt.title(f\"Clusters in SVD space (k={K}) — z1 vs z2\")\n",
    "    plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.legend(markerscale=2)\n",
    "    plt.tight_layout(); plt.savefig(f\"plots_unsup/cluster_scatter_z12_k{K}.png\", dpi=160); plt.show()\n",
    "    print(\"Saved:\", f\"plots_unsup/cluster_scatter_z12_k{K}.png\")\n",
    "\n",
    "    if y_full is not None and \"share_high_rating\" in summary_df.columns:\n",
    "        plt.figure(figsize=(6.5,4.2))\n",
    "        plt.bar(summary_df[\"cluster\"].astype(str), summary_df[\"share_high_rating\"])\n",
    "        plt.xlabel(\"Cluster\"); plt.ylabel(\"Avg. high-rating share (post-hoc)\")\n",
    "        plt.title(f\"Avg. label by cluster (k={K})\")\n",
    "        plt.tight_layout(); plt.savefig(f\"plots_unsup/cluster_avg_rating_k{K}.png\", dpi=160); plt.show()\n",
    "        print(\"Saved:\", f\"plots_unsup/cluster_avg_rating_k{K}.png\")\n",
    "\n",
    "    # Console summary\n",
    "    print(f\"\\n[STEP U5] Summary for k={K}\")\n",
    "    print(f\"Silhouette: {sil:.3f}\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "# Run for k=3 and k=7\n",
    "for K in (3, 7):\n",
    "    summarize_for_k(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc21d6-670b-4e60-9536-0a268fe5881a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27922c-2277-460d-a726-b5e7f9885d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U6: Summaries for k=3 main + k=7 spotlight =====\n",
    "import os, pandas as pd, zipfile\n",
    "\n",
    "def need(path):\n",
    "    assert os.path.exists(path), f\"Missing file: {path}. Did STEP U5 complete?\"\n",
    "    return path\n",
    "\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "\n",
    "# --- Load STEP U5 outputs\n",
    "summ_k3 = pd.read_csv(need(\"unsup_outputs/cluster_summary_k3.csv\"))\n",
    "sig_k3  = pd.read_csv(need(\"unsup_outputs/cluster_top_signals_readable_k3.csv\"))\n",
    "summ_k7 = pd.read_csv(need(\"unsup_outputs/cluster_summary_k7.csv\"))\n",
    "sig_k7  = pd.read_csv(need(\"unsup_outputs/cluster_top_signals_readable_k7.csv\"))\n",
    "\n",
    "def pct(x): \n",
    "    try: return f\"{100*float(x):.1f}%\"\n",
    "    except: return str(x)\n",
    "\n",
    "# --- k=3 main summary (Markdown)\n",
    "lines = []\n",
    "lines.append(\"# Unsupervised Segments — Main (k=3)\\n\")\n",
    "lines.append(\"**Method:** TruncatedSVD → MiniBatchKMeans (k=3). Ratings used **post-hoc** only for interpretation.\\n\")\n",
    "\n",
    "tbl = summ_k3.copy()\n",
    "if \"share\" in tbl: tbl[\"share\"] = tbl[\"share\"].map(pct)\n",
    "if \"share_high_rating\" in tbl: tbl[\"share_high_rating\"] = tbl[\"share_high_rating\"].map(pct)\n",
    "\n",
    "lines.append(\"## Segment sizes & post-hoc high-rating share\")\n",
    "lines.append(tbl.to_markdown(index=False))\n",
    "lines.append(\"\")\n",
    "\n",
    "lines.append(\"## Cluster profiles — characteristic signals (top ±5)\")\n",
    "for c in sorted(sig_k3[\"cluster\"].unique()):\n",
    "    sub = sig_k3[sig_k3[\"cluster\"]==c]\n",
    "    pos5 = sub[sub[\"direction\"]==\"over\"].sort_values(\"diff_from_global\", ascending=False).head(5)\n",
    "    neg5 = sub[sub[\"direction\"]==\"under\"].sort_values(\"diff_from_global\", ascending=True).head(5)\n",
    "    lines.append(f\"### Cluster {int(c)}\")\n",
    "    if not pos5.empty:\n",
    "        lines.append(\"**Over-represented:** \" + \n",
    "                     \"; \".join(f\"`{r.feature}` (Δ={r.diff_from_global:.3f}, {r.family})\" for _, r in pos5.iterrows()))\n",
    "    if not neg5.empty:\n",
    "        lines.append(\"**Under-represented:** \" + \n",
    "                     \"; \".join(f\"`{r.feature}` (Δ={r.diff_from_global:.3f}, {r.family})\" for _, r in neg5.iterrows()))\n",
    "    lines.append(\"\")\n",
    "\n",
    "# Include plots if available\n",
    "for p, cap in [(\"plots_unsup/cluster_scatter_z12_k3.png\",\"Clusters in SVD space (k=3) — z1 vs z2\"),\n",
    "               (\"plots_unsup/cluster_avg_rating_k3.png\",\"Post-hoc average high-rating share (k=3)\")]:\n",
    "    if os.path.exists(p):\n",
    "        lines.append(f\"**{cap}**\")\n",
    "        lines.append(f\"![{cap}]({p})\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "md_k3 = \"unsup_outputs/unsup_summary_k3.md\"\n",
    "with open(md_k3, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "print(\"Saved:\", md_k3)\n",
    "\n",
    "# --- k=7 spotlight (highest post-hoc high-rating cluster)\n",
    "best = summ_k7.loc[summ_k7[\"share_high_rating\"].idxmax()]\n",
    "cstar = int(best[\"cluster\"])\n",
    "spot = []\n",
    "spot.append(\"# Segment spotlight — Premium cohort (k=7)\\n\")\n",
    "spot.append(f\"**Cluster {cstar}** — size={int(best['size'])} (~{pct(best['share'])}), \"\n",
    "            f\"post-hoc high-rating share ≈ **{pct(best['share_high_rating'])}**.\\n\")\n",
    "\n",
    "sub7 = sig_k7[sig_k7[\"cluster\"]==cstar]\n",
    "pos8 = sub7[sub7[\"direction\"]==\"over\"].sort_values(\"diff_from_global\", ascending=False).head(8)\n",
    "neg8 = sub7[sub7[\"direction\"]==\"under\"].sort_values(\"diff_from_global\", ascending=True).head(8)\n",
    "\n",
    "spot.append(\"## Characteristic signals\")\n",
    "spot.append(\"**Over-represented:** \" + \n",
    "            \"; \".join(f\"`{r.feature}` (Δ={r.diff_from_global:.3f}, {r.family})\" for _, r in pos8.iterrows()))\n",
    "spot.append(\"**Under-represented:** \" + \n",
    "            \"; \".join(f\"`{r.feature}` (Δ={r.diff_from_global:.3f}, {r.family})\" for _, r in neg8.iterrows()))\n",
    "spot.append(\"\")\n",
    "\n",
    "for p, cap in [(\"plots_unsup/cluster_scatter_z12_k7.png\",\"Clusters in SVD space (k=7) — z1 vs z2\"),\n",
    "               (\"plots_unsup/cluster_avg_rating_k7.png\",\"Post-hoc average high-rating share (k=7)\")]:\n",
    "    if os.path.exists(p):\n",
    "        spot.append(f\"**{cap}**\")\n",
    "        spot.append(f\"![{cap}]({p})\")\n",
    "        spot.append(\"\")\n",
    "\n",
    "md_k7 = \"unsup_outputs/unsup_spotlight_k7.md\"\n",
    "with open(md_k7, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(spot))\n",
    "print(\"Saved:\", md_k7)\n",
    "\n",
    "# --- Zip addendum with markdowns + CSVs + plots\n",
    "zip_path = \"unsup_addendum_k3_k7.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for p in [\n",
    "        md_k3, md_k7,\n",
    "        \"unsup_outputs/cluster_summary_k3.csv\",\n",
    "        \"unsup_outputs/cluster_top_signals_readable_k3.csv\",\n",
    "        \"unsup_outputs/cluster_profile_means_readable_k3.csv\",\n",
    "        \"unsup_outputs/cluster_summary_k7.csv\",\n",
    "        \"unsup_outputs/cluster_top_signals_readable_k7.csv\",\n",
    "        \"unsup_outputs/cluster_profile_means_readable_k7.csv\",\n",
    "        \"unsup_outputs/anomalies.csv\",\n",
    "        \"plots_unsup/cluster_scatter_z12_k3.png\",\n",
    "        \"plots_unsup/cluster_avg_rating_k3.png\",\n",
    "        \"plots_unsup/cluster_scatter_z12_k7.png\",\n",
    "        \"plots_unsup/cluster_avg_rating_k7.png\",\n",
    "        \"plots_unsup/anomaly_score_hist.png\",\n",
    "        \"plots_unsup/anomaly_by_cluster_box.png\",\n",
    "    ]:\n",
    "        if os.path.exists(p):\n",
    "            z.write(p, arcname=os.path.basename(p))\n",
    "print(\"Saved:\", zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e6a7f-585d-43fa-9612-152951f5c46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0ac6d-8c5b-43ee-b3ad-0c6ad2ef364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U7a: k-Prototypes hybrid clustering (K=3) =====\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from joblib import load, dump\n",
    "\n",
    "# 1) Try to import k-Prototypes\n",
    "try:\n",
    "    from kmodes.kprototypes import KPrototypes\n",
    "except Exception as e:\n",
    "    raise SystemExit(\n",
    "        \"kmodes is not installed. Run:\\n  pip install kmodes\\nthen re-run STEP U7a.\\n\"\n",
    "        f\"Import error: {e}\"\n",
    "    )\n",
    "\n",
    "os.makedirs(\"unsup_kproto\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# 2) Load artifacts to recover schema + latent space for plotting\n",
    "ct  = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "svd = load(\"unsup_artifacts/svd.joblib\")\n",
    "\n",
    "# Build X_full exactly as in earlier steps\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "# Post-hoc label for interpretation only\n",
    "y_full = globals().get(\"y_full\")\n",
    "if y_full is None:\n",
    "    y_tr = globals().get(\"y_train\", globals().get(\"ytr\"))\n",
    "    y_te = globals().get(\"y_eval\")\n",
    "    y_full = (np.concatenate([np.asarray(y_tr).ravel(), np.asarray(y_te).ravel()])\n",
    "              if y_tr is not None and y_te is not None else None)\n",
    "\n",
    "# 3) Recover numeric/categorical column lists from your ColumnTransformer\n",
    "num_cols = list(ct.transformers_[0][2])\n",
    "cat_cols = list(ct.transformers_[1][2])\n",
    "assert len(num_cols) + len(cat_cols) > 0, \"Could not recover numeric/categorical columns from ct.\"\n",
    "\n",
    "# 4) Prepare matrices for k-Prototypes\n",
    "# - Numerics: coerce -> float, impute median, standardize\n",
    "# - Categoricals: to string categories, fillna(\"missing\")\n",
    "num_df = X_full[num_cols].copy()\n",
    "for c in num_cols:\n",
    "    num_df[c] = pd.to_numeric(num_df[c], errors=\"coerce\")\n",
    "num_df = num_df.fillna(num_df.median(numeric_only=True))\n",
    "\n",
    "# standardize\n",
    "num_arr = (num_df - num_df.mean()) / (num_df.std(ddof=0) + 1e-9)\n",
    "num_arr = num_arr.to_numpy()\n",
    "\n",
    "cat_df = X_full[cat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    cat_df[c] = cat_df[c].astype(\"string\").fillna(\"missing\")\n",
    "cat_arr = cat_df.to_numpy()\n",
    "\n",
    "# Concatenate numerics + categoricals into a single object array as expected by k-Prototypes\n",
    "X_kp = np.concatenate([num_arr, cat_arr], axis=1).astype(object)\n",
    "cat_idx = list(range(num_arr.shape[1], num_arr.shape[1] + cat_arr.shape[1]))  # positions of categorical columns\n",
    "\n",
    "# 5) Fit k-Prototypes (K=3)\n",
    "K = 3\n",
    "kproto = KPrototypes(n_jobs=-1, n_clusters=K, init='Cao', n_init=5, max_iter=50, random_state=42)\n",
    "labels = kproto.fit_predict(X_kp, categorical=cat_idx)\n",
    "\n",
    "# Save artifacts\n",
    "dump(kproto, f\"unsup_kproto/kproto_k{K}.joblib\")\n",
    "pd.DataFrame({\"row_id\": np.arange(len(labels)), \"cluster\": labels}).to_csv(\n",
    "    f\"unsup_kproto/labels_k{K}.csv\", index=False\n",
    ")\n",
    "\n",
    "# 6) Summarize: cluster sizes + (optional) post-hoc high-rating share\n",
    "summ_rows = []\n",
    "for c in range(K):\n",
    "    idx = (labels == c)\n",
    "    row = {\"cluster\": int(c), \"size\": int(idx.sum()), \"share\": float(idx.mean())}\n",
    "    if y_full is not None:\n",
    "        row[\"share_high_rating\"] = float(np.mean(np.asarray(y_full)[idx]))\n",
    "    summ_rows.append(row)\n",
    "summary_df = pd.DataFrame(summ_rows).sort_values(\"cluster\")\n",
    "summary_df.to_csv(f\"unsup_kproto/summary_k{K}.csv\", index=False)\n",
    "\n",
    "# 7) Categorical \"top signals\": for each categorical column, which levels are most over/under represented?\n",
    "sig_rows = []\n",
    "for c in range(K):\n",
    "    idx = (labels == c)\n",
    "    sub = cat_df[idx]\n",
    "    for col in cat_cols:\n",
    "        # frequency in cluster vs global\n",
    "        freq_c = sub[col].value_counts(normalize=True, dropna=False)\n",
    "        freq_g = cat_df[col].value_counts(normalize=True, dropna=False)\n",
    "        # align\n",
    "        all_levels = freq_g.index.union(freq_c.index)\n",
    "        diff = (freq_c.reindex(all_levels).fillna(0) - freq_g.reindex(all_levels).fillna(0)).sort_values(ascending=False)\n",
    "        # take top +/- 5\n",
    "        top_over  = diff.head(5)\n",
    "        top_under = diff.tail(5)\n",
    "        for lvl, dv in top_over.items():\n",
    "            sig_rows.append({\"cluster\": c, \"column\": col, \"level\": str(lvl), \"direction\": \"over\", \"diff\": float(dv)})\n",
    "        for lvl, dv in top_under.items():\n",
    "            sig_rows.append({\"cluster\": c, \"column\": col, \"level\": str(lvl), \"direction\": \"under\", \"diff\": float(dv)})\n",
    "signals_df = pd.DataFrame(sig_rows)\n",
    "signals_df.to_csv(f\"unsup_kproto/top_signals_k{K}.csv\", index=False)\n",
    "\n",
    "# 8) Quick visuals: project to SVD space (z1,z2) and color by k-Prototypes labels\n",
    "X_feat = ct.transform(X_full)          # same preproc as before\n",
    "Z = svd.transform(X_feat)              # latent for plotting\n",
    "plt.figure(figsize=(7.2,5.8))\n",
    "rng = np.random.default_rng(42)\n",
    "sample_idx = rng.choice(len(Z), size=min(6000, len(Z)), replace=False)\n",
    "for c in range(K):\n",
    "    m = sample_idx[labels[sample_idx] == c]\n",
    "    plt.scatter(Z[m,0], Z[m,1], s=8, alpha=0.6, label=f\"Cluster {c}\")\n",
    "plt.title(f\"k-Prototypes clusters in SVD space (k={K})\")\n",
    "plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.legend(markerscale=2)\n",
    "plt.tight_layout(); plt.savefig(f\"plots_unsup/kproto_scatter_k{K}.png\", dpi=160); plt.show()\n",
    "print(\"Saved:\", f\"plots_unsup/kproto_scatter_k{K}.png\")\n",
    "\n",
    "if y_full is not None and \"share_high_rating\" in summary_df.columns:\n",
    "    plt.figure(figsize=(6.2,4.2))\n",
    "    plt.bar(summary_df[\"cluster\"].astype(str), summary_df[\"share_high_rating\"])\n",
    "    plt.xlabel(\"Cluster\"); plt.ylabel(\"Post-hoc high-rating share\")\n",
    "    plt.title(f\"k-Prototypes — avg label by cluster (k={K})\")\n",
    "    plt.tight_layout(); plt.savefig(f\"plots_unsup/kproto_avg_rating_k{K}.png\", dpi=160); plt.show()\n",
    "    print(\"Saved:\", f\"plots_unsup/kproto_avg_rating_k{K}.png\")\n",
    "\n",
    "# 9) Console summary\n",
    "print(\"\\n[STEP U7a] k-Prototypes summary (k=3)\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\nTop categorical signals — head():\")\n",
    "print(signals_df.head(12).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bd0c4-1618-4688-9f8a-78a10ee6d397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172cbe6-a0e1-4245-8762-d927b8dda368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U7b: k-Prototypes (K=7) + side-by-side comparison =====\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from joblib import load, dump\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# k-Prototypes\n",
    "try:\n",
    "    from kmodes.kprototypes import KPrototypes\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"Please install kmodes first: pip install kmodes\\n\" + str(e))\n",
    "\n",
    "os.makedirs(\"unsup_kproto\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# --- Load preprocessing+SVD (from U1) and rebuild X_full\n",
    "ct  = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "svd = load(\"unsup_artifacts/svd.joblib\")\n",
    "\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "# Post-hoc label for interpretation only\n",
    "y_full = globals().get(\"y_full\")\n",
    "if y_full is None:\n",
    "    y_tr = globals().get(\"y_train\", globals().get(\"ytr\"))\n",
    "    y_te = globals().get(\"y_eval\")\n",
    "    y_full = (np.concatenate([np.asarray(y_tr).ravel(), np.asarray(y_te).ravel()])\n",
    "              if y_tr is not None and y_te is not None else None)\n",
    "\n",
    "# --- Recover numeric/categorical columns from ct\n",
    "num_cols = list(ct.transformers_[0][2])\n",
    "cat_cols = list(ct.transformers_[1][2])\n",
    "\n",
    "# Prepare k-Prototypes matrix (same as U7a)\n",
    "num_df = X_full[num_cols].copy()\n",
    "for c in num_cols:\n",
    "    num_df[c] = pd.to_numeric(num_df[c], errors=\"coerce\")\n",
    "num_df = num_df.fillna(num_df.median(numeric_only=True))\n",
    "num_arr = (num_df - num_df.mean()) / (num_df.std(ddof=0) + 1e-9)\n",
    "num_arr = num_arr.to_numpy()\n",
    "\n",
    "cat_df = X_full[cat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    cat_df[c] = cat_df[c].astype(\"string\").fillna(\"missing\")\n",
    "cat_arr = cat_df.to_numpy()\n",
    "\n",
    "X_kp = np.concatenate([num_arr, cat_arr], axis=1).astype(object)\n",
    "cat_idx = list(range(num_arr.shape[1], num_arr.shape[1] + cat_arr.shape[1]))\n",
    "\n",
    "# --- Fit k-Prototypes K=7\n",
    "K = 7\n",
    "kproto7 = KPrototypes(n_clusters=K, init='Cao', n_init=5, max_iter=50, random_state=42, n_jobs=-1)\n",
    "labels7 = kproto7.fit_predict(X_kp, categorical=cat_idx)\n",
    "\n",
    "dump(kproto7, f\"unsup_kproto/kproto_k{K}.joblib\")\n",
    "pd.DataFrame({\"row_id\": np.arange(len(labels7)), \"cluster\": labels7}).to_csv(\n",
    "    f\"unsup_kproto/labels_k{K}.csv\", index=False\n",
    ")\n",
    "\n",
    "# --- Summary for K=7\n",
    "summ_rows = []\n",
    "for c in range(K):\n",
    "    idx = (labels7 == c)\n",
    "    row = {\"cluster\": int(c), \"size\": int(idx.sum()), \"share\": float(idx.mean())}\n",
    "    if y_full is not None:\n",
    "        row[\"share_high_rating\"] = float(np.mean(np.asarray(y_full)[idx]))\n",
    "    summ_rows.append(row)\n",
    "summary7 = pd.DataFrame(summ_rows).sort_values(\"cluster\")\n",
    "summary7.to_csv(f\"unsup_kproto/summary_k{K}.csv\", index=False)\n",
    "\n",
    "# --- Top categorical signals for K=7\n",
    "sig_rows = []\n",
    "for c in range(K):\n",
    "    idx = (labels7 == c)\n",
    "    sub = cat_df[idx]\n",
    "    for col in cat_cols:\n",
    "        freq_c = sub[col].value_counts(normalize=True, dropna=False)\n",
    "        freq_g = cat_df[col].value_counts(normalize=True, dropna=False)\n",
    "        all_levels = freq_g.index.union(freq_c.index)\n",
    "        diff = (freq_c.reindex(all_levels).fillna(0) - freq_g.reindex(all_levels).fillna(0)).sort_values(ascending=False)\n",
    "        for lvl, dv in diff.head(5).items():\n",
    "            sig_rows.append({\"cluster\": c, \"column\": col, \"level\": str(lvl), \"direction\": \"over\", \"diff\": float(dv)})\n",
    "        for lvl, dv in diff.tail(5).items():\n",
    "            sig_rows.append({\"cluster\": c, \"column\": col, \"level\": str(lvl), \"direction\": \"under\", \"diff\": float(dv)})\n",
    "signals7 = pd.DataFrame(sig_rows)\n",
    "signals7.to_csv(f\"unsup_kproto/top_signals_k{K}.csv\", index=False)\n",
    "\n",
    "# --- Plots (project to SVD space for visualization)\n",
    "X_feat = ct.transform(X_full)\n",
    "Z = svd.transform(X_feat)\n",
    "\n",
    "import numpy.random as npr\n",
    "rng = npr.default_rng(42)\n",
    "sample_idx = rng.choice(len(Z), size=min(6000, len(Z)), replace=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.8))\n",
    "for c in range(K):\n",
    "    m = sample_idx[labels7[sample_idx] == c]\n",
    "    plt.scatter(Z[m,0], Z[m,1], s=8, alpha=0.6, label=f\"Cluster {c}\")\n",
    "plt.title(f\"k-Prototypes clusters in SVD space (k={K})\")\n",
    "plt.xlabel(\"z1\"); plt.ylabel(\"z2\"); plt.legend(markerscale=2)\n",
    "plt.tight_layout(); plt.savefig(f\"plots_unsup/kproto_scatter_k{K}.png\", dpi=160); plt.show()\n",
    "print(\"Saved:\", f\"plots_unsup/kproto_scatter_k{K}.png\")\n",
    "\n",
    "if y_full is not None and \"share_high_rating\" in summary7.columns:\n",
    "    plt.figure(figsize=(6.2,4.2))\n",
    "    plt.bar(summary7[\"cluster\"].astype(str), summary7[\"share_high_rating\"])\n",
    "    plt.xlabel(\"Cluster\"); plt.ylabel(\"Post-hoc high-rating share\")\n",
    "    plt.title(f\"k-Prototypes — avg label by cluster (k={K})\")\n",
    "    plt.tight_layout(); plt.savefig(f\"plots_unsup/kproto_avg_rating_k{K}.png\", dpi=160); plt.show()\n",
    "    print(\"Saved:\", f\"plots_unsup/kproto_avg_rating_k{K}.png\")\n",
    "\n",
    "print(\"\\n[STEP U7b] k-Prototypes summary (k=7)\")\n",
    "print(summary7.to_string(index=False))\n",
    "\n",
    "# --- Side-by-side comparison table on the same SVD space\n",
    "rows = []\n",
    "\n",
    "# k-means labels from earlier (U5)\n",
    "def sil_on_Z(labels_any):\n",
    "    # compute silhouette on Z using a sample for speed & consistency\n",
    "    lab_s = labels_any[sample_idx]\n",
    "    return float(silhouette_score(Z[sample_idx], lab_s))\n",
    "\n",
    "if os.path.exists(\"unsup_artifacts/cluster_labels_k3.csv\"):\n",
    "    km3 = pd.read_csv(\"unsup_artifacts/cluster_labels_k3.csv\")[\"cluster\"].to_numpy()\n",
    "    sil_km3 = sil_on_Z(km3)\n",
    "    sk3 = pd.read_csv(\"unsup_outputs/cluster_summary_k3.csv\")\n",
    "    rows.append({\"method\":\"kmeans\",\"k\":3,\n",
    "                 \"silhouette_on_SVD\": sil_km3,\n",
    "                 \"max_posthoc_high_share\": float(sk3[\"share_high_rating\"].max())})\n",
    "\n",
    "if os.path.exists(\"unsup_artifacts/cluster_labels_k7.csv\"):\n",
    "    km7 = pd.read_csv(\"unsup_artifacts/cluster_labels_k7.csv\")[\"cluster\"].to_numpy()\n",
    "    sil_km7 = sil_on_Z(km7)\n",
    "    sk7 = pd.read_csv(\"unsup_outputs/cluster_summary_k7.csv\")\n",
    "    rows.append({\"method\":\"kmeans\",\"k\":7,\n",
    "                 \"silhouette_on_SVD\": sil_km7,\n",
    "                 \"max_posthoc_high_share\": float(sk7[\"share_high_rating\"].max())})\n",
    "\n",
    "# k-prototypes k=3 (from U7a)\n",
    "if os.path.exists(\"unsup_kproto/labels_k3.csv\"):\n",
    "    kp3 = pd.read_csv(\"unsup_kproto/labels_k3.csv\")[\"cluster\"].to_numpy()\n",
    "    sil_kp3 = sil_on_Z(kp3)\n",
    "    sp3 = pd.read_csv(\"unsup_kproto/summary_k3.csv\")\n",
    "    rows.append({\"method\":\"kprototypes\",\"k\":3,\n",
    "                 \"silhouette_on_SVD\": sil_kp3,\n",
    "                 \"max_posthoc_high_share\": float(sp3[\"share_high_rating\"].max())})\n",
    "\n",
    "# k-prototypes k=7 (current)\n",
    "sil_kp7 = sil_on_Z(labels7)\n",
    "rows.append({\"method\":\"kprototypes\",\"k\":7,\n",
    "             \"silhouette_on_SVD\": sil_kp7,\n",
    "             \"max_posthoc_high_share\": float(summary7[\"share_high_rating\"].max())})\n",
    "\n",
    "cmp_df = pd.DataFrame(rows).sort_values([\"method\",\"k\"]).reset_index(drop=True)\n",
    "cmp_path = \"unsup_kproto/segmentation_comparison.csv\"\n",
    "cmp_df.to_csv(cmp_path, index=False)\n",
    "\n",
    "print(\"\\n[STEP U7b] Side-by-side segmentation comparison (silhouette on SVD)\")\n",
    "print(cmp_df.to_string(index=False))\n",
    "print(\"Saved:\", cmp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023750f-2f61-487a-b163-a653e38d4578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b1a4a-4154-4c53-a4ce-d9928cf407df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP U7c: Finalize unsupervised choice (k-Prototypes K=3) and export =====\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# 1) Load comparison + summaries\n",
    "cmp_path   = \"unsup_kproto/segmentation_comparison.csv\"\n",
    "summ_kp3   = \"unsup_kproto/summary_k3.csv\"\n",
    "sig_cat_kp3= \"unsup_kproto/top_signals_k3.csv\"\n",
    "labels_kp3 = \"unsup_kproto/labels_k3.csv\"\n",
    "\n",
    "cmp_df   = pd.read_csv(cmp_path)\n",
    "summ_df  = pd.read_csv(summ_kp3)\n",
    "sig_cat  = pd.read_csv(sig_cat_kp3)\n",
    "labels   = pd.read_csv(labels_kp3)\n",
    "\n",
    "# 2) Make a small silhouette comparison bar chart\n",
    "plt.figure(figsize=(6.5, 4.2))\n",
    "show = cmp_df.copy()\n",
    "show[\"label\"] = show[\"method\"] + \" k=\" + show[\"k\"].astype(str)\n",
    "plt.bar(show[\"label\"], show[\"silhouette_on_SVD\"])\n",
    "plt.ylabel(\"Silhouette (on SVD space)\")\n",
    "plt.title(\"Segmentation quality comparison\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots_unsup/segmentation_silhouette_comparison.png\", dpi=160)\n",
    "plt.show()\n",
    "print(\"Saved: plots_unsup/segmentation_silhouette_comparison.png\")\n",
    "\n",
    "# 3) Compute NUMERIC top signals for k-Prototypes K=3 (over/under vs global)\n",
    "#    (Complements categorical 'top_signals_k3.csv')\n",
    "ct = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "num_cols = list(ct.transformers_[0][2])  # numeric raw columns\n",
    "# Rebuild X_full\n",
    "X_full = globals().get(\"X_full\")\n",
    "if X_full is None:\n",
    "    Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "    Xte_ = globals().get(\"Xte\")\n",
    "    assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "    cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "    X_full = pd.concat([\n",
    "        Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "        Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "    ], axis=0, ignore_index=True)\n",
    "\n",
    "num_df = X_full[num_cols].copy()\n",
    "for c in num_cols:\n",
    "    num_df[c] = pd.to_numeric(num_df[c], errors=\"coerce\")\n",
    "num_df = num_df.fillna(num_df.median(numeric_only=True))\n",
    "\n",
    "labs = labels[\"cluster\"].to_numpy()\n",
    "global_mean = num_df.mean(axis=0)\n",
    "rows = []\n",
    "TOP = 10\n",
    "for c in sorted(np.unique(labs)):\n",
    "    sub = num_df[labs == c]\n",
    "    mean_c = sub.mean(axis=0)\n",
    "    diff = (mean_c - global_mean).sort_values(ascending=False)\n",
    "    top_over  = diff.head(TOP)\n",
    "    top_under = diff.tail(TOP)\n",
    "    for feat, dv in top_over.items():\n",
    "        rows.append({\"cluster\": int(c), \"feature\": feat, \"direction\": \"over\", \"diff_from_global\": float(dv)})\n",
    "    for feat, dv in top_under.items():\n",
    "        rows.append({\"cluster\": int(c), \"feature\": feat, \"direction\": \"under\", \"diff_from_global\": float(dv)})\n",
    "num_sig = pd.DataFrame(rows)\n",
    "num_sig.to_csv(\"unsup_kproto/top_numeric_signals_k3.csv\", index=False)\n",
    "print(\"Saved: unsup_kproto/top_numeric_signals_k3.csv\")\n",
    "\n",
    "# 4) Final selection write-up (Markdown)\n",
    "def pct(x): \n",
    "    try: return f\"{100*float(x):.1f}%\"\n",
    "    except: return str(x)\n",
    "\n",
    "choice_md = []\n",
    "choice_md.append(\"# Final Unsupervised Selection\\n\")\n",
    "choice_md.append(\"**Chosen segmentation:** k-Prototypes (hybrid k-means/k-modes), **K=3**.\\n\")\n",
    "choice_md.append(\"**Why:** best separation on the same geometry (silhouette on SVD ≈ highest), clean/ interpretable segments, and categorical signals appear naturally.\\n\")\n",
    "choice_md.append(\"**Also included:** k-means **K=7** premium cohort (max post-hoc high-rating share) as an appendix spotlight.\\n\")\n",
    "\n",
    "# Quick tables\n",
    "choice_md.append(\"## Quality comparison (silhouette on SVD)\")\n",
    "choice_md.append(cmp_df.to_markdown(index=False))\n",
    "\n",
    "tmp = summ_df.copy()\n",
    "if \"share\" in tmp: tmp[\"share\"] = tmp[\"share\"].map(pct)\n",
    "if \"share_high_rating\" in tmp: tmp[\"share_high_rating\"] = tmp[\"share_high_rating\"].map(pct)\n",
    "choice_md.append(\"\\n## k-Prototypes K=3 — segment sizes\")\n",
    "choice_md.append(tmp.to_markdown(index=False))\n",
    "\n",
    "# Cat signals preview\n",
    "choice_md.append(\"\\n## k-Prototypes K=3 — sample categorical signals\")\n",
    "for c in sorted(sig_cat[\"cluster\"].unique()):\n",
    "    sub = sig_cat[sig_cat[\"cluster\"]==c]\n",
    "    over = sub[sub[\"direction\"]==\"over\"].sort_values(\"diff\", ascending=False).head(5)\n",
    "    under= sub[sub[\"direction\"]==\"under\"].sort_values(\"diff\", ascending=True).head(5)\n",
    "    choice_md.append(f\"### Cluster {int(c)}\")\n",
    "    choice_md.append(\"**Over-represented:** \" + \"; \".join(f\"`{r.column} = {r.level}` (Δ{r.diff:+.3f})\" for _, r in over.iterrows()))\n",
    "    choice_md.append(\"**Under-represented:** \" + \"; \".join(f\"`{r.column} = {r.level}` (Δ{r.diff:+.3f})\" for _, r in under.iterrows()))\n",
    "    choice_md.append(\"\")\n",
    "\n",
    "with open(\"unsup_outputs/unsup_final_choice.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(choice_md))\n",
    "print(\"Saved: unsup_outputs/unsup_final_choice.md\")\n",
    "\n",
    "# 5) Zip addendum (final)\n",
    "import zipfile\n",
    "zip_path = \"unsup_addendum_final_segments.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for p in [\n",
    "        \"unsup_outputs/unsup_final_choice.md\",\n",
    "        \"unsup_outputs/unsup_summary_k3.md\",\n",
    "        \"unsup_outputs/unsup_spotlight_k7.md\",\n",
    "        \"unsup_kproto/summary_k3.csv\",\n",
    "        \"unsup_kproto/top_signals_k3.csv\",\n",
    "        \"unsup_kproto/top_numeric_signals_k3.csv\",\n",
    "        \"unsup_kproto/summary_k7.csv\",\n",
    "        \"unsup_kproto/top_signals_k7.csv\",\n",
    "        \"unsup_kproto/segmentation_comparison.csv\",\n",
    "        \"unsup_kproto/labels_k3.csv\",\n",
    "        \"plots_unsup/segmentation_silhouette_comparison.png\",\n",
    "        \"plots_unsup/kproto_scatter_k3.png\",\n",
    "        \"plots_unsup/kproto_avg_rating_k3.png\",\n",
    "        \"plots_unsup/cluster_scatter_z12_k3.png\",\n",
    "        \"plots_unsup/cluster_avg_rating_k3.png\",\n",
    "        \"plots_unsup/kproto_scatter_k7.png\",\n",
    "        \"plots_unsup/kproto_avg_rating_k7.png\",\n",
    "        \"plots_unsup/cluster_scatter_z12_k7.png\",\n",
    "        \"plots_unsup/cluster_avg_rating_k7.png\",\n",
    "    ]:\n",
    "        if os.path.exists(p): z.write(p, arcname=os.path.basename(p))\n",
    "print(\"Saved:\", zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10706e0c-4345-4cb6-aafa-226b8420e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP U7c (fix): finalize unsupervised choice & export ===\n",
    "import os, zipfile, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "\n",
    "os.makedirs(\"unsup_outputs\", exist_ok=True)\n",
    "os.makedirs(\"plots_unsup\", exist_ok=True)\n",
    "\n",
    "# 1) Load comparison + summaries generated earlier\n",
    "cmp_df   = pd.read_csv(\"unsup_kproto/segmentation_comparison.csv\")\n",
    "summ_df  = pd.read_csv(\"unsup_kproto/summary_k3.csv\")\n",
    "sig_cat  = pd.read_csv(\"unsup_kproto/top_signals_k3.csv\")\n",
    "labels   = pd.read_csv(\"unsup_kproto/labels_k3.csv\")\n",
    "\n",
    "# 2) (Re)make silhouette comparison plot (idempotent)\n",
    "plt.figure(figsize=(6.5, 4.2))\n",
    "show = cmp_df.copy()\n",
    "show[\"label\"] = show[\"method\"] + \" k=\" + show[\"k\"].astype(str)\n",
    "plt.bar(show[\"label\"], show[\"silhouette_on_SVD\"])\n",
    "plt.ylabel(\"Silhouette (on SVD space)\")\n",
    "plt.title(\"Segmentation quality comparison\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots_unsup/segmentation_silhouette_comparison.png\", dpi=160)\n",
    "plt.close()\n",
    "print(\"Saved: plots_unsup/segmentation_silhouette_comparison.png\")\n",
    "\n",
    "# 3) Compute numeric top signals (if not already there)\n",
    "if not os.path.exists(\"unsup_kproto/top_numeric_signals_k3.csv\"):\n",
    "    ct = load(\"unsup_artifacts/ct_preproc.joblib\")\n",
    "    num_cols = list(ct.transformers_[0][2])\n",
    "    # rebuild X_full from train/eval\n",
    "    X_full = globals().get(\"X_full\")\n",
    "    if X_full is None:\n",
    "        Xtr_ = globals().get(\"Xtr\", globals().get(\"Xtr2\"))\n",
    "        Xte_ = globals().get(\"Xte\")\n",
    "        assert Xtr_ is not None and Xte_ is not None, \"Need X_full or (Xtr & Xte).\"\n",
    "        cols_union = Xtr_.columns.union(Xte_.columns)\n",
    "        X_full = pd.concat([\n",
    "            Xtr_.reindex(columns=cols_union, fill_value=0),\n",
    "            Xte_.reindex(columns=cols_union, fill_value=0)\n",
    "        ], axis=0, ignore_index=True)\n",
    "\n",
    "    num_df = X_full[num_cols].copy()\n",
    "    for c in num_cols:\n",
    "        num_df[c] = pd.to_numeric(num_df[c], errors=\"coerce\")\n",
    "    num_df = num_df.fillna(num_df.median(numeric_only=True))\n",
    "\n",
    "    labs = labels[\"cluster\"].to_numpy()\n",
    "    global_mean = num_df.mean(axis=0)\n",
    "    rows = []\n",
    "    TOP = 10\n",
    "    for c in sorted(np.unique(labs)):\n",
    "        sub = num_df[labs == c]\n",
    "        diff = (sub.mean(axis=0) - global_mean).sort_values(ascending=False)\n",
    "        for feat, dv in diff.head(TOP).items():\n",
    "            rows.append({\"cluster\": int(c), \"feature\": feat, \"direction\": \"over\",  \"diff_from_global\": float(dv)})\n",
    "        for feat, dv in diff.tail(TOP).items():\n",
    "            rows.append({\"cluster\": int(c), \"feature\": feat, \"direction\": \"under\",\"diff_from_global\": float(dv)})\n",
    "    pd.DataFrame(rows).to_csv(\"unsup_kproto/top_numeric_signals_k3.csv\", index=False)\n",
    "    print(\"Saved: unsup_kproto/top_numeric_signals_k3.csv\")\n",
    "\n",
    "# 4) Write the final selection markdown (FIX: use row['diff'], not row.diff)\n",
    "def pct(x):\n",
    "    try: return f\"{100*float(x):.1f}%\"\n",
    "    except Exception: return str(x)\n",
    "\n",
    "choice_md = []\n",
    "choice_md.append(\"# Final Unsupervised Selection\\n\")\n",
    "choice_md.append(\"**Chosen segmentation:** k-Prototypes (hybrid k-means/k-modes), **K=3**.\\n\")\n",
    "choice_md.append(\"**Why:** best separation on the same geometry (highest silhouette on SVD), clean/ interpretable segments, and categorical signals appear naturally.\\n\")\n",
    "choice_md.append(\"**Also included:** k-means **K=7** premium cohort (max post-hoc high-rating share) as an appendix spotlight.\\n\")\n",
    "\n",
    "choice_md.append(\"## Quality comparison (silhouette on SVD)\")\n",
    "choice_md.append(cmp_df.to_markdown(index=False))\n",
    "\n",
    "tbl = summ_df.copy()\n",
    "if \"share\" in tbl: tbl[\"share\"] = tbl[\"share\"].map(pct)\n",
    "if \"share_high_rating\" in tbl: tbl[\"share_high_rating\"] = tbl[\"share_high_rating\"].map(pct)\n",
    "choice_md.append(\"\\n## k-Prototypes K=3 — segment sizes\")\n",
    "choice_md.append(tbl.to_markdown(index=False))\n",
    "\n",
    "choice_md.append(\"\\n## k-Prototypes K=3 — sample categorical signals\")\n",
    "for c in sorted(sig_cat[\"cluster\"].unique()):\n",
    "    sub = sig_cat[sig_cat[\"cluster\"]==c]\n",
    "    over = sub[sub[\"direction\"]==\"over\"].sort_values(\"diff\", ascending=False).head(5)\n",
    "    under= sub[sub[\"direction\"]==\"under\"].sort_values(\"diff\", ascending=True).head(5)\n",
    "    choice_md.append(f\"### Cluster {int(c)}\")\n",
    "    if not over.empty:\n",
    "        over_str = \"; \".join(\n",
    "            f\"`{row['column']} = {row['level']}` (Δ{float(row['diff']):+0.3f})\"\n",
    "            for _, row in over.iterrows()\n",
    "        )\n",
    "        choice_md.append(\"**Over-represented:** \" + over_str)\n",
    "    if not under.empty:\n",
    "        under_str = \"; \".join(\n",
    "            f\"`{row['column']} = {row['level']}` (Δ{float(row['diff']):+0.3f})\"\n",
    "            for _, row in under.iterrows()\n",
    "        )\n",
    "        choice_md.append(\"**Under-represented:** \" + under_str)\n",
    "    choice_md.append(\"\")\n",
    "\n",
    "out_md = \"unsup_outputs/unsup_final_choice.md\"\n",
    "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(choice_md))\n",
    "print(\"Saved:\", out_md)\n",
    "\n",
    "# 5) Final zip addendum (only add files that exist)\n",
    "zip_path = \"unsup_addendum_final_segments.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for p in [\n",
    "        \"unsup_outputs/unsup_final_choice.md\",\n",
    "        \"unsup_outputs/unsup_summary_k3.md\",\n",
    "        \"unsup_outputs/unsup_spotlight_k7.md\",\n",
    "        \"unsup_kproto/summary_k3.csv\",\n",
    "        \"unsup_kproto/top_signals_k3.csv\",\n",
    "        \"unsup_kproto/top_numeric_signals_k3.csv\",\n",
    "        \"unsup_kproto/summary_k7.csv\",\n",
    "        \"unsup_kproto/top_signals_k7.csv\",\n",
    "        \"unsup_kproto/segmentation_comparison.csv\",\n",
    "        \"unsup_kproto/labels_k3.csv\",\n",
    "        \"plots_unsup/segmentation_silhouette_comparison.png\",\n",
    "        \"plots_unsup/kproto_scatter_k3.png\",\n",
    "        \"plots_unsup/kproto_avg_rating_k3.png\",\n",
    "        \"plots_unsup/cluster_scatter_z12_k3.png\",\n",
    "        \"plots_unsup/cluster_avg_rating_k3.png\",\n",
    "        \"plots_unsup/kproto_scatter_k7.png\",\n",
    "        \"plots_unsup/kproto_avg_rating_k7.png\",\n",
    "        \"plots_unsup/cluster_scatter_z12_k7.png\",\n",
    "        \"plots_unsup/cluster_avg_rating_k7.png\",\n",
    "    ]:\n",
    "        if os.path.exists(p):\n",
    "            z.write(p, arcname=os.path.basename(p))\n",
    "print(\"Saved:\", zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3397780-bd21-466e-b600-501fc0ca5625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42345114-9981-4236-a138-adf000eccc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0badb6-1a82-4ce1-b390-a02b30caaa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b46706-88f9-43cf-9f37-a8c4e7b50fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc505229-06cb-4a3e-a6bb-b1016346cbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8df16a-623d-472c-b735-5a64dee98a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19206063-3453-4ccc-84c2-2dc79d7326fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Github Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6afeea-77ec-4fc5-9754-e693664f28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.name \"erosas9172\"\n",
    "!git config --global user.email \"erosas9172@sdsu.edu\"\n",
    "!git config --global init.defaultBranch main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217c513-2a27-4f63-8de9-65c50a98ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper osxkeychain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f365baa-2027-417f-958f-254e1c41af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/jupyter-notebooks\n",
    "%cd ~/jupyter-notebooks\n",
    "!pwd\n",
    "!ls -la\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35d315-ad6e-4199-868a-b6864044b281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f2bfd-f044-467c-9937-edbeb006a539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c3696-d60f-4292-850b-33530d186fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
